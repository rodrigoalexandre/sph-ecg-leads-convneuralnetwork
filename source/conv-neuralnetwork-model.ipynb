{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47353fcc-74e3-426e-a724-6b1d1bf32b2f",
   "metadata": {},
   "source": [
    "#### Train a Convolutional Neural Network model for predicting cardiac arrhythmias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbe460f",
   "metadata": {},
   "source": [
    "#### Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "077b6c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gc\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42175028",
   "metadata": {},
   "source": [
    "#### Define a function to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b43ccbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(lead_name):\n",
    "    # Loads the dataset using only the chosen lead.\n",
    "    # Parameters:\n",
    "    #    lead_name: Lead to be used.\n",
    "    # Return:\n",
    "    #    Dataframe loaded (Pandas dataframe)\n",
    "    df = None\n",
    "    column_names = [\"idx\", \"ecg_id\", lead_name, \"arrhythmia_code\"]\n",
    "    dtypes = {\"ecg_id\": \"str\", lead_name : \"float16\", \"arrhythmia_code\" : \"int16\"}\n",
    "    try:\n",
    "        print(\"\\nStart loading CSV file...\")\n",
    "        df = pd.read_csv(\"../dataset/csv_files/ecg_sph_dataset.csv\", sep=\"|\", dtype = dtypes, usecols = column_names)\n",
    "        print(\"Finish loading CSV file.\")\n",
    "    except Exception as e:\n",
    "        print(\"\\nFail to load CSV file.\")\n",
    "        print(\"Error: {}\".format(e))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3579e10b",
   "metadata": {},
   "source": [
    "#### Build a helper function to convert the records to the required format to perform a time series processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "859f6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "number_of_steps = 1250\n",
    "number_of_features = 1\n",
    "number_of_classes = 32\n",
    "\n",
    "def get_new_columns_order(column_names_array):\n",
    "    columns_series = pd.Series(column_names_array)\n",
    "    column_idx_count = 0\n",
    "    new_array = np.zeros(len(column_names_array), dtype = int)\n",
    "    for column_idx in range(0, (number_of_steps * 4)):\n",
    "        for column_idx_2 in range(0, number_of_features):\n",
    "            new_array[column_idx + column_idx_2 * (number_of_steps * 4)] = column_idx_count\n",
    "            column_idx_count += 1\n",
    "    return new_array\n",
    "\n",
    "def build_time_window_structure(df, lead_name):\n",
    "    # Splits the dataset into \"time windows\" to be used as a time series.\n",
    "    # The function groups each 125 dataset records (CSV lines) into one record.\n",
    "    # Parameters:\n",
    "    #    df: Dataframe to be splitted.\n",
    "    #    lead_name: Lead to be used.\n",
    "    # Return:\n",
    "    #    All time windows (np.array)\n",
    "    #    All target values (np.array)\n",
    "    print(\"\\nStarting build_time_window_structure function...\")\n",
    "    df[\"idx\"] = df[\"idx\"] % (number_of_steps * 4)\n",
    "    df_aux = df.pivot_table(index = \"ecg_id\", columns = \"idx\", values = [lead_name], aggfunc = \"sum\")\n",
    "    new_columns = get_new_columns_order(df_aux.columns.values)\n",
    "    df_aux.columns = list(new_columns)\n",
    "    sorted_columns = sorted(df_aux.columns)\n",
    "    df_modified = df_aux[sorted_columns]\n",
    "    X_array = df_modified.values\n",
    "    y_array = df[\"arrhythmia_code\"].values\n",
    "    y_array = y_array[::(number_of_steps * 4)]\n",
    "    # Resample sample frequency to 125 hz.\n",
    "    fs_original = 500 # Original frequency (Hz)\n",
    "    fs_new = 125 # New frequency (Hz)\n",
    "    downsampling_factor = int(fs_original / fs_new)\n",
    "    nyquist_rate = fs_original / 2.0  # Nyquist rate\n",
    "    cutoff_freq = fs_new / 2.0  # Cut off rate\n",
    "    b, a = signal.butter(4, cutoff_freq / nyquist_rate, btype = \"low\")\n",
    "    X_array_filtered = signal.filtfilt(b, a, X_array, axis = 1)\n",
    "    X_array_125hz = X_array_filtered[:, ::downsampling_factor]\n",
    "    print(\"\\nShape of features: \", X_array_125hz.shape)\n",
    "    print(\"Quantity os samples (labels): \", len(y_array))\n",
    "    print(\"\\nFinishing build_time_window_structure function.\")\n",
    "    return X_array_125hz, y_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d50c0a6-624d-4e06-b5c3-438e3909aea8",
   "metadata": {},
   "source": [
    "#### Define a function to remove classes with less than 6 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b49334-6e2d-4a4e-899f-6ab4aceed629",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_classes_with_less_samples(X_array, y_array):\n",
    "    # Remove classes with less than 6 samples.\n",
    "    # Parameters:\n",
    "    #    X_array: array of features.\n",
    "    #    y_array: array of targets.\n",
    "    # Return:\n",
    "    #    Array of features (np.array)\n",
    "    #    Array of targets (np.array)\n",
    "\n",
    "    # Remove samples belonging to diagnostics 31, 37, 84, 87, 102, 143, 148, and 152 because these classes have less than 6 samples (SMOTE restriction).\n",
    "    print(\"\\nRemove classes with less than 6 samples.\")\n",
    "    removed_idx = np.where(np.isin(y_array, [31, 37, 84, 87, 102, 143, 148, 152]))[0]\n",
    "    X_array = np.delete(X_array, removed_idx, axis = 0)\n",
    "    y_array = np.delete(y_array, removed_idx, axis = 0)\n",
    "    number_of_classes = 32\n",
    "    # Generate a class number for each diagnostic code and replace y_array values.\n",
    "    sorted_codes = sorted(set(y_array))\n",
    "    dict_aux = {}\n",
    "    for classes_idx in range(0, number_of_classes):\n",
    "        dict_aux[classes_idx] = sorted_codes[classes_idx]\n",
    "        y_array = [classes_idx if elem == sorted_codes[classes_idx] else elem for elem in y_array]\n",
    "    y_array = np.array(y_array)\n",
    "    print(\"\\nShow classes identification:\")\n",
    "    for key, value in dict_aux.items():\n",
    "        print(f\"Class: {key} - Arrhythmia code: {value}\")\n",
    "    # Check for dataset balance.\n",
    "    diagnostic_classes, count = np.unique(y_array, return_counts = True)\n",
    "    percentage_by_class = [(i * 100 / np.sum(count)) for i in count]\n",
    "    category_count = list(zip(diagnostic_classes, count, percentage_by_class))\n",
    "    category_count.sort(key = lambda x: x[1], reverse = True)\n",
    "    print(\"\\nCheck for dataset balance:\")\n",
    "    for diagnostic_classes, count, percentage_by_class in category_count:\n",
    "        print(f\"Class = {diagnostic_classes:3.0f}   Qty = {count:8.0f}   Percentage = {percentage_by_class:2.2f} %\")\n",
    "    return X_array, y_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2c820a-3ac1-4da5-ae09-dd378637c4be",
   "metadata": {},
   "source": [
    "#### Define a function for training a CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19d8f38d-7cd0-4ddc-80d9-b11e94edb868",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_cnn_model(cnn_model, X_train, y_train, X_test, y_test, num_epochs, batch_size, validation_split, model_cfg_file):\n",
    "    # Train a CNN model.\n",
    "    # Parameters:\n",
    "    #    cnn_model (Sequential): model to be trained.\n",
    "    #    X_train (np.array): array of features values.\n",
    "    #    X_test (np.array): array of features values.\n",
    "    #    y_train (np.array): array of target values.\n",
    "    #    y_test (np.array): array of target values.\n",
    "    #    nun_folds (int): number of folds.\n",
    "    #    num_epochs (int): number of epochs of training.\n",
    "    #    batch_size (int): batch size.\n",
    "    #    validation_split (float): percentage of instances for validation set.\n",
    "    #    model_cfg_file (str): file to save the configuration model.\n",
    "    # Returns:\n",
    "    #    history (History object): history of training metrics.\n",
    "\n",
    "    # Train the CNN model and evaluate it.\n",
    "    start_time = time.time()\n",
    "    print(\"\\nStarting training at: \", time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "    es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 30)\n",
    "    with tf.device('/cpu:0'):\n",
    "        history = cnn_model.fit(X_train, y_train, validation_split = validation_split, epochs = num_epochs, batch_size = batch_size, \n",
    "                                verbose = 1, callbacks = [es])\n",
    "        cnn_model.save(\"../modelconfig/\" + model_cfg_file)\n",
    "        _, train_accuracy = cnn_model.evaluate(X_train, y_train, verbose = 0)\n",
    "        _, test_accuracy = cnn_model.evaluate(X_test, y_test, verbose = 0)\n",
    "        elapsed_seconds = time.time() - start_time\n",
    "        print(\"\\nTime taken for training: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_seconds)))\n",
    "        print(\"\\nTrain Accuracy: {:.2f} %\".format(train_accuracy * 100))\n",
    "        print(\"Test Accuracy: {:.2f} %\".format(test_accuracy * 100))\n",
    "        print(\"\\nEvaluate other metrics:\")\n",
    "        pred_classes = np.argmax(cnn_model.predict(X_test), axis = 1)\n",
    "        truth_classes = y_test\n",
    "        print(classification_report(truth_classes, pred_classes, zero_division = 0))\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8dbf24-0ece-49d0-9644-a3a90865f0dd",
   "metadata": {},
   "source": [
    "#### Define a function to build a version 1 of CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acff693b-6d32-4b69-8133-0fca13f2b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_v1():\n",
    "    act_fuction = \"relu\"\n",
    "    k_init = \"he_uniform\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters = 8, kernel_size = 3, activation = act_fuction, kernel_initializer = k_init, \n",
    "                     input_shape = (number_of_steps, number_of_features)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters = 8, kernel_size = 3, activation = act_fuction, kernel_initializer = k_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Conv1D(filters = 16, kernel_size = 5, activation = act_fuction, kernel_initializer = k_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters = 16, kernel_size = 5, activation = act_fuction, kernel_initializer = k_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation = act_fuction, kernel_initializer = k_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(number_of_classes, activation = 'softmax'))\n",
    "    opt = Adam(learning_rate = 0.001)\n",
    "    model.summary()\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be2207f-84ab-4183-9670-72b06c811622",
   "metadata": {},
   "source": [
    "#### Define a function to use SMOTE technique to generate upsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbc31f65-cf1f-458c-8d18-9f57101745bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_smote(X_array, y_array):\n",
    "    # Apply the SMOTE technique to generate upsampling.\n",
    "    # Parameters:\n",
    "    #    X_array: array of features.\n",
    "    #    y_array: array of targets.\n",
    "    # Return:\n",
    "    #    Array of features (np.array)\n",
    "    #    Array of targets (np.array)\n",
    "    diagnostic_classes, count = np.unique(y_array, return_counts = True)\n",
    "    percentage_by_class = [(i * 100 / np.sum(count)) for i in count]\n",
    "    category_count = list(zip(diagnostic_classes, count, percentage_by_class))\n",
    "    category_count.sort(key = lambda x: x[1], reverse = True)\n",
    "    print(\"\\nGenerating upsampling through SMOTE...\")\n",
    "    smote = SMOTE(sampling_strategy = \"auto\", k_neighbors = 5, random_state = 42)\n",
    "    X_array_res, y_array_res = smote.fit_resample(X_array, y_array)\n",
    "    dict_samples_per_class = {}\n",
    "    nr_samples_per_class = 6250\n",
    "    for category_ids, count, percentage_of_categories in category_count:\n",
    "        dict_samples_per_class[category_ids] = nr_samples_per_class\n",
    "    rus = RandomUnderSampler(sampling_strategy = dict_samples_per_class, random_state = 42)\n",
    "    X_array_res, y_array_res = rus.fit_resample(X_array_res, y_array_res)\n",
    "    print(\"{} samples after upsampling.\".format(len(y_array_res)))\n",
    "    print(\"Finishing upsampling.\")\n",
    "    return X_array_res, y_array_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a3ed55-1027-42d9-9362-d28242bc891e",
   "metadata": {},
   "source": [
    "#### Define a function to split the dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65a16046-f588-41f8-9338-f641b04f2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_dataset_for_training(X_array, y_array):\n",
    "    # Split dataset for training\n",
    "    # Parameters:\n",
    "    #    X_array: array of features.\n",
    "    #    y_array: array of targets.\n",
    "    # Return:\n",
    "    #    X_train (np.array)\n",
    "    #    X_test (np.array)\n",
    "    #    y_train (np.array)\n",
    "    #    y_test (np.array)\n",
    "\n",
    "    # Scale features using statistics that are robust to outliers.\n",
    "    print(\"\\nStarting dataset split...\")\n",
    "    rb_scaler = RobustScaler()\n",
    "    rb_scaler.fit(X_array)\n",
    "    X_array_samples = rb_scaler.transform(X_array)\n",
    "    # Reshape the structure data to be compatible with the pattern [samples, timesteps, features].\n",
    "    X_array_samples = X_array_samples.reshape((X_array_samples.shape[0], number_of_steps, number_of_features))\n",
    "    # Split train and test sets.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_array_samples, y_array, test_size = 0.2, stratify = y_array, random_state = 42)\n",
    "    print(\"Finishing dataset split.\\n\")\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d861ca2b-79bb-4d8a-8216-3f1d80e985ba",
   "metadata": {},
   "source": [
    "#### Lead I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b3ad224-b9d5-4158-ba39-3f046d59ecdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n",
      "\n",
      "Generating upsampling through SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Finishing upsampling.\n",
      "\n",
      "Starting dataset split...\n",
      "Finishing dataset split.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1248, 8)           32        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1248, 8)          32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1246, 8)           200       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1246, 8)          32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 623, 8)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 619, 16)           656       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 619, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 615, 16)           1296      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 615, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 307, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4912)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2515456   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                16416     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,536,296\n",
      "Trainable params: 2,535,176\n",
      "Non-trainable params: 1,120\n",
      "_________________________________________________________________\n",
      "\n",
      "Starting training at:  12:06:56\n",
      "Epoch 1/300\n",
      "4500/4500 [==============================] - 443s 98ms/step - loss: 0.3448 - accuracy: 0.9052 - val_loss: 0.1765 - val_accuracy: 0.9497\n",
      "Epoch 2/300\n",
      "4500/4500 [==============================] - 537s 119ms/step - loss: 0.1045 - accuracy: 0.9671 - val_loss: 0.1206 - val_accuracy: 0.9633\n",
      "Epoch 3/300\n",
      "4500/4500 [==============================] - 681s 151ms/step - loss: 0.0555 - accuracy: 0.9823 - val_loss: 0.1158 - val_accuracy: 0.9681\n",
      "Epoch 4/300\n",
      "4500/4500 [==============================] - 584s 130ms/step - loss: 0.0368 - accuracy: 0.9886 - val_loss: 0.2023 - val_accuracy: 0.9480\n",
      "Epoch 5/300\n",
      "4500/4500 [==============================] - 581s 129ms/step - loss: 0.0312 - accuracy: 0.9903 - val_loss: 0.1235 - val_accuracy: 0.9634\n",
      "Epoch 6/300\n",
      "4500/4500 [==============================] - 575s 128ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.0956 - val_accuracy: 0.9786\n",
      "Epoch 7/300\n",
      "4500/4500 [==============================] - 589s 131ms/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.1092 - val_accuracy: 0.9728\n",
      "Epoch 8/300\n",
      "4500/4500 [==============================] - 590s 131ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.1030 - val_accuracy: 0.9744\n",
      "Epoch 9/300\n",
      "4500/4500 [==============================] - 588s 131ms/step - loss: 0.0173 - accuracy: 0.9950 - val_loss: 0.0984 - val_accuracy: 0.9794\n",
      "Epoch 10/300\n",
      "4500/4500 [==============================] - 596s 132ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 6.6026 - val_accuracy: 0.1813\n",
      "Epoch 11/300\n",
      "4500/4500 [==============================] - 622s 138ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 0.1015 - val_accuracy: 0.9787\n",
      "Epoch 12/300\n",
      "4500/4500 [==============================] - 605s 134ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.8920 - val_accuracy: 0.8280\n",
      "Epoch 13/300\n",
      "4500/4500 [==============================] - 597s 133ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.1165 - val_accuracy: 0.9783\n",
      "Epoch 14/300\n",
      "4500/4500 [==============================] - 591s 131ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.1213 - val_accuracy: 0.9805\n",
      "Epoch 15/300\n",
      "4500/4500 [==============================] - 596s 132ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.1091 - val_accuracy: 0.9777\n",
      "Epoch 16/300\n",
      "4500/4500 [==============================] - 604s 134ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.1212 - val_accuracy: 0.9789\n",
      "Epoch 17/300\n",
      "4500/4500 [==============================] - 618s 137ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.1174 - val_accuracy: 0.9756\n",
      "Epoch 18/300\n",
      "4500/4500 [==============================] - 605s 134ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.1044 - val_accuracy: 0.9796\n",
      "Epoch 19/300\n",
      "4500/4500 [==============================] - 620s 138ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.1189 - val_accuracy: 0.9783\n",
      "Epoch 20/300\n",
      "4500/4500 [==============================] - 609s 135ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.2656 - val_accuracy: 0.9406\n",
      "Epoch 21/300\n",
      "4500/4500 [==============================] - 613s 136ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.2321 - val_accuracy: 0.9554\n",
      "Epoch 22/300\n",
      "4500/4500 [==============================] - 620s 138ms/step - loss: 0.0085 - accuracy: 0.9978 - val_loss: 0.1091 - val_accuracy: 0.9787\n",
      "Epoch 23/300\n",
      "4500/4500 [==============================] - 622s 138ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.1288 - val_accuracy: 0.9801\n",
      "Epoch 24/300\n",
      "4500/4500 [==============================] - 620s 138ms/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.1782 - val_accuracy: 0.9627\n",
      "Epoch 25/300\n",
      "4500/4500 [==============================] - 533s 119ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.3330 - val_accuracy: 0.9339\n",
      "Epoch 26/300\n",
      "4500/4500 [==============================] - 355s 79ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.1752 - val_accuracy: 0.9657\n",
      "Epoch 27/300\n",
      "4500/4500 [==============================] - 392s 87ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 7.4851 - val_accuracy: 0.2719\n",
      "Epoch 28/300\n",
      "4500/4500 [==============================] - 380s 85ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 1.6979 - val_accuracy: 0.7147\n",
      "Epoch 29/300\n",
      "4500/4500 [==============================] - 407s 90ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.1270 - val_accuracy: 0.9806\n",
      "Epoch 30/300\n",
      "4500/4500 [==============================] - 382s 85ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.4959 - val_accuracy: 0.8861\n",
      "Epoch 31/300\n",
      "4500/4500 [==============================] - 388s 86ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.1282 - val_accuracy: 0.9794\n",
      "Epoch 32/300\n",
      "4500/4500 [==============================] - 390s 87ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.1361 - val_accuracy: 0.9792\n",
      "Epoch 33/300\n",
      "4500/4500 [==============================] - 412s 91ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.1339 - val_accuracy: 0.9808\n",
      "Epoch 34/300\n",
      "4500/4500 [==============================] - 397s 88ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.1422 - val_accuracy: 0.9793\n",
      "Epoch 35/300\n",
      "4500/4500 [==============================] - 384s 85ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.1352 - val_accuracy: 0.9807\n",
      "Epoch 36/300\n",
      "4500/4500 [==============================] - 385s 86ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.1437 - val_accuracy: 0.9836\n",
      "Epoch 36: early stopping\n",
      "\n",
      "Time taken for training:  05:20:53\n",
      "\n",
      "Train Accuracy: 99.78 %\n",
      "Test Accuracy: 98.20 %\n",
      "\n",
      "Evaluate other metrics:\n",
      "1250/1250 [==============================] - 42s 33ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78      1250\n",
      "           1       0.99      0.99      0.99      1250\n",
      "           2       0.97      0.97      0.97      1250\n",
      "           3       0.97      0.93      0.95      1250\n",
      "           4       0.99      0.99      0.99      1250\n",
      "           5       1.00      1.00      1.00      1250\n",
      "           6       0.98      0.98      0.98      1250\n",
      "           7       1.00      1.00      1.00      1250\n",
      "           8       1.00      1.00      1.00      1250\n",
      "           9       0.97      0.97      0.97      1250\n",
      "          10       0.99      1.00      0.99      1250\n",
      "          11       1.00      1.00      1.00      1250\n",
      "          12       1.00      1.00      1.00      1250\n",
      "          13       1.00      1.00      1.00      1250\n",
      "          14       1.00      1.00      1.00      1250\n",
      "          15       1.00      1.00      1.00      1250\n",
      "          16       0.96      0.96      0.96      1250\n",
      "          17       1.00      0.99      0.99      1250\n",
      "          18       1.00      1.00      1.00      1250\n",
      "          19       1.00      0.99      0.99      1250\n",
      "          20       1.00      1.00      1.00      1250\n",
      "          21       0.99      1.00      1.00      1250\n",
      "          22       1.00      1.00      1.00      1250\n",
      "          23       1.00      1.00      1.00      1250\n",
      "          24       0.95      0.95      0.95      1250\n",
      "          25       0.98      0.99      0.98      1250\n",
      "          26       0.91      0.94      0.92      1250\n",
      "          27       1.00      1.00      1.00      1250\n",
      "          28       1.00      1.00      1.00      1250\n",
      "          29       1.00      1.00      1.00      1250\n",
      "          30       1.00      1.00      1.00      1250\n",
      "          31       1.00      1.00      1.00      1250\n",
      "\n",
      "    accuracy                           0.98     40000\n",
      "   macro avg       0.98      0.98      0.98     40000\n",
      "weighted avg       0.98      0.98      0.98     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"lead1\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"lead1\")\n",
    "\n",
    "# Try to release memory\n",
    "del new_df\n",
    "gc.collect()\n",
    "\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "X_array, y_array = apply_smote(X_array, y_array)\n",
    "X_train, X_test, y_train, y_test = split_dataset_for_training(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.1\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_train, y_train, X_test, y_test, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_lead1.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a16aed-e2fe-44c0-a83d-30235fc2ec44",
   "metadata": {},
   "source": [
    "#### Lead II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b2c21c2-ca1c-4ec4-b7c7-42c4f374d4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n",
      "\n",
      "Generating upsampling through SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Finishing upsampling.\n",
      "\n",
      "Starting dataset split...\n",
      "Finishing dataset split.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1248, 8)           32        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1248, 8)          32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1246, 8)           200       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1246, 8)          32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 623, 8)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 619, 16)           656       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 619, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 615, 16)           1296      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 615, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 307, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4912)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2515456   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                16416     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,536,296\n",
      "Trainable params: 2,535,176\n",
      "Non-trainable params: 1,120\n",
      "_________________________________________________________________\n",
      "\n",
      "Starting training at:  07:15:28\n",
      "Epoch 1/300\n",
      "4500/4500 [==============================] - 486s 108ms/step - loss: 0.3068 - accuracy: 0.9156 - val_loss: 0.1255 - val_accuracy: 0.9616\n",
      "Epoch 2/300\n",
      "4500/4500 [==============================] - 589s 131ms/step - loss: 0.0819 - accuracy: 0.9741 - val_loss: 0.0988 - val_accuracy: 0.9713\n",
      "Epoch 3/300\n",
      "4500/4500 [==============================] - 610s 136ms/step - loss: 0.0433 - accuracy: 0.9861 - val_loss: 0.0927 - val_accuracy: 0.9756\n",
      "Epoch 4/300\n",
      "4500/4500 [==============================] - 616s 137ms/step - loss: 0.0291 - accuracy: 0.9907 - val_loss: 0.0836 - val_accuracy: 0.9789\n",
      "Epoch 5/300\n",
      "4500/4500 [==============================] - 619s 138ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 0.1045 - val_accuracy: 0.9771\n",
      "Epoch 6/300\n",
      "4500/4500 [==============================] - 632s 140ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.0926 - val_accuracy: 0.9797\n",
      "Epoch 7/300\n",
      "4500/4500 [==============================] - 641s 142ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.1122 - val_accuracy: 0.9762\n",
      "Epoch 8/300\n",
      "4500/4500 [==============================] - 630s 140ms/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.1210 - val_accuracy: 0.9772\n",
      "Epoch 9/300\n",
      "4500/4500 [==============================] - 630s 140ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.1007 - val_accuracy: 0.9814\n",
      "Epoch 10/300\n",
      "4500/4500 [==============================] - 658s 146ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.1110 - val_accuracy: 0.9798\n",
      "Epoch 11/300\n",
      "4500/4500 [==============================] - 623s 138ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.1125 - val_accuracy: 0.9796\n",
      "Epoch 12/300\n",
      "4500/4500 [==============================] - 717s 159ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.1148 - val_accuracy: 0.9786\n",
      "Epoch 13/300\n",
      "4500/4500 [==============================] - 667s 148ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.1085 - val_accuracy: 0.9808\n",
      "Epoch 14/300\n",
      "4500/4500 [==============================] - 759s 169ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.1077 - val_accuracy: 0.9825\n",
      "Epoch 15/300\n",
      "4500/4500 [==============================] - 761s 169ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.1131 - val_accuracy: 0.9808\n",
      "Epoch 16/300\n",
      "4500/4500 [==============================] - 783s 174ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1198 - val_accuracy: 0.9820\n",
      "Epoch 17/300\n",
      "4500/4500 [==============================] - 799s 178ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1330 - val_accuracy: 0.9803\n",
      "Epoch 18/300\n",
      "4500/4500 [==============================] - 771s 171ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.1253 - val_accuracy: 0.9806\n",
      "Epoch 19/300\n",
      "4500/4500 [==============================] - 769s 171ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.1617 - val_accuracy: 0.9790\n",
      "Epoch 20/300\n",
      "4500/4500 [==============================] - 770s 171ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.1297 - val_accuracy: 0.9819\n",
      "Epoch 21/300\n",
      "4500/4500 [==============================] - 793s 176ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.1280 - val_accuracy: 0.9818\n",
      "Epoch 22/300\n",
      "4500/4500 [==============================] - 786s 175ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.1246 - val_accuracy: 0.9828\n",
      "Epoch 23/300\n",
      "4500/4500 [==============================] - 784s 174ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.1236 - val_accuracy: 0.9821\n",
      "Epoch 24/300\n",
      "4500/4500 [==============================] - 784s 174ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.1292 - val_accuracy: 0.9822\n",
      "Epoch 25/300\n",
      "4500/4500 [==============================] - 796s 177ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 0.1331 - val_accuracy: 0.9819\n",
      "Epoch 26/300\n",
      "4500/4500 [==============================] - 797s 177ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.1438 - val_accuracy: 0.9822\n",
      "Epoch 27/300\n",
      "4500/4500 [==============================] - 789s 175ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1314 - val_accuracy: 0.9826\n",
      "Epoch 28/300\n",
      "4500/4500 [==============================] - 802s 178ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.1188 - val_accuracy: 0.9838\n",
      "Epoch 29/300\n",
      "4500/4500 [==============================] - 814s 181ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1366 - val_accuracy: 0.9824\n",
      "Epoch 30/300\n",
      "4500/4500 [==============================] - 828s 184ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.1320 - val_accuracy: 0.9829\n",
      "Epoch 31/300\n",
      "4500/4500 [==============================] - 811s 180ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1266 - val_accuracy: 0.9842\n",
      "Epoch 32/300\n",
      "4500/4500 [==============================] - 823s 183ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.1311 - val_accuracy: 0.9835\n",
      "Epoch 33/300\n",
      "4500/4500 [==============================] - 813s 181ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.1248 - val_accuracy: 0.9833\n",
      "Epoch 34/300\n",
      "4500/4500 [==============================] - 822s 183ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.1217 - val_accuracy: 0.9827\n",
      "Epoch 34: early stopping\n",
      "\n",
      "Time taken for training:  06:57:27\n",
      "\n",
      "Train Accuracy: 99.79 %\n",
      "Test Accuracy: 98.37 %\n",
      "\n",
      "Evaluate other metrics:\n",
      "1250/1250 [==============================] - 74s 58ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1250\n",
      "           1       0.99      1.00      0.99      1250\n",
      "           2       0.96      0.97      0.97      1250\n",
      "           3       0.94      0.94      0.94      1250\n",
      "           4       0.98      0.99      0.99      1250\n",
      "           5       1.00      1.00      1.00      1250\n",
      "           6       0.98      0.99      0.99      1250\n",
      "           7       1.00      1.00      1.00      1250\n",
      "           8       1.00      1.00      1.00      1250\n",
      "           9       0.98      0.98      0.98      1250\n",
      "          10       1.00      1.00      1.00      1250\n",
      "          11       1.00      1.00      1.00      1250\n",
      "          12       1.00      1.00      1.00      1250\n",
      "          13       1.00      1.00      1.00      1250\n",
      "          14       1.00      1.00      1.00      1250\n",
      "          15       1.00      1.00      1.00      1250\n",
      "          16       0.95      0.96      0.95      1250\n",
      "          17       0.98      1.00      0.99      1250\n",
      "          18       1.00      1.00      1.00      1250\n",
      "          19       1.00      1.00      1.00      1250\n",
      "          20       1.00      1.00      1.00      1250\n",
      "          21       1.00      1.00      1.00      1250\n",
      "          22       1.00      1.00      1.00      1250\n",
      "          23       1.00      1.00      1.00      1250\n",
      "          24       0.98      0.95      0.96      1250\n",
      "          25       0.98      0.99      0.99      1250\n",
      "          26       0.98      0.91      0.94      1250\n",
      "          27       1.00      1.00      1.00      1250\n",
      "          28       1.00      1.00      1.00      1250\n",
      "          29       1.00      1.00      1.00      1250\n",
      "          30       1.00      1.00      1.00      1250\n",
      "          31       1.00      1.00      1.00      1250\n",
      "\n",
      "    accuracy                           0.98     40000\n",
      "   macro avg       0.98      0.98      0.98     40000\n",
      "weighted avg       0.98      0.98      0.98     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"lead2\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"lead2\")\n",
    "\n",
    "# Try to release memory\n",
    "del new_df\n",
    "gc.collect()\n",
    "\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "X_array, y_array = apply_smote(X_array, y_array)\n",
    "X_train, X_test, y_train, y_test = split_dataset_for_training(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.1\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_train, y_train, X_test, y_test, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_lead2.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba6dabf-e8cc-4899-aa7a-db4ad6b0cd7a",
   "metadata": {},
   "source": [
    "#### Lead III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47199c32-f584-4be7-9a65-47b703645bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n",
      "\n",
      "Generating upsampling through SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Finishing upsampling.\n",
      "\n",
      "Starting dataset split...\n",
      "Finishing dataset split.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1248, 8)           32        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1248, 8)          32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1246, 8)           200       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1246, 8)          32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 623, 8)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 619, 16)           656       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 619, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 615, 16)           1296      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 615, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 307, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4912)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2515456   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                16416     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,536,296\n",
      "Trainable params: 2,535,176\n",
      "Non-trainable params: 1,120\n",
      "_________________________________________________________________\n",
      "\n",
      "Starting training at:  22:28:43\n",
      "Epoch 1/300\n",
      "4500/4500 [==============================] - 320s 71ms/step - loss: 0.3593 - accuracy: 0.9009 - val_loss: 1.9188 - val_accuracy: 0.6568\n",
      "Epoch 2/300\n",
      "4500/4500 [==============================] - 361s 80ms/step - loss: 0.1008 - accuracy: 0.9683 - val_loss: 0.1170 - val_accuracy: 0.9631\n",
      "Epoch 3/300\n",
      "4500/4500 [==============================] - 421s 93ms/step - loss: 0.0550 - accuracy: 0.9826 - val_loss: 0.1293 - val_accuracy: 0.9641\n",
      "Epoch 4/300\n",
      "4500/4500 [==============================] - 533s 118ms/step - loss: 0.0366 - accuracy: 0.9887 - val_loss: 0.1035 - val_accuracy: 0.9756\n",
      "Epoch 5/300\n",
      "4500/4500 [==============================] - 593s 132ms/step - loss: 0.0317 - accuracy: 0.9900 - val_loss: 0.1175 - val_accuracy: 0.9761\n",
      "Epoch 6/300\n",
      "4500/4500 [==============================] - 594s 132ms/step - loss: 0.0254 - accuracy: 0.9923 - val_loss: 0.1250 - val_accuracy: 0.9756\n",
      "Epoch 7/300\n",
      "4500/4500 [==============================] - 572s 127ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 0.1570 - val_accuracy: 0.9663\n",
      "Epoch 8/300\n",
      "4500/4500 [==============================] - 570s 127ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.1197 - val_accuracy: 0.9774\n",
      "Epoch 9/300\n",
      "4500/4500 [==============================] - 569s 126ms/step - loss: 0.0180 - accuracy: 0.9948 - val_loss: 0.1216 - val_accuracy: 0.9769\n",
      "Epoch 10/300\n",
      "4500/4500 [==============================] - 573s 127ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 0.1205 - val_accuracy: 0.9761\n",
      "Epoch 11/300\n",
      "4500/4500 [==============================] - 580s 129ms/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 10.0853 - val_accuracy: 0.3641\n",
      "Epoch 12/300\n",
      "4500/4500 [==============================] - 686s 152ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 1.9974 - val_accuracy: 0.6926\n",
      "Epoch 13/300\n",
      "4500/4500 [==============================] - 588s 131ms/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 2.2163 - val_accuracy: 0.6463\n",
      "Epoch 14/300\n",
      "4500/4500 [==============================] - 588s 131ms/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.1559 - val_accuracy: 0.9791\n",
      "Epoch 15/300\n",
      "4500/4500 [==============================] - 588s 131ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.1624 - val_accuracy: 0.9750\n",
      "Epoch 16/300\n",
      "4500/4500 [==============================] - 594s 132ms/step - loss: 0.0122 - accuracy: 0.9967 - val_loss: 0.2222 - val_accuracy: 0.9596\n",
      "Epoch 17/300\n",
      "4500/4500 [==============================] - 601s 133ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.1507 - val_accuracy: 0.9789\n",
      "Epoch 18/300\n",
      "4500/4500 [==============================] - 599s 133ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.1584 - val_accuracy: 0.9794\n",
      "Epoch 19/300\n",
      "4500/4500 [==============================] - 543s 121ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.1622 - val_accuracy: 0.9804\n",
      "Epoch 20/300\n",
      "4500/4500 [==============================] - 582s 129ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 1.9368 - val_accuracy: 0.6786\n",
      "Epoch 21/300\n",
      "4500/4500 [==============================] - 546s 121ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.1570 - val_accuracy: 0.9778\n",
      "Epoch 22/300\n",
      "4500/4500 [==============================] - 596s 133ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 0.1593 - val_accuracy: 0.9779\n",
      "Epoch 23/300\n",
      "4500/4500 [==============================] - 606s 135ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.1529 - val_accuracy: 0.9797\n",
      "Epoch 24/300\n",
      "4500/4500 [==============================] - 601s 134ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.1481 - val_accuracy: 0.9788\n",
      "Epoch 25/300\n",
      "4500/4500 [==============================] - 652s 145ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.1440 - val_accuracy: 0.9808\n",
      "Epoch 26/300\n",
      "4500/4500 [==============================] - 576s 128ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 6.1494 - val_accuracy: 0.2897\n",
      "Epoch 27/300\n",
      "4500/4500 [==============================] - 568s 126ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.1705 - val_accuracy: 0.9754\n",
      "Epoch 28/300\n",
      "4500/4500 [==============================] - 529s 118ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1864 - val_accuracy: 0.9796\n",
      "Epoch 29/300\n",
      "4500/4500 [==============================] - 552s 123ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.1684 - val_accuracy: 0.9799\n",
      "Epoch 30/300\n",
      "4500/4500 [==============================] - 576s 128ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.2625 - val_accuracy: 0.9586\n",
      "Epoch 31/300\n",
      "4500/4500 [==============================] - 571s 127ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.1955 - val_accuracy: 0.9814\n",
      "Epoch 32/300\n",
      "4500/4500 [==============================] - 595s 132ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.1827 - val_accuracy: 0.9787\n",
      "Epoch 33/300\n",
      "4500/4500 [==============================] - 818s 182ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.2190 - val_accuracy: 0.9800\n",
      "Epoch 34/300\n",
      "4500/4500 [==============================] - 657s 146ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.2145 - val_accuracy: 0.9694\n",
      "Epoch 34: early stopping\n",
      "\n",
      "Time taken for training:  05:28:31\n",
      "\n",
      "Train Accuracy: 99.00 %\n",
      "Test Accuracy: 96.89 %\n",
      "\n",
      "Evaluate other metrics:\n",
      "1250/1250 [==============================] - 45s 35ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.67      1250\n",
      "           1       1.00      0.96      0.98      1250\n",
      "           2       0.90      0.97      0.94      1250\n",
      "           3       0.96      0.91      0.93      1250\n",
      "           4       1.00      0.97      0.98      1250\n",
      "           5       1.00      1.00      1.00      1250\n",
      "           6       0.98      0.92      0.95      1250\n",
      "           7       1.00      0.99      1.00      1250\n",
      "           8       1.00      1.00      1.00      1250\n",
      "           9       0.97      0.98      0.98      1250\n",
      "          10       0.99      1.00      0.99      1250\n",
      "          11       1.00      1.00      1.00      1250\n",
      "          12       1.00      1.00      1.00      1250\n",
      "          13       1.00      1.00      1.00      1250\n",
      "          14       1.00      1.00      1.00      1250\n",
      "          15       1.00      1.00      1.00      1250\n",
      "          16       0.95      0.91      0.93      1250\n",
      "          17       0.84      1.00      0.91      1250\n",
      "          18       1.00      1.00      1.00      1250\n",
      "          19       0.99      0.99      0.99      1250\n",
      "          20       1.00      1.00      1.00      1250\n",
      "          21       1.00      0.98      0.99      1250\n",
      "          22       1.00      1.00      1.00      1250\n",
      "          23       1.00      0.99      0.99      1250\n",
      "          24       0.95      0.91      0.93      1250\n",
      "          25       0.95      0.98      0.97      1250\n",
      "          26       0.89      0.90      0.90      1250\n",
      "          27       1.00      1.00      1.00      1250\n",
      "          28       1.00      1.00      1.00      1250\n",
      "          29       1.00      1.00      1.00      1250\n",
      "          30       1.00      1.00      1.00      1250\n",
      "          31       1.00      1.00      1.00      1250\n",
      "\n",
      "    accuracy                           0.97     40000\n",
      "   macro avg       0.97      0.97      0.97     40000\n",
      "weighted avg       0.97      0.97      0.97     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"lead3\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"lead3\")\n",
    "\n",
    "# Try to release memory\n",
    "del new_df\n",
    "gc.collect()\n",
    "\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "X_array, y_array = apply_smote(X_array, y_array)\n",
    "X_train, X_test, y_train, y_test = split_dataset_for_training(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.1\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_train, y_train, X_test, y_test, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_lead3.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54846ed-31bc-430c-85e0-6d212656e48b",
   "metadata": {},
   "source": [
    "#### aVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e435817e-25fc-4477-a72c-f5c760204725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n",
      "\n",
      "Generating upsampling through SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Finishing upsampling.\n",
      "\n",
      "Starting dataset split...\n",
      "Finishing dataset split.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1248, 8)           32        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1248, 8)          32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1246, 8)           200       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1246, 8)          32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 623, 8)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 619, 16)           656       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 619, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 615, 16)           1296      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 615, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 307, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4912)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2515456   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                16416     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,536,296\n",
      "Trainable params: 2,535,176\n",
      "Non-trainable params: 1,120\n",
      "_________________________________________________________________\n",
      "\n",
      "Starting training at:  04:12:39\n",
      "Epoch 1/300\n",
      "4500/4500 [==============================] - 528s 117ms/step - loss: 0.2812 - accuracy: 0.9218 - val_loss: 0.1188 - val_accuracy: 0.9634\n",
      "Epoch 2/300\n",
      "4500/4500 [==============================] - 537s 119ms/step - loss: 0.0764 - accuracy: 0.9760 - val_loss: 0.0917 - val_accuracy: 0.9720\n",
      "Epoch 3/300\n",
      "4500/4500 [==============================] - 564s 125ms/step - loss: 0.0405 - accuracy: 0.9871 - val_loss: 0.1247 - val_accuracy: 0.9647\n",
      "Epoch 4/300\n",
      "4500/4500 [==============================] - 506s 113ms/step - loss: 0.0284 - accuracy: 0.9910 - val_loss: 0.0931 - val_accuracy: 0.9793\n",
      "Epoch 5/300\n",
      "4500/4500 [==============================] - 516s 115ms/step - loss: 0.0251 - accuracy: 0.9922 - val_loss: 0.0995 - val_accuracy: 0.9774\n",
      "Epoch 6/300\n",
      "4500/4500 [==============================] - 537s 119ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.0884 - val_accuracy: 0.9804\n",
      "Epoch 7/300\n",
      "4500/4500 [==============================] - 568s 126ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.0930 - val_accuracy: 0.9825\n",
      "Epoch 8/300\n",
      "4500/4500 [==============================] - 520s 116ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.1093 - val_accuracy: 0.9796\n",
      "Epoch 9/300\n",
      "4500/4500 [==============================] - 527s 117ms/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: 0.1002 - val_accuracy: 0.9805\n",
      "Epoch 10/300\n",
      "4500/4500 [==============================] - 523s 116ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.1237 - val_accuracy: 0.9726\n",
      "Epoch 11/300\n",
      "4500/4500 [==============================] - 527s 117ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.1091 - val_accuracy: 0.9814\n",
      "Epoch 12/300\n",
      "4500/4500 [==============================] - 522s 116ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.1135 - val_accuracy: 0.9778\n",
      "Epoch 13/300\n",
      "4500/4500 [==============================] - 529s 118ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 0.1082 - val_accuracy: 0.9814\n",
      "Epoch 14/300\n",
      "4500/4500 [==============================] - 531s 118ms/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 0.1177 - val_accuracy: 0.9802\n",
      "Epoch 15/300\n",
      "4500/4500 [==============================] - 540s 120ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.1032 - val_accuracy: 0.9813\n",
      "Epoch 16/300\n",
      "4500/4500 [==============================] - 544s 121ms/step - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.1006 - val_accuracy: 0.9821\n",
      "Epoch 17/300\n",
      "4500/4500 [==============================] - 546s 121ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.1049 - val_accuracy: 0.9834\n",
      "Epoch 18/300\n",
      "4500/4500 [==============================] - 537s 119ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.1173 - val_accuracy: 0.9820\n",
      "Epoch 19/300\n",
      "4500/4500 [==============================] - 548s 122ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.1204 - val_accuracy: 0.9833\n",
      "Epoch 20/300\n",
      "4500/4500 [==============================] - 522s 116ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.1058 - val_accuracy: 0.9825\n",
      "Epoch 21/300\n",
      "4500/4500 [==============================] - 525s 117ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.1189 - val_accuracy: 0.9839\n",
      "Epoch 22/300\n",
      "4500/4500 [==============================] - 530s 118ms/step - loss: 0.0085 - accuracy: 0.9978 - val_loss: 0.1179 - val_accuracy: 0.9814\n",
      "Epoch 23/300\n",
      "4500/4500 [==============================] - 539s 120ms/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.1253 - val_accuracy: 0.9812\n",
      "Epoch 24/300\n",
      "4500/4500 [==============================] - 544s 121ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.2365 - val_accuracy: 0.9505\n",
      "Epoch 25/300\n",
      "4500/4500 [==============================] - 533s 118ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.1293 - val_accuracy: 0.9816\n",
      "Epoch 26/300\n",
      "4500/4500 [==============================] - 542s 120ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.1340 - val_accuracy: 0.9808\n",
      "Epoch 27/300\n",
      "4500/4500 [==============================] - 544s 121ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1397 - val_accuracy: 0.9825\n",
      "Epoch 28/300\n",
      "4500/4500 [==============================] - 539s 120ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1353 - val_accuracy: 0.9835\n",
      "Epoch 29/300\n",
      "4500/4500 [==============================] - 554s 123ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.1378 - val_accuracy: 0.9787\n",
      "Epoch 30/300\n",
      "4500/4500 [==============================] - 556s 124ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1296 - val_accuracy: 0.9828\n",
      "Epoch 31/300\n",
      "4500/4500 [==============================] - 562s 125ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.1488 - val_accuracy: 0.9754\n",
      "Epoch 32/300\n",
      "4500/4500 [==============================] - 566s 126ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.1270 - val_accuracy: 0.9847\n",
      "Epoch 33/300\n",
      "4500/4500 [==============================] - 586s 130ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.2350 - val_accuracy: 0.9561\n",
      "Epoch 34/300\n",
      "4500/4500 [==============================] - 664s 147ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1438 - val_accuracy: 0.9811\n",
      "Epoch 35/300\n",
      "4500/4500 [==============================] - 590s 131ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.1325 - val_accuracy: 0.9819\n",
      "Epoch 36/300\n",
      "4500/4500 [==============================] - 666s 148ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.1375 - val_accuracy: 0.9829\n",
      "Epoch 36: early stopping\n",
      "\n",
      "Time taken for training:  05:31:44\n",
      "\n",
      "Train Accuracy: 99.77 %\n",
      "Test Accuracy: 98.35 %\n",
      "\n",
      "Evaluate other metrics:\n",
      "1250/1250 [==============================] - 40s 31ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81      1250\n",
      "           1       0.98      1.00      0.99      1250\n",
      "           2       0.95      0.98      0.97      1250\n",
      "           3       0.98      0.92      0.95      1250\n",
      "           4       0.99      0.99      0.99      1250\n",
      "           5       1.00      1.00      1.00      1250\n",
      "           6       0.99      0.98      0.99      1250\n",
      "           7       1.00      1.00      1.00      1250\n",
      "           8       1.00      1.00      1.00      1250\n",
      "           9       0.99      0.97      0.98      1250\n",
      "          10       1.00      1.00      1.00      1250\n",
      "          11       1.00      1.00      1.00      1250\n",
      "          12       1.00      1.00      1.00      1250\n",
      "          13       1.00      1.00      1.00      1250\n",
      "          14       1.00      1.00      1.00      1250\n",
      "          15       1.00      1.00      1.00      1250\n",
      "          16       0.97      0.95      0.96      1250\n",
      "          17       1.00      0.99      0.99      1250\n",
      "          18       1.00      1.00      1.00      1250\n",
      "          19       1.00      1.00      1.00      1250\n",
      "          20       1.00      1.00      1.00      1250\n",
      "          21       1.00      1.00      1.00      1250\n",
      "          22       1.00      1.00      1.00      1250\n",
      "          23       1.00      1.00      1.00      1250\n",
      "          24       0.97      0.92      0.95      1250\n",
      "          25       0.98      0.99      0.98      1250\n",
      "          26       0.94      0.93      0.94      1250\n",
      "          27       1.00      1.00      1.00      1250\n",
      "          28       1.00      1.00      1.00      1250\n",
      "          29       1.00      1.00      1.00      1250\n",
      "          30       1.00      1.00      1.00      1250\n",
      "          31       1.00      1.00      1.00      1250\n",
      "\n",
      "    accuracy                           0.98     40000\n",
      "   macro avg       0.98      0.98      0.98     40000\n",
      "weighted avg       0.98      0.98      0.98     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"aVR\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"aVR\")\n",
    "\n",
    "# Try to release memory\n",
    "del new_df\n",
    "gc.collect()\n",
    "\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "X_array, y_array = apply_smote(X_array, y_array)\n",
    "X_train, X_test, y_train, y_test = split_dataset_for_training(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.1\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_train, y_train, X_test, y_test, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_aVR.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d176951-e933-4b9c-99a2-0b8feb53f203",
   "metadata": {},
   "source": [
    "#### aVL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf2df936-284f-40ba-bc77-fac990e58f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n",
      "\n",
      "Generating upsampling through SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Finishing upsampling.\n",
      "\n",
      "Starting dataset split...\n",
      "Finishing dataset split.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1248, 8)           32        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1248, 8)          32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1246, 8)           200       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1246, 8)          32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 623, 8)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 619, 16)           656       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 619, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 615, 16)           1296      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 615, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 307, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4912)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2515456   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                16416     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,536,296\n",
      "Trainable params: 2,535,176\n",
      "Non-trainable params: 1,120\n",
      "_________________________________________________________________\n",
      "\n",
      "Starting training at:  12:03:38\n",
      "Epoch 1/300\n",
      "4500/4500 [==============================] - 350s 77ms/step - loss: 0.3663 - accuracy: 0.8997 - val_loss: 0.1669 - val_accuracy: 0.9488\n",
      "Epoch 2/300\n",
      "4500/4500 [==============================] - 404s 90ms/step - loss: 0.1047 - accuracy: 0.9673 - val_loss: 0.1434 - val_accuracy: 0.9599\n",
      "Epoch 3/300\n",
      "4500/4500 [==============================] - 512s 114ms/step - loss: 0.0595 - accuracy: 0.9818 - val_loss: 7.6178 - val_accuracy: 0.1753\n",
      "Epoch 4/300\n",
      "4500/4500 [==============================] - 552s 123ms/step - loss: 0.0404 - accuracy: 0.9878 - val_loss: 0.1233 - val_accuracy: 0.9749\n",
      "Epoch 5/300\n",
      "4500/4500 [==============================] - 552s 123ms/step - loss: 0.0320 - accuracy: 0.9904 - val_loss: 0.1490 - val_accuracy: 0.9621\n",
      "Epoch 6/300\n",
      "4500/4500 [==============================] - 572s 127ms/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 0.1005 - val_accuracy: 0.9765\n",
      "Epoch 7/300\n",
      "4500/4500 [==============================] - 549s 122ms/step - loss: 0.0248 - accuracy: 0.9930 - val_loss: 12.9523 - val_accuracy: 0.0605\n",
      "Epoch 8/300\n",
      "4500/4500 [==============================] - 558s 124ms/step - loss: 0.0230 - accuracy: 0.9935 - val_loss: 0.2048 - val_accuracy: 0.9483\n",
      "Epoch 9/300\n",
      "4500/4500 [==============================] - 560s 125ms/step - loss: 0.0195 - accuracy: 0.9945 - val_loss: 0.1180 - val_accuracy: 0.9779\n",
      "Epoch 10/300\n",
      "4500/4500 [==============================] - 558s 124ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.8455 - val_accuracy: 0.7810\n",
      "Epoch 11/300\n",
      "4500/4500 [==============================] - 563s 125ms/step - loss: 0.0162 - accuracy: 0.9956 - val_loss: 0.1168 - val_accuracy: 0.9772\n",
      "Epoch 12/300\n",
      "4500/4500 [==============================] - 561s 125ms/step - loss: 0.0147 - accuracy: 0.9960 - val_loss: 0.2273 - val_accuracy: 0.9498\n",
      "Epoch 13/300\n",
      "4500/4500 [==============================] - 567s 126ms/step - loss: 0.0151 - accuracy: 0.9961 - val_loss: 15.4659 - val_accuracy: 0.0864\n",
      "Epoch 14/300\n",
      "4500/4500 [==============================] - 574s 128ms/step - loss: 0.0134 - accuracy: 0.9967 - val_loss: 0.1068 - val_accuracy: 0.9796\n",
      "Epoch 15/300\n",
      "4500/4500 [==============================] - 572s 127ms/step - loss: 0.0132 - accuracy: 0.9966 - val_loss: 0.1986 - val_accuracy: 0.9545\n",
      "Epoch 16/300\n",
      "4500/4500 [==============================] - 579s 129ms/step - loss: 0.0121 - accuracy: 0.9968 - val_loss: 0.1120 - val_accuracy: 0.9796\n",
      "Epoch 17/300\n",
      "4500/4500 [==============================] - 591s 131ms/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.1252 - val_accuracy: 0.9809\n",
      "Epoch 18/300\n",
      "4500/4500 [==============================] - 588s 131ms/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 1.3951 - val_accuracy: 0.7171\n",
      "Epoch 19/300\n",
      "4500/4500 [==============================] - 592s 131ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.1130 - val_accuracy: 0.9753\n",
      "Epoch 20/300\n",
      "4500/4500 [==============================] - 597s 133ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.1346 - val_accuracy: 0.9794\n",
      "Epoch 21/300\n",
      "4500/4500 [==============================] - 588s 131ms/step - loss: 0.0095 - accuracy: 0.9977 - val_loss: 3.9325 - val_accuracy: 0.4357\n",
      "Epoch 22/300\n",
      "4500/4500 [==============================] - 594s 132ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.1229 - val_accuracy: 0.9796\n",
      "Epoch 23/300\n",
      "4500/4500 [==============================] - 599s 133ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.1353 - val_accuracy: 0.9809\n",
      "Epoch 24/300\n",
      "4500/4500 [==============================] - 604s 134ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 8.3097 - val_accuracy: 0.1625\n",
      "Epoch 25/300\n",
      "4500/4500 [==============================] - 613s 136ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.2069 - val_accuracy: 0.9804\n",
      "Epoch 26/300\n",
      "4500/4500 [==============================] - 607s 135ms/step - loss: 0.0091 - accuracy: 0.9978 - val_loss: 8.8783 - val_accuracy: 0.2581\n",
      "Epoch 27/300\n",
      "4500/4500 [==============================] - 605s 134ms/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.1525 - val_accuracy: 0.9805\n",
      "Epoch 28/300\n",
      "4500/4500 [==============================] - 611s 136ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.1127 - val_accuracy: 0.9783\n",
      "Epoch 29/300\n",
      "4500/4500 [==============================] - 620s 138ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 0.2466 - val_accuracy: 0.9449\n",
      "Epoch 30/300\n",
      "4500/4500 [==============================] - 615s 137ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 7.8641 - val_accuracy: 0.2036\n",
      "Epoch 31/300\n",
      "4500/4500 [==============================] - 621s 138ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.7234 - val_accuracy: 0.8518\n",
      "Epoch 32/300\n",
      "4500/4500 [==============================] - 625s 139ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 5.5224 - val_accuracy: 0.3446\n",
      "Epoch 33/300\n",
      "4500/4500 [==============================] - 623s 138ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 1.4553 - val_accuracy: 0.7193\n",
      "Epoch 34/300\n",
      "4500/4500 [==============================] - 643s 143ms/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 0.1174 - val_accuracy: 0.9804\n",
      "Epoch 35/300\n",
      "4500/4500 [==============================] - 638s 142ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 8.3105 - val_accuracy: 0.2072\n",
      "Epoch 36/300\n",
      "4500/4500 [==============================] - 643s 143ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.1137 - val_accuracy: 0.9820\n",
      "Epoch 36: early stopping\n",
      "\n",
      "Time taken for training:  05:49:51\n",
      "\n",
      "Train Accuracy: 99.76 %\n",
      "Test Accuracy: 98.04 %\n",
      "\n",
      "Evaluate other metrics:\n",
      "1250/1250 [==============================] - 58s 46ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.67      0.72      1250\n",
      "           1       0.99      1.00      0.99      1250\n",
      "           2       0.95      0.97      0.96      1250\n",
      "           3       0.93      0.96      0.95      1250\n",
      "           4       0.99      1.00      0.99      1250\n",
      "           5       1.00      1.00      1.00      1250\n",
      "           6       0.99      0.98      0.99      1250\n",
      "           7       1.00      1.00      1.00      1250\n",
      "           8       1.00      1.00      1.00      1250\n",
      "           9       0.99      0.97      0.98      1250\n",
      "          10       1.00      1.00      1.00      1250\n",
      "          11       1.00      1.00      1.00      1250\n",
      "          12       1.00      1.00      1.00      1250\n",
      "          13       1.00      1.00      1.00      1250\n",
      "          14       1.00      1.00      1.00      1250\n",
      "          15       1.00      1.00      1.00      1250\n",
      "          16       0.96      0.96      0.96      1250\n",
      "          17       0.99      1.00      0.99      1250\n",
      "          18       1.00      1.00      1.00      1250\n",
      "          19       0.99      0.99      0.99      1250\n",
      "          20       1.00      1.00      1.00      1250\n",
      "          21       0.99      1.00      1.00      1250\n",
      "          22       0.99      1.00      1.00      1250\n",
      "          23       1.00      1.00      1.00      1250\n",
      "          24       0.92      0.97      0.94      1250\n",
      "          25       0.98      0.99      0.98      1250\n",
      "          26       0.91      0.92      0.91      1250\n",
      "          27       1.00      1.00      1.00      1250\n",
      "          28       1.00      1.00      1.00      1250\n",
      "          29       1.00      1.00      1.00      1250\n",
      "          30       1.00      1.00      1.00      1250\n",
      "          31       1.00      1.00      1.00      1250\n",
      "\n",
      "    accuracy                           0.98     40000\n",
      "   macro avg       0.98      0.98      0.98     40000\n",
      "weighted avg       0.98      0.98      0.98     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"aVL\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"aVL\")\n",
    "\n",
    "# Try to release memory\n",
    "del new_df\n",
    "gc.collect()\n",
    "\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "X_array, y_array = apply_smote(X_array, y_array)\n",
    "X_train, X_test, y_train, y_test = split_dataset_for_training(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.1\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_train, y_train, X_test, y_test, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_aVL.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2208e2-0e65-456a-b89e-12edae1f335e",
   "metadata": {},
   "source": [
    "#### aVF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edc52dc0-fd6e-4fbb-8e35-49f257922c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n",
      "\n",
      "Generating upsampling through SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Finishing upsampling.\n",
      "\n",
      "Starting dataset split...\n",
      "Finishing dataset split.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1248, 8)           32        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1248, 8)          32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1246, 8)           200       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1246, 8)          32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 623, 8)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 619, 16)           656       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 619, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 615, 16)           1296      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 615, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 307, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4912)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2515456   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                16416     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,536,296\n",
      "Trainable params: 2,535,176\n",
      "Non-trainable params: 1,120\n",
      "_________________________________________________________________\n",
      "\n",
      "Starting training at:  21:15:19\n",
      "Epoch 1/300\n",
      "4500/4500 [==============================] - 450s 100ms/step - loss: 0.3540 - accuracy: 0.9039 - val_loss: 0.1583 - val_accuracy: 0.9530\n",
      "Epoch 2/300\n",
      "4500/4500 [==============================] - 556s 124ms/step - loss: 0.0991 - accuracy: 0.9691 - val_loss: 0.0970 - val_accuracy: 0.9704\n",
      "Epoch 3/300\n",
      "4500/4500 [==============================] - 566s 126ms/step - loss: 0.0546 - accuracy: 0.9832 - val_loss: 0.0902 - val_accuracy: 0.9741\n",
      "Epoch 4/300\n",
      "4500/4500 [==============================] - 582s 129ms/step - loss: 0.0386 - accuracy: 0.9876 - val_loss: 0.6368 - val_accuracy: 0.8038\n",
      "Epoch 5/300\n",
      "4500/4500 [==============================] - 564s 125ms/step - loss: 0.0293 - accuracy: 0.9908 - val_loss: 0.0985 - val_accuracy: 0.9759\n",
      "Epoch 6/300\n",
      "4500/4500 [==============================] - 632s 140ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.1068 - val_accuracy: 0.9752\n",
      "Epoch 7/300\n",
      "4500/4500 [==============================] - 616s 137ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.0896 - val_accuracy: 0.9786\n",
      "Epoch 8/300\n",
      "4500/4500 [==============================] - 615s 137ms/step - loss: 0.0190 - accuracy: 0.9943 - val_loss: 0.0881 - val_accuracy: 0.9799\n",
      "Epoch 9/300\n",
      "4500/4500 [==============================] - 584s 130ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.0889 - val_accuracy: 0.9797\n",
      "Epoch 10/300\n",
      "4500/4500 [==============================] - 578s 129ms/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.1078 - val_accuracy: 0.9754\n",
      "Epoch 11/300\n",
      "4500/4500 [==============================] - 596s 132ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.1010 - val_accuracy: 0.9805\n",
      "Epoch 12/300\n",
      "4500/4500 [==============================] - 591s 131ms/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 0.0993 - val_accuracy: 0.9798\n",
      "Epoch 13/300\n",
      "4500/4500 [==============================] - 585s 130ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 0.0952 - val_accuracy: 0.9815\n",
      "Epoch 14/300\n",
      "4500/4500 [==============================] - 584s 130ms/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.1079 - val_accuracy: 0.9811\n",
      "Epoch 15/300\n",
      "4500/4500 [==============================] - 591s 131ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 0.0952 - val_accuracy: 0.9823\n",
      "Epoch 16/300\n",
      "4500/4500 [==============================] - 599s 133ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.4253 - val_accuracy: 0.8944\n",
      "Epoch 17/300\n",
      "4500/4500 [==============================] - 595s 132ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.1114 - val_accuracy: 0.9765\n",
      "Epoch 18/300\n",
      "4500/4500 [==============================] - 708s 157ms/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.1201 - val_accuracy: 0.9806\n",
      "Epoch 19/300\n",
      "4500/4500 [==============================] - 627s 139ms/step - loss: 0.0100 - accuracy: 0.9975 - val_loss: 0.1167 - val_accuracy: 0.9799\n",
      "Epoch 20/300\n",
      "4500/4500 [==============================] - 606s 135ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.1175 - val_accuracy: 0.9800\n",
      "Epoch 21/300\n",
      "4500/4500 [==============================] - 608s 135ms/step - loss: 0.0094 - accuracy: 0.9977 - val_loss: 0.1124 - val_accuracy: 0.9812\n",
      "Epoch 22/300\n",
      "4500/4500 [==============================] - 611s 136ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.1413 - val_accuracy: 0.9764\n",
      "Epoch 23/300\n",
      "4500/4500 [==============================] - 610s 136ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1132 - val_accuracy: 0.9825\n",
      "Epoch 24/300\n",
      "4500/4500 [==============================] - 617s 137ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 3.7143 - val_accuracy: 0.4789\n",
      "Epoch 25/300\n",
      "4500/4500 [==============================] - 621s 138ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.1226 - val_accuracy: 0.9820\n",
      "Epoch 26/300\n",
      "4500/4500 [==============================] - 623s 138ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.7145 - val_accuracy: 0.8541\n",
      "Epoch 27/300\n",
      "4500/4500 [==============================] - 629s 140ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.1364 - val_accuracy: 0.9794\n",
      "Epoch 28/300\n",
      "4500/4500 [==============================] - 630s 140ms/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.1419 - val_accuracy: 0.9796\n",
      "Epoch 29/300\n",
      "4500/4500 [==============================] - 633s 141ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1283 - val_accuracy: 0.9821\n",
      "Epoch 30/300\n",
      "4500/4500 [==============================] - 633s 141ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1351 - val_accuracy: 0.9824\n",
      "Epoch 31/300\n",
      "4500/4500 [==============================] - 700s 156ms/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.1326 - val_accuracy: 0.9821\n",
      "Epoch 32/300\n",
      "4500/4500 [==============================] - 648s 144ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.1273 - val_accuracy: 0.9832\n",
      "Epoch 33/300\n",
      "4500/4500 [==============================] - 644s 143ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.1420 - val_accuracy: 0.9814\n",
      "Epoch 34/300\n",
      "4500/4500 [==============================] - 647s 144ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.1613 - val_accuracy: 0.9789\n",
      "Epoch 35/300\n",
      "4500/4500 [==============================] - 663s 147ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1561 - val_accuracy: 0.9811\n",
      "Epoch 36/300\n",
      "4500/4500 [==============================] - 661s 147ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.1563 - val_accuracy: 0.9776\n",
      "Epoch 37/300\n",
      "4500/4500 [==============================] - 658s 146ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.1899 - val_accuracy: 0.9805\n",
      "Epoch 38/300\n",
      "4500/4500 [==============================] - 663s 147ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.2394 - val_accuracy: 0.9600\n",
      "Epoch 38: early stopping\n",
      "\n",
      "Time taken for training:  06:32:11\n",
      "\n",
      "Train Accuracy: 97.75 %\n",
      "Test Accuracy: 95.85 %\n",
      "\n",
      "Evaluate other metrics:\n",
      "1250/1250 [==============================] - 62s 49ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.81      0.63      1250\n",
      "           1       1.00      0.98      0.99      1250\n",
      "           2       0.85      0.97      0.91      1250\n",
      "           3       0.97      0.87      0.91      1250\n",
      "           4       0.98      0.98      0.98      1250\n",
      "           5       1.00      0.98      0.99      1250\n",
      "           6       1.00      0.78      0.88      1250\n",
      "           7       1.00      0.98      0.99      1250\n",
      "           8       1.00      1.00      1.00      1250\n",
      "           9       0.96      0.96      0.96      1250\n",
      "          10       0.99      1.00      0.99      1250\n",
      "          11       1.00      0.94      0.97      1250\n",
      "          12       1.00      1.00      1.00      1250\n",
      "          13       1.00      0.99      1.00      1250\n",
      "          14       1.00      0.99      1.00      1250\n",
      "          15       1.00      0.99      0.99      1250\n",
      "          16       0.96      0.91      0.93      1250\n",
      "          17       1.00      0.89      0.94      1250\n",
      "          18       1.00      1.00      1.00      1250\n",
      "          19       1.00      0.97      0.98      1250\n",
      "          20       1.00      1.00      1.00      1250\n",
      "          21       0.98      0.99      0.99      1250\n",
      "          22       1.00      1.00      1.00      1250\n",
      "          23       1.00      0.99      1.00      1250\n",
      "          24       0.87      0.94      0.91      1250\n",
      "          25       0.96      0.95      0.96      1250\n",
      "          26       0.96      0.83      0.89      1250\n",
      "          27       1.00      1.00      1.00      1250\n",
      "          28       1.00      1.00      1.00      1250\n",
      "          29       1.00      0.98      0.99      1250\n",
      "          30       1.00      0.99      1.00      1250\n",
      "          31       1.00      1.00      1.00      1250\n",
      "\n",
      "    accuracy                           0.96     40000\n",
      "   macro avg       0.97      0.96      0.96     40000\n",
      "weighted avg       0.97      0.96      0.96     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"aVF\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"aVF\")\n",
    "\n",
    "# Try to release memory\n",
    "del new_df\n",
    "gc.collect()\n",
    "\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "X_array, y_array = apply_smote(X_array, y_array)\n",
    "X_train, X_test, y_train, y_test = split_dataset_for_training(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.1\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_train, y_train, X_test, y_test, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_aVF.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb71dcc-692a-42df-a689-fb840b30eb16",
   "metadata": {},
   "source": [
    "#### V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b835848-0532-4dc4-a4bf-f8512aceeea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n",
      "\n",
      "Generating upsampling through SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Finishing upsampling.\n",
      "\n",
      "Starting dataset split...\n",
      "Finishing dataset split.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1248, 8)           32        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1248, 8)          32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1246, 8)           200       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1246, 8)          32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 623, 8)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 619, 16)           656       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 619, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 615, 16)           1296      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 615, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 307, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4912)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2515456   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                16416     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,536,296\n",
      "Trainable params: 2,535,176\n",
      "Non-trainable params: 1,120\n",
      "_________________________________________________________________\n",
      "\n",
      "Starting training at:  05:59:44\n",
      "Epoch 1/300\n",
      "4500/4500 [==============================] - 735s 162ms/step - loss: 0.3323 - accuracy: 0.9075 - val_loss: 0.1465 - val_accuracy: 0.9544\n",
      "Epoch 2/300\n",
      "4500/4500 [==============================] - 695s 154ms/step - loss: 0.0957 - accuracy: 0.9701 - val_loss: 0.1114 - val_accuracy: 0.9650\n",
      "Epoch 3/300\n",
      "4500/4500 [==============================] - 691s 154ms/step - loss: 0.0504 - accuracy: 0.9839 - val_loss: 2.6526 - val_accuracy: 0.5479\n",
      "Epoch 4/300\n",
      "4500/4500 [==============================] - 693s 154ms/step - loss: 0.0351 - accuracy: 0.9889 - val_loss: 0.1220 - val_accuracy: 0.9665\n",
      "Epoch 5/300\n",
      "4500/4500 [==============================] - 701s 156ms/step - loss: 0.0268 - accuracy: 0.9918 - val_loss: 0.1070 - val_accuracy: 0.9721\n",
      "Epoch 6/300\n",
      "4500/4500 [==============================] - 725s 161ms/step - loss: 0.0232 - accuracy: 0.9928 - val_loss: 0.1073 - val_accuracy: 0.9726\n",
      "Epoch 7/300\n",
      "4500/4500 [==============================] - 708s 157ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.1061 - val_accuracy: 0.9775\n",
      "Epoch 8/300\n",
      "4500/4500 [==============================] - 706s 157ms/step - loss: 0.0185 - accuracy: 0.9946 - val_loss: 0.1062 - val_accuracy: 0.9741\n",
      "Epoch 9/300\n",
      "4500/4500 [==============================] - 714s 159ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.0990 - val_accuracy: 0.9759\n",
      "Epoch 10/300\n",
      "4500/4500 [==============================] - 716s 159ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.1017 - val_accuracy: 0.9791\n",
      "Epoch 11/300\n",
      "4500/4500 [==============================] - 724s 161ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 12.2902 - val_accuracy: 0.1031\n",
      "Epoch 12/300\n",
      "4500/4500 [==============================] - 724s 161ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.1113 - val_accuracy: 0.9804\n",
      "Epoch 13/300\n",
      "4500/4500 [==============================] - 728s 162ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.1015 - val_accuracy: 0.9821\n",
      "Epoch 14/300\n",
      "4500/4500 [==============================] - 732s 163ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.1062 - val_accuracy: 0.9798\n",
      "Epoch 15/300\n",
      "4500/4500 [==============================] - 738s 164ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.1089 - val_accuracy: 0.9803\n",
      "Epoch 16/300\n",
      "4500/4500 [==============================] - 744s 165ms/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.1061 - val_accuracy: 0.9799\n",
      "Epoch 17/300\n",
      "4500/4500 [==============================] - 746s 166ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.1190 - val_accuracy: 0.9801\n",
      "Epoch 18/300\n",
      "4500/4500 [==============================] - 747s 166ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.1062 - val_accuracy: 0.9815\n",
      "Epoch 19/300\n",
      "4500/4500 [==============================] - 748s 166ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.1062 - val_accuracy: 0.9818\n",
      "Epoch 20/300\n",
      "4500/4500 [==============================] - 779s 173ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.1286 - val_accuracy: 0.9801\n",
      "Epoch 21/300\n",
      "4500/4500 [==============================] - 764s 170ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 0.1043 - val_accuracy: 0.9811\n",
      "Epoch 22/300\n",
      "4500/4500 [==============================] - 762s 169ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.1183 - val_accuracy: 0.9803\n",
      "Epoch 23/300\n",
      "4500/4500 [==============================] - 771s 171ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 0.1402 - val_accuracy: 0.9776\n",
      "Epoch 24/300\n",
      "4500/4500 [==============================] - 766s 170ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.1388 - val_accuracy: 0.9768\n",
      "Epoch 25/300\n",
      "4500/4500 [==============================] - 770s 171ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.1325 - val_accuracy: 0.9771\n",
      "Epoch 26/300\n",
      "4500/4500 [==============================] - 772s 172ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.1180 - val_accuracy: 0.9820\n",
      "Epoch 27/300\n",
      "4500/4500 [==============================] - 781s 174ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.1237 - val_accuracy: 0.9791\n",
      "Epoch 28/300\n",
      "4500/4500 [==============================] - 776s 172ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1257 - val_accuracy: 0.9802\n",
      "Epoch 29/300\n",
      "4500/4500 [==============================] - 787s 175ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.1205 - val_accuracy: 0.9793\n",
      "Epoch 30/300\n",
      "4500/4500 [==============================] - 788s 175ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.1229 - val_accuracy: 0.9822\n",
      "Epoch 31/300\n",
      "4500/4500 [==============================] - 794s 176ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1237 - val_accuracy: 0.9816\n",
      "Epoch 32/300\n",
      "4500/4500 [==============================] - 805s 179ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.1546 - val_accuracy: 0.9710\n",
      "Epoch 33/300\n",
      "4500/4500 [==============================] - 794s 177ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.1331 - val_accuracy: 0.9817\n",
      "Epoch 34/300\n",
      "4500/4500 [==============================] - 795s 177ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.1291 - val_accuracy: 0.9808\n",
      "Epoch 35/300\n",
      "4500/4500 [==============================] - 806s 179ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.1314 - val_accuracy: 0.9815\n",
      "Epoch 36/300\n",
      "4500/4500 [==============================] - 810s 180ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.1394 - val_accuracy: 0.9812\n",
      "Epoch 37/300\n",
      "4500/4500 [==============================] - 810s 180ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.1379 - val_accuracy: 0.9799\n",
      "Epoch 38/300\n",
      "4500/4500 [==============================] - 805s 179ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 6.5168 - val_accuracy: 0.3288\n",
      "Epoch 39/300\n",
      "4500/4500 [==============================] - 826s 183ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.1279 - val_accuracy: 0.9806\n",
      "Epoch 39: early stopping\n",
      "\n",
      "Time taken for training:  08:15:16\n",
      "\n",
      "Train Accuracy: 99.76 %\n",
      "Test Accuracy: 97.91 %\n",
      "\n",
      "Evaluate other metrics:\n",
      "1250/1250 [==============================] - 69s 55ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74      1250\n",
      "           1       0.99      0.99      0.99      1250\n",
      "           2       0.95      0.98      0.96      1250\n",
      "           3       0.92      0.94      0.93      1250\n",
      "           4       0.99      0.99      0.99      1250\n",
      "           5       1.00      1.00      1.00      1250\n",
      "           6       0.99      0.98      0.99      1250\n",
      "           7       1.00      1.00      1.00      1250\n",
      "           8       1.00      1.00      1.00      1250\n",
      "           9       0.95      0.96      0.96      1250\n",
      "          10       1.00      1.00      1.00      1250\n",
      "          11       1.00      1.00      1.00      1250\n",
      "          12       1.00      1.00      1.00      1250\n",
      "          13       1.00      1.00      1.00      1250\n",
      "          14       1.00      1.00      1.00      1250\n",
      "          15       1.00      1.00      1.00      1250\n",
      "          16       0.98      0.93      0.95      1250\n",
      "          17       0.99      1.00      0.99      1250\n",
      "          18       1.00      1.00      1.00      1250\n",
      "          19       1.00      1.00      1.00      1250\n",
      "          20       1.00      1.00      1.00      1250\n",
      "          21       1.00      1.00      1.00      1250\n",
      "          22       1.00      1.00      1.00      1250\n",
      "          23       1.00      1.00      1.00      1250\n",
      "          24       0.95      0.94      0.94      1250\n",
      "          25       0.98      0.98      0.98      1250\n",
      "          26       0.88      0.91      0.90      1250\n",
      "          27       1.00      1.00      1.00      1250\n",
      "          28       1.00      1.00      1.00      1250\n",
      "          29       1.00      1.00      1.00      1250\n",
      "          30       1.00      1.00      1.00      1250\n",
      "          31       1.00      1.00      1.00      1250\n",
      "\n",
      "    accuracy                           0.98     40000\n",
      "   macro avg       0.98      0.98      0.98     40000\n",
      "weighted avg       0.98      0.98      0.98     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"V1\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"V1\")\n",
    "\n",
    "# Try to release memory\n",
    "del new_df\n",
    "gc.collect()\n",
    "\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "X_array, y_array = apply_smote(X_array, y_array)\n",
    "X_train, X_test, y_train, y_test = split_dataset_for_training(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.1\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_train, y_train, X_test, y_test, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_V1.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb5ce9b-c8da-4148-9c31-b214e86f06c9",
   "metadata": {},
   "source": [
    "#### V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02823a7a-2fe6-46ff-a389-9cda41b46cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n",
      "\n",
      "Generating upsampling through SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Finishing upsampling.\n",
      "\n",
      "Starting dataset split...\n",
      "Finishing dataset split.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1248, 8)           32        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1248, 8)          32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1246, 8)           200       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1246, 8)          32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 623, 8)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 619, 16)           656       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 619, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 615, 16)           1296      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 615, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 307, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4912)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2515456   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                16416     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,536,296\n",
      "Trainable params: 2,535,176\n",
      "Non-trainable params: 1,120\n",
      "_________________________________________________________________\n",
      "\n",
      "Starting training at:  22:04:58\n",
      "Epoch 1/300\n",
      "4500/4500 [==============================] - 799s 177ms/step - loss: 0.3222 - accuracy: 0.9111 - val_loss: 0.2647 - val_accuracy: 0.9168\n",
      "Epoch 2/300\n",
      "4500/4500 [==============================] - 677s 150ms/step - loss: 0.0911 - accuracy: 0.9717 - val_loss: 0.1606 - val_accuracy: 0.9709\n",
      "Epoch 3/300\n",
      "4500/4500 [==============================] - 611s 136ms/step - loss: 0.0481 - accuracy: 0.9848 - val_loss: 0.1317 - val_accuracy: 0.9748\n",
      "Epoch 4/300\n",
      "4500/4500 [==============================] - 575s 128ms/step - loss: 0.0332 - accuracy: 0.9895 - val_loss: 0.1992 - val_accuracy: 0.9699\n",
      "Epoch 5/300\n",
      "4500/4500 [==============================] - 571s 127ms/step - loss: 0.0258 - accuracy: 0.9920 - val_loss: 0.1025 - val_accuracy: 0.9767\n",
      "Epoch 6/300\n",
      "4500/4500 [==============================] - 581s 129ms/step - loss: 0.0220 - accuracy: 0.9935 - val_loss: 0.1431 - val_accuracy: 0.9757\n",
      "Epoch 7/300\n",
      "4500/4500 [==============================] - 578s 128ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.0919 - val_accuracy: 0.9778\n",
      "Epoch 8/300\n",
      "4500/4500 [==============================] - 582s 129ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.9270 - val_accuracy: 0.8652\n",
      "Epoch 9/300\n",
      "4500/4500 [==============================] - 585s 130ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.4113 - val_accuracy: 0.9214\n",
      "Epoch 10/300\n",
      "4500/4500 [==============================] - 585s 130ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.1946 - val_accuracy: 0.9761\n",
      "Epoch 11/300\n",
      "4500/4500 [==============================] - 588s 131ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.1978 - val_accuracy: 0.9760\n",
      "Epoch 12/300\n",
      "4500/4500 [==============================] - 661s 147ms/step - loss: 0.0125 - accuracy: 0.9967 - val_loss: 0.1979 - val_accuracy: 0.9766\n",
      "Epoch 13/300\n",
      "4500/4500 [==============================] - 813s 181ms/step - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.1748 - val_accuracy: 0.9789\n",
      "Epoch 14/300\n",
      "4500/4500 [==============================] - 710s 158ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.1737 - val_accuracy: 0.9803\n",
      "Epoch 15/300\n",
      "4500/4500 [==============================] - 627s 139ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.2339 - val_accuracy: 0.9682\n",
      "Epoch 16/300\n",
      "4500/4500 [==============================] - 608s 135ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.1783 - val_accuracy: 0.9791\n",
      "Epoch 17/300\n",
      "4500/4500 [==============================] - 620s 138ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1494 - val_accuracy: 0.9761\n",
      "Epoch 18/300\n",
      "4500/4500 [==============================] - 609s 135ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.1642 - val_accuracy: 0.9790\n",
      "Epoch 19/300\n",
      "4500/4500 [==============================] - 617s 137ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.2063 - val_accuracy: 0.9792\n",
      "Epoch 20/300\n",
      "4500/4500 [==============================] - 622s 138ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.2505 - val_accuracy: 0.9789\n",
      "Epoch 21/300\n",
      "4500/4500 [==============================] - 620s 138ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.2131 - val_accuracy: 0.9760\n",
      "Epoch 22/300\n",
      "4500/4500 [==============================] - 627s 139ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.1944 - val_accuracy: 0.9788\n",
      "Epoch 23/300\n",
      "4500/4500 [==============================] - 632s 140ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.2146 - val_accuracy: 0.9806\n",
      "Epoch 24/300\n",
      "4500/4500 [==============================] - 662s 147ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.2216 - val_accuracy: 0.9806\n",
      "Epoch 25/300\n",
      "4500/4500 [==============================] - 663s 147ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.2137 - val_accuracy: 0.9801\n",
      "Epoch 26/300\n",
      "4500/4500 [==============================] - 647s 144ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.2580 - val_accuracy: 0.9814\n",
      "Epoch 27/300\n",
      "4500/4500 [==============================] - 646s 144ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.2561 - val_accuracy: 0.9811\n",
      "Epoch 28/300\n",
      "4500/4500 [==============================] - 645s 143ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.2472 - val_accuracy: 0.9812\n",
      "Epoch 29/300\n",
      "4500/4500 [==============================] - 656s 146ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.2137 - val_accuracy: 0.9796\n",
      "Epoch 30/300\n",
      "4500/4500 [==============================] - 657s 146ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.2457 - val_accuracy: 0.9806\n",
      "Epoch 31/300\n",
      "4500/4500 [==============================] - 656s 146ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.2248 - val_accuracy: 0.9809\n",
      "Epoch 32/300\n",
      "4500/4500 [==============================] - 664s 148ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.2423 - val_accuracy: 0.9801\n",
      "Epoch 33/300\n",
      "4500/4500 [==============================] - 678s 151ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.1527 - val_accuracy: 0.9812\n",
      "Epoch 34/300\n",
      "4500/4500 [==============================] - 671s 149ms/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.1572 - val_accuracy: 0.9806\n",
      "Epoch 35/300\n",
      "4500/4500 [==============================] - 672s 149ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.1839 - val_accuracy: 0.9741\n",
      "Epoch 36/300\n",
      "4500/4500 [==============================] - 679s 151ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.2486 - val_accuracy: 0.9807\n",
      "Epoch 37/300\n",
      "4500/4500 [==============================] - 694s 154ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.2864 - val_accuracy: 0.9799\n",
      "Epoch 37: early stopping\n",
      "\n",
      "Time taken for training:  06:40:34\n",
      "\n",
      "Train Accuracy: 99.77 %\n",
      "Test Accuracy: 98.03 %\n",
      "\n",
      "Evaluate other metrics:\n",
      "1250/1250 [==============================] - 64s 51ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1250\n",
      "           1       0.98      1.00      0.99      1250\n",
      "           2       0.95      0.98      0.97      1250\n",
      "           3       0.96      0.94      0.95      1250\n",
      "           4       0.99      0.99      0.99      1250\n",
      "           5       1.00      1.00      1.00      1250\n",
      "           6       0.98      0.97      0.98      1250\n",
      "           7       1.00      1.00      1.00      1250\n",
      "           8       1.00      1.00      1.00      1250\n",
      "           9       0.97      0.97      0.97      1250\n",
      "          10       1.00      1.00      1.00      1250\n",
      "          11       1.00      1.00      1.00      1250\n",
      "          12       1.00      1.00      1.00      1250\n",
      "          13       1.00      1.00      1.00      1250\n",
      "          14       1.00      1.00      1.00      1250\n",
      "          15       1.00      1.00      1.00      1250\n",
      "          16       0.96      0.96      0.96      1250\n",
      "          17       0.98      1.00      0.99      1250\n",
      "          18       1.00      1.00      1.00      1250\n",
      "          19       1.00      1.00      1.00      1250\n",
      "          20       1.00      1.00      1.00      1250\n",
      "          21       1.00      1.00      1.00      1250\n",
      "          22       1.00      1.00      1.00      1250\n",
      "          23       1.00      1.00      1.00      1250\n",
      "          24       0.91      0.96      0.93      1250\n",
      "          25       0.98      0.98      0.98      1250\n",
      "          26       0.93      0.91      0.92      1250\n",
      "          27       1.00      1.00      1.00      1250\n",
      "          28       1.00      1.00      1.00      1250\n",
      "          29       1.00      1.00      1.00      1250\n",
      "          30       1.00      1.00      1.00      1250\n",
      "          31       1.00      1.00      1.00      1250\n",
      "\n",
      "    accuracy                           0.98     40000\n",
      "   macro avg       0.98      0.98      0.98     40000\n",
      "weighted avg       0.98      0.98      0.98     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"V2\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"V2\")\n",
    "\n",
    "# Try to release memory\n",
    "del new_df\n",
    "gc.collect()\n",
    "\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "X_array, y_array = apply_smote(X_array, y_array)\n",
    "X_train, X_test, y_train, y_test = split_dataset_for_training(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.1\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_train, y_train, X_test, y_test, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_V2.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94d85e3-d80b-4382-a810-5f7459e324e3",
   "metadata": {},
   "source": [
    "#### V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acf30b68-13b9-4d3e-bb39-b83a0f5c003f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n",
      "\n",
      "Generating upsampling through SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Finishing upsampling.\n",
      "\n",
      "Starting dataset split...\n",
      "Finishing dataset split.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1248, 8)           32        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1248, 8)          32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1246, 8)           200       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1246, 8)          32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 623, 8)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 619, 16)           656       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 619, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 615, 16)           1296      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 615, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 307, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4912)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2515456   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                16416     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,536,296\n",
      "Trainable params: 2,535,176\n",
      "Non-trainable params: 1,120\n",
      "_________________________________________________________________\n",
      "\n",
      "Starting training at:  07:24:55\n",
      "Epoch 1/300\n",
      "4500/4500 [==============================] - 604s 133ms/step - loss: 0.3112 - accuracy: 0.9144 - val_loss: 0.3042 - val_accuracy: 0.9334\n",
      "Epoch 2/300\n",
      "4500/4500 [==============================] - 578s 128ms/step - loss: 0.0893 - accuracy: 0.9716 - val_loss: 0.1557 - val_accuracy: 0.9706\n",
      "Epoch 3/300\n",
      "4500/4500 [==============================] - 588s 131ms/step - loss: 0.0451 - accuracy: 0.9855 - val_loss: 0.1865 - val_accuracy: 0.9716\n",
      "Epoch 4/300\n",
      "4500/4500 [==============================] - 583s 130ms/step - loss: 0.0342 - accuracy: 0.9894 - val_loss: 0.1611 - val_accuracy: 0.9750\n",
      "Epoch 5/300\n",
      "4500/4500 [==============================] - 591s 131ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.1971 - val_accuracy: 0.9746\n",
      "Epoch 6/300\n",
      "4500/4500 [==============================] - 596s 132ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.2325 - val_accuracy: 0.9765\n",
      "Epoch 7/300\n",
      "4500/4500 [==============================] - 592s 131ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.2085 - val_accuracy: 0.9749\n",
      "Epoch 8/300\n",
      "4500/4500 [==============================] - 600s 133ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.2547 - val_accuracy: 0.9746\n",
      "Epoch 9/300\n",
      "4500/4500 [==============================] - 602s 134ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.2166 - val_accuracy: 0.9770\n",
      "Epoch 10/300\n",
      "4500/4500 [==============================] - 640s 142ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.2225 - val_accuracy: 0.9793\n",
      "Epoch 11/300\n",
      "4500/4500 [==============================] - 599s 133ms/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.2380 - val_accuracy: 0.9771\n",
      "Epoch 12/300\n",
      "4500/4500 [==============================] - 604s 134ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.2385 - val_accuracy: 0.9776\n",
      "Epoch 13/300\n",
      "4500/4500 [==============================] - 610s 135ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.2584 - val_accuracy: 0.9751\n",
      "Epoch 14/300\n",
      "4500/4500 [==============================] - 612s 136ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 0.2474 - val_accuracy: 0.9751\n",
      "Epoch 15/300\n",
      "4500/4500 [==============================] - 653s 145ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.2690 - val_accuracy: 0.9779\n",
      "Epoch 16/300\n",
      "4500/4500 [==============================] - 628s 140ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.2506 - val_accuracy: 0.9777\n",
      "Epoch 17/300\n",
      "4500/4500 [==============================] - 617s 137ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.2474 - val_accuracy: 0.9797\n",
      "Epoch 18/300\n",
      "4500/4500 [==============================] - 625s 139ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.2730 - val_accuracy: 0.9798\n",
      "Epoch 19/300\n",
      "4500/4500 [==============================] - 630s 140ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.2503 - val_accuracy: 0.9772\n",
      "Epoch 20/300\n",
      "4500/4500 [==============================] - 626s 139ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.2924 - val_accuracy: 0.9785\n",
      "Epoch 21/300\n",
      "4500/4500 [==============================] - 635s 141ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.3007 - val_accuracy: 0.9786\n",
      "Epoch 22/300\n",
      "4500/4500 [==============================] - 636s 141ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.2877 - val_accuracy: 0.9789\n",
      "Epoch 23/300\n",
      "4500/4500 [==============================] - 642s 143ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.2657 - val_accuracy: 0.9783\n",
      "Epoch 24/300\n",
      "4500/4500 [==============================] - 644s 143ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.2694 - val_accuracy: 0.9808\n",
      "Epoch 25/300\n",
      "4500/4500 [==============================] - 647s 144ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.3227 - val_accuracy: 0.9814\n",
      "Epoch 26/300\n",
      "4500/4500 [==============================] - 653s 145ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.2895 - val_accuracy: 0.9815\n",
      "Epoch 27/300\n",
      "4500/4500 [==============================] - 653s 145ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.3102 - val_accuracy: 0.9781\n",
      "Epoch 28/300\n",
      "4500/4500 [==============================] - 660s 147ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.3682 - val_accuracy: 0.9794\n",
      "Epoch 29/300\n",
      "4500/4500 [==============================] - 668s 148ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.3238 - val_accuracy: 0.9806\n",
      "Epoch 30/300\n",
      "4500/4500 [==============================] - 672s 149ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.3418 - val_accuracy: 0.9816\n",
      "Epoch 31/300\n",
      "4500/4500 [==============================] - 669s 149ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.3396 - val_accuracy: 0.9811\n",
      "Epoch 32/300\n",
      "4500/4500 [==============================] - 680s 151ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.2725 - val_accuracy: 0.9826\n",
      "Epoch 32: early stopping\n",
      "\n",
      "Time taken for training:  05:37:19\n",
      "\n",
      "Train Accuracy: 99.78 %\n",
      "Test Accuracy: 98.03 %\n",
      "\n",
      "Evaluate other metrics:\n",
      "1250/1250 [==============================] - 61s 49ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      1250\n",
      "           1       0.99      1.00      0.99      1250\n",
      "           2       0.94      0.99      0.96      1250\n",
      "           3       0.98      0.92      0.95      1250\n",
      "           4       0.98      0.99      0.98      1250\n",
      "           5       1.00      1.00      1.00      1250\n",
      "           6       0.97      0.98      0.98      1250\n",
      "           7       1.00      1.00      1.00      1250\n",
      "           8       1.00      1.00      1.00      1250\n",
      "           9       0.98      0.97      0.97      1250\n",
      "          10       1.00      1.00      1.00      1250\n",
      "          11       1.00      1.00      1.00      1250\n",
      "          12       1.00      1.00      1.00      1250\n",
      "          13       1.00      1.00      1.00      1250\n",
      "          14       1.00      1.00      1.00      1250\n",
      "          15       1.00      1.00      1.00      1250\n",
      "          16       0.98      0.95      0.96      1250\n",
      "          17       0.99      0.99      0.99      1250\n",
      "          18       1.00      1.00      1.00      1250\n",
      "          19       1.00      1.00      1.00      1250\n",
      "          20       1.00      1.00      1.00      1250\n",
      "          21       0.98      1.00      0.99      1250\n",
      "          22       1.00      1.00      1.00      1250\n",
      "          23       1.00      1.00      1.00      1250\n",
      "          24       0.93      0.93      0.93      1250\n",
      "          25       0.98      0.98      0.98      1250\n",
      "          26       0.94      0.90      0.92      1250\n",
      "          27       1.00      1.00      1.00      1250\n",
      "          28       1.00      1.00      1.00      1250\n",
      "          29       1.00      1.00      1.00      1250\n",
      "          30       1.00      1.00      1.00      1250\n",
      "          31       1.00      1.00      1.00      1250\n",
      "\n",
      "    accuracy                           0.98     40000\n",
      "   macro avg       0.98      0.98      0.98     40000\n",
      "weighted avg       0.98      0.98      0.98     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"V3\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"V3\")\n",
    "\n",
    "# Try to release memory\n",
    "del new_df\n",
    "gc.collect()\n",
    "\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "X_array, y_array = apply_smote(X_array, y_array)\n",
    "X_train, X_test, y_train, y_test = split_dataset_for_training(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.1\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_train, y_train, X_test, y_test, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_V3.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5c04d8-ecce-4f37-a589-6241f436d375",
   "metadata": {},
   "source": [
    "#### V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46d5bb04-8192-4d41-a718-524175becc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n",
      "\n",
      "Generating upsampling through SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Finishing upsampling.\n",
      "\n",
      "Starting dataset split...\n",
      "Finishing dataset split.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1248, 8)           32        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1248, 8)          32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1246, 8)           200       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1246, 8)          32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 623, 8)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 619, 16)           656       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 619, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 615, 16)           1296      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 615, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 307, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4912)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2515456   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                16416     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,536,296\n",
      "Trainable params: 2,535,176\n",
      "Non-trainable params: 1,120\n",
      "_________________________________________________________________\n",
      "\n",
      "Starting training at:  16:28:35\n",
      "Epoch 1/300\n",
      "4500/4500 [==============================] - 588s 130ms/step - loss: 0.2977 - accuracy: 0.9186 - val_loss: 0.5600 - val_accuracy: 0.8246\n",
      "Epoch 2/300\n",
      "4500/4500 [==============================] - 600s 133ms/step - loss: 0.0889 - accuracy: 0.9726 - val_loss: 0.1201 - val_accuracy: 0.9675\n",
      "Epoch 3/300\n",
      "4500/4500 [==============================] - 578s 128ms/step - loss: 0.0488 - accuracy: 0.9847 - val_loss: 0.4582 - val_accuracy: 0.8719\n",
      "Epoch 4/300\n",
      "4500/4500 [==============================] - 582s 129ms/step - loss: 0.0325 - accuracy: 0.9898 - val_loss: 0.1437 - val_accuracy: 0.9636\n",
      "Epoch 5/300\n",
      "4500/4500 [==============================] - 582s 129ms/step - loss: 0.0254 - accuracy: 0.9923 - val_loss: 0.1191 - val_accuracy: 0.9733\n",
      "Epoch 6/300\n",
      "4500/4500 [==============================] - 588s 131ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.1902 - val_accuracy: 0.9544\n",
      "Epoch 7/300\n",
      "4500/4500 [==============================] - 586s 130ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 0.2095 - val_accuracy: 0.9490\n",
      "Epoch 8/300\n",
      "4500/4500 [==============================] - 592s 132ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.7074 - val_accuracy: 0.8530\n",
      "Epoch 9/300\n",
      "4500/4500 [==============================] - 597s 133ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.2767 - val_accuracy: 0.9324\n",
      "Epoch 10/300\n",
      "4500/4500 [==============================] - 598s 133ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.2065 - val_accuracy: 0.9523\n",
      "Epoch 11/300\n",
      "4500/4500 [==============================] - 595s 132ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 0.1577 - val_accuracy: 0.9683\n",
      "Epoch 12/300\n",
      "4500/4500 [==============================] - 603s 134ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.6586 - val_accuracy: 0.8721\n",
      "Epoch 13/300\n",
      "4500/4500 [==============================] - 612s 136ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.1082 - val_accuracy: 0.9799\n",
      "Epoch 14/300\n",
      "4500/4500 [==============================] - 600s 133ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.5334 - val_accuracy: 0.8741\n",
      "Epoch 15/300\n",
      "4500/4500 [==============================] - 620s 138ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.5525 - val_accuracy: 0.8848\n",
      "Epoch 16/300\n",
      "4500/4500 [==============================] - 603s 134ms/step - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.1360 - val_accuracy: 0.9761\n",
      "Epoch 17/300\n",
      "4500/4500 [==============================] - 594s 132ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1286 - val_accuracy: 0.9764\n",
      "Epoch 18/300\n",
      "4500/4500 [==============================] - 599s 133ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.1251 - val_accuracy: 0.9808\n",
      "Epoch 19/300\n",
      "4500/4500 [==============================] - 603s 134ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.1368 - val_accuracy: 0.9790\n",
      "Epoch 20/300\n",
      "4500/4500 [==============================] - 603s 134ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.1758 - val_accuracy: 0.9696\n",
      "Epoch 21/300\n",
      "4500/4500 [==============================] - 612s 136ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.1955 - val_accuracy: 0.9660\n",
      "Epoch 22/300\n",
      "4500/4500 [==============================] - 478s 106ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.1330 - val_accuracy: 0.9780\n",
      "Epoch 23/300\n",
      "4500/4500 [==============================] - 401s 89ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 1.2778 - val_accuracy: 0.7793\n",
      "Epoch 24/300\n",
      "4500/4500 [==============================] - 373s 83ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.1745 - val_accuracy: 0.9731\n",
      "Epoch 25/300\n",
      "4500/4500 [==============================] - 375s 83ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1468 - val_accuracy: 0.9769\n",
      "Epoch 26/300\n",
      "4500/4500 [==============================] - 366s 81ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.1164 - val_accuracy: 0.9817\n",
      "Epoch 27/300\n",
      "4500/4500 [==============================] - 359s 80ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.1370 - val_accuracy: 0.9813\n",
      "Epoch 28/300\n",
      "4500/4500 [==============================] - 364s 81ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1466 - val_accuracy: 0.9829\n",
      "Epoch 29/300\n",
      "4500/4500 [==============================] - 365s 81ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.2909 - val_accuracy: 0.9556\n",
      "Epoch 30/300\n",
      "4500/4500 [==============================] - 355s 79ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.1690 - val_accuracy: 0.9762\n",
      "Epoch 31/300\n",
      "4500/4500 [==============================] - 376s 84ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.1494 - val_accuracy: 0.9808\n",
      "Epoch 32/300\n",
      "4500/4500 [==============================] - 370s 82ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.4098 - val_accuracy: 0.9250\n",
      "Epoch 33/300\n",
      "4500/4500 [==============================] - 359s 80ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.1388 - val_accuracy: 0.9809\n",
      "Epoch 34/300\n",
      "4500/4500 [==============================] - 353s 78ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 1.0105 - val_accuracy: 0.8485\n",
      "Epoch 35/300\n",
      "4500/4500 [==============================] - 348s 77ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.1515 - val_accuracy: 0.9807\n",
      "Epoch 36/300\n",
      "4500/4500 [==============================] - 362s 80ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.6599 - val_accuracy: 0.8925\n",
      "Epoch 37/300\n",
      "4500/4500 [==============================] - 358s 79ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.1701 - val_accuracy: 0.9802\n",
      "Epoch 38/300\n",
      "4500/4500 [==============================] - 350s 78ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.2617 - val_accuracy: 0.9636\n",
      "Epoch 39/300\n",
      "4500/4500 [==============================] - 332s 74ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.7357 - val_accuracy: 0.8911\n",
      "Epoch 40/300\n",
      "4500/4500 [==============================] - 351s 78ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.1564 - val_accuracy: 0.9736\n",
      "Epoch 41/300\n",
      "4500/4500 [==============================] - 400s 89ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.1480 - val_accuracy: 0.9814\n",
      "Epoch 42/300\n",
      "4500/4500 [==============================] - 529s 118ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.6101 - val_accuracy: 0.8939\n",
      "Epoch 43/300\n",
      "4500/4500 [==============================] - 793s 176ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.2785 - val_accuracy: 0.9526\n",
      "Epoch 43: early stopping\n",
      "\n",
      "Time taken for training:  05:59:56\n",
      "\n",
      "Train Accuracy: 96.89 %\n",
      "Test Accuracy: 95.09 %\n",
      "\n",
      "Evaluate other metrics:\n",
      "1250/1250 [==============================] - 65s 50ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.92      0.63      1250\n",
      "           1       1.00      0.96      0.98      1250\n",
      "           2       0.72      0.99      0.83      1250\n",
      "           3       0.92      0.89      0.91      1250\n",
      "           4       0.99      0.96      0.98      1250\n",
      "           5       1.00      0.98      0.99      1250\n",
      "           6       1.00      0.92      0.95      1250\n",
      "           7       1.00      0.95      0.98      1250\n",
      "           8       1.00      1.00      1.00      1250\n",
      "           9       0.98      0.94      0.96      1250\n",
      "          10       1.00      0.99      1.00      1250\n",
      "          11       1.00      0.99      0.99      1250\n",
      "          12       1.00      1.00      1.00      1250\n",
      "          13       1.00      0.99      0.99      1250\n",
      "          14       1.00      0.97      0.98      1250\n",
      "          15       1.00      0.96      0.98      1250\n",
      "          16       0.97      0.91      0.94      1250\n",
      "          17       1.00      0.91      0.95      1250\n",
      "          18       1.00      0.96      0.98      1250\n",
      "          19       1.00      0.95      0.97      1250\n",
      "          20       1.00      0.99      0.99      1250\n",
      "          21       1.00      0.95      0.97      1250\n",
      "          22       1.00      1.00      1.00      1250\n",
      "          23       1.00      1.00      1.00      1250\n",
      "          24       0.98      0.84      0.90      1250\n",
      "          25       1.00      0.89      0.94      1250\n",
      "          26       0.99      0.77      0.87      1250\n",
      "          27       1.00      1.00      1.00      1250\n",
      "          28       1.00      0.87      0.93      1250\n",
      "          29       1.00      0.99      1.00      1250\n",
      "          30       1.00      0.98      0.99      1250\n",
      "          31       1.00      1.00      1.00      1250\n",
      "\n",
      "    accuracy                           0.95     40000\n",
      "   macro avg       0.97      0.95      0.96     40000\n",
      "weighted avg       0.97      0.95      0.96     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"V4\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"V4\")\n",
    "\n",
    "# Try to release memory\n",
    "del new_df\n",
    "gc.collect()\n",
    "\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "X_array, y_array = apply_smote(X_array, y_array)\n",
    "X_train, X_test, y_train, y_test = split_dataset_for_training(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.1\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_train, y_train, X_test, y_test, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_V4.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4393b94-adff-4999-bc4a-f800ed79665e",
   "metadata": {},
   "source": [
    "#### V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53694cdc-fc20-4759-9fc5-94ed8992946f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n",
      "\n",
      "Generating upsampling through SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Finishing upsampling.\n",
      "\n",
      "Starting dataset split...\n",
      "Finishing dataset split.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1248, 8)           32        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1248, 8)          32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1246, 8)           200       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1246, 8)          32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 623, 8)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 619, 16)           656       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 619, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 615, 16)           1296      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 615, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 307, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4912)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2515456   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                16416     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,536,296\n",
      "Trainable params: 2,535,176\n",
      "Non-trainable params: 1,120\n",
      "_________________________________________________________________\n",
      "\n",
      "Starting training at:  01:26:18\n",
      "Epoch 1/300\n",
      "4500/4500 [==============================] - 593s 131ms/step - loss: 0.2901 - accuracy: 0.9211 - val_loss: 0.2453 - val_accuracy: 0.9280\n",
      "Epoch 2/300\n",
      "4500/4500 [==============================] - 573s 127ms/step - loss: 0.0826 - accuracy: 0.9746 - val_loss: 1.0403 - val_accuracy: 0.7559\n",
      "Epoch 3/300\n",
      "4500/4500 [==============================] - 573s 127ms/step - loss: 0.0438 - accuracy: 0.9864 - val_loss: 0.1547 - val_accuracy: 0.9582\n",
      "Epoch 4/300\n",
      "4500/4500 [==============================] - 576s 128ms/step - loss: 0.0298 - accuracy: 0.9906 - val_loss: 1.2697 - val_accuracy: 0.7555\n",
      "Epoch 5/300\n",
      "4500/4500 [==============================] - 581s 129ms/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 0.1640 - val_accuracy: 0.9618\n",
      "Epoch 6/300\n",
      "4500/4500 [==============================] - 649s 144ms/step - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.1369 - val_accuracy: 0.9698\n",
      "Epoch 7/300\n",
      "4500/4500 [==============================] - 585s 130ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.2955 - val_accuracy: 0.9340\n",
      "Epoch 8/300\n",
      "4500/4500 [==============================] - 591s 131ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 8.4954 - val_accuracy: 0.1611\n",
      "Epoch 9/300\n",
      "4500/4500 [==============================] - 684s 152ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.4417 - val_accuracy: 0.8942\n",
      "Epoch 10/300\n",
      "4500/4500 [==============================] - 714s 159ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 6.0673 - val_accuracy: 0.3758\n",
      "Epoch 11/300\n",
      "4500/4500 [==============================] - 732s 163ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 3.6303 - val_accuracy: 0.5199\n",
      "Epoch 12/300\n",
      "4500/4500 [==============================] - 742s 165ms/step - loss: 0.0105 - accuracy: 0.9973 - val_loss: 0.1307 - val_accuracy: 0.9756\n",
      "Epoch 13/300\n",
      "4500/4500 [==============================] - 768s 171ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.5056 - val_accuracy: 0.9158\n",
      "Epoch 14/300\n",
      "4500/4500 [==============================] - 750s 167ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 1.4050 - val_accuracy: 0.7755\n",
      "Epoch 15/300\n",
      "4500/4500 [==============================] - 763s 170ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.1678 - val_accuracy: 0.9753\n",
      "Epoch 16/300\n",
      "4500/4500 [==============================] - 765s 170ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 6.7082 - val_accuracy: 0.3889\n",
      "Epoch 17/300\n",
      "4500/4500 [==============================] - 764s 170ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 11.1634 - val_accuracy: 0.2022\n",
      "Epoch 18/300\n",
      "4500/4500 [==============================] - 763s 169ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.1360 - val_accuracy: 0.9777\n",
      "Epoch 19/300\n",
      "4500/4500 [==============================] - 769s 171ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.6438 - val_accuracy: 0.8751\n",
      "Epoch 20/300\n",
      "4500/4500 [==============================] - 765s 170ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 17.5835 - val_accuracy: 0.1010\n",
      "Epoch 21/300\n",
      "4500/4500 [==============================] - 766s 170ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 4.1693 - val_accuracy: 0.4832\n",
      "Epoch 22/300\n",
      "4500/4500 [==============================] - 774s 172ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 1.5901 - val_accuracy: 0.7447\n",
      "Epoch 23/300\n",
      "4500/4500 [==============================] - 773s 172ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 4.9563 - val_accuracy: 0.5656\n",
      "Epoch 24/300\n",
      "4500/4500 [==============================] - 784s 174ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 5.4750 - val_accuracy: 0.4319\n",
      "Epoch 25/300\n",
      "4500/4500 [==============================] - 775s 172ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.1509 - val_accuracy: 0.9783\n",
      "Epoch 26/300\n",
      "4500/4500 [==============================] - 785s 174ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1516 - val_accuracy: 0.9783\n",
      "Epoch 27/300\n",
      "4500/4500 [==============================] - 784s 174ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1492 - val_accuracy: 0.9788\n",
      "Epoch 28/300\n",
      "4500/4500 [==============================] - 824s 183ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.9628 - val_accuracy: 0.8578\n",
      "Epoch 29/300\n",
      "4500/4500 [==============================] - 787s 175ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 4.5769 - val_accuracy: 0.3970\n",
      "Epoch 30/300\n",
      "4500/4500 [==============================] - 786s 175ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 3.4405 - val_accuracy: 0.5374\n",
      "Epoch 31/300\n",
      "4500/4500 [==============================] - 800s 178ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.2427 - val_accuracy: 0.9628\n",
      "Epoch 32/300\n",
      "4500/4500 [==============================] - 799s 178ms/step - loss: 0.0125 - accuracy: 0.9970 - val_loss: 0.1334 - val_accuracy: 0.9819\n",
      "Epoch 33/300\n",
      "4500/4500 [==============================] - 797s 177ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.1412 - val_accuracy: 0.9818\n",
      "Epoch 34/300\n",
      "4500/4500 [==============================] - 797s 177ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 14.2344 - val_accuracy: 0.0551\n",
      "Epoch 35/300\n",
      "4500/4500 [==============================] - 816s 181ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.6847 - val_accuracy: 0.8792\n",
      "Epoch 36/300\n",
      "4500/4500 [==============================] - 812s 181ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 3.7041 - val_accuracy: 0.5779\n",
      "Epoch 37/300\n",
      "4500/4500 [==============================] - 820s 182ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 3.3070 - val_accuracy: 0.6033\n",
      "Epoch 38/300\n",
      "4500/4500 [==============================] - 815s 181ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.2139 - val_accuracy: 0.9679\n",
      "Epoch 39/300\n",
      "4500/4500 [==============================] - 819s 182ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.2484 - val_accuracy: 0.9602\n",
      "Epoch 40/300\n",
      "4500/4500 [==============================] - 828s 184ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 1.5659 - val_accuracy: 0.7778\n",
      "Epoch 41/300\n",
      "4500/4500 [==============================] - 839s 186ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.1350 - val_accuracy: 0.9835\n",
      "Epoch 42/300\n",
      "4500/4500 [==============================] - 842s 187ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.1307 - val_accuracy: 0.9821\n",
      "Epoch 42: early stopping\n",
      "\n",
      "Time taken for training:  08:46:38\n",
      "\n",
      "Train Accuracy: 99.77 %\n",
      "Test Accuracy: 98.14 %\n",
      "\n",
      "Evaluate other metrics:\n",
      "1250/1250 [==============================] - 69s 53ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80      1250\n",
      "           1       1.00      0.98      0.99      1250\n",
      "           2       0.94      0.98      0.96      1250\n",
      "           3       0.96      0.91      0.93      1250\n",
      "           4       0.99      0.98      0.99      1250\n",
      "           5       1.00      1.00      1.00      1250\n",
      "           6       0.98      0.98      0.98      1250\n",
      "           7       1.00      1.00      1.00      1250\n",
      "           8       1.00      1.00      1.00      1250\n",
      "           9       0.98      0.95      0.97      1250\n",
      "          10       1.00      1.00      1.00      1250\n",
      "          11       1.00      1.00      1.00      1250\n",
      "          12       1.00      1.00      1.00      1250\n",
      "          13       1.00      1.00      1.00      1250\n",
      "          14       1.00      1.00      1.00      1250\n",
      "          15       1.00      1.00      1.00      1250\n",
      "          16       0.98      0.94      0.96      1250\n",
      "          17       1.00      0.99      0.99      1250\n",
      "          18       1.00      1.00      1.00      1250\n",
      "          19       1.00      1.00      1.00      1250\n",
      "          20       1.00      1.00      1.00      1250\n",
      "          21       0.99      1.00      1.00      1250\n",
      "          22       1.00      1.00      1.00      1250\n",
      "          23       1.00      1.00      1.00      1250\n",
      "          24       0.96      0.93      0.94      1250\n",
      "          25       0.97      0.98      0.97      1250\n",
      "          26       0.92      0.94      0.93      1250\n",
      "          27       1.00      1.00      1.00      1250\n",
      "          28       1.00      1.00      1.00      1250\n",
      "          29       1.00      1.00      1.00      1250\n",
      "          30       1.00      1.00      1.00      1250\n",
      "          31       1.00      1.00      1.00      1250\n",
      "\n",
      "    accuracy                           0.98     40000\n",
      "   macro avg       0.98      0.98      0.98     40000\n",
      "weighted avg       0.98      0.98      0.98     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"V5\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"V5\")\n",
    "\n",
    "# Try to release memory\n",
    "del new_df\n",
    "gc.collect()\n",
    "\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "X_array, y_array = apply_smote(X_array, y_array)\n",
    "X_train, X_test, y_train, y_test = split_dataset_for_training(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.1\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_train, y_train, X_test, y_test, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_V5.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f5e894-ae42-4873-98a3-1fea5d538033",
   "metadata": {},
   "source": [
    "#### V6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "604f6dc2-b2e7-4688-9aff-c4a8874d5f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n",
      "\n",
      "Generating upsampling through SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Finishing upsampling.\n",
      "\n",
      "Starting dataset split...\n",
      "Finishing dataset split.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1248, 8)           32        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1248, 8)          32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1246, 8)           200       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1246, 8)          32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 623, 8)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 619, 16)           656       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 619, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 615, 16)           1296      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 615, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 307, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4912)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2515456   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                16416     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,536,296\n",
      "Trainable params: 2,535,176\n",
      "Non-trainable params: 1,120\n",
      "_________________________________________________________________\n",
      "\n",
      "Starting training at:  20:39:59\n",
      "Epoch 1/300\n",
      "4500/4500 [==============================] - 363s 80ms/step - loss: 0.3070 - accuracy: 0.9167 - val_loss: 0.2874 - val_accuracy: 0.9159\n",
      "Epoch 2/300\n",
      "4500/4500 [==============================] - 415s 92ms/step - loss: 0.0916 - accuracy: 0.9723 - val_loss: 0.1550 - val_accuracy: 0.9526\n",
      "Epoch 3/300\n",
      "4500/4500 [==============================] - 396s 88ms/step - loss: 0.0531 - accuracy: 0.9838 - val_loss: 6.6567 - val_accuracy: 0.2809\n",
      "Epoch 4/300\n",
      "4500/4500 [==============================] - 402s 89ms/step - loss: 0.0359 - accuracy: 0.9892 - val_loss: 12.8497 - val_accuracy: 0.2169\n",
      "Epoch 5/300\n",
      "4500/4500 [==============================] - 408s 91ms/step - loss: 0.0297 - accuracy: 0.9909 - val_loss: 2.7489 - val_accuracy: 0.5082\n",
      "Epoch 6/300\n",
      "4500/4500 [==============================] - 413s 92ms/step - loss: 0.0243 - accuracy: 0.9929 - val_loss: 2.4906 - val_accuracy: 0.5796\n",
      "Epoch 7/300\n",
      "4500/4500 [==============================] - 406s 90ms/step - loss: 0.0216 - accuracy: 0.9937 - val_loss: 9.2576 - val_accuracy: 0.1561\n",
      "Epoch 8/300\n",
      "4500/4500 [==============================] - 407s 90ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.6346 - val_accuracy: 0.8642\n",
      "Epoch 9/300\n",
      "4500/4500 [==============================] - 422s 94ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.2587 - val_accuracy: 0.9389\n",
      "Epoch 10/300\n",
      "4500/4500 [==============================] - 414s 92ms/step - loss: 0.0148 - accuracy: 0.9959 - val_loss: 3.4732 - val_accuracy: 0.4879\n",
      "Epoch 11/300\n",
      "4500/4500 [==============================] - 425s 94ms/step - loss: 0.0134 - accuracy: 0.9964 - val_loss: 21.4164 - val_accuracy: 0.0676\n",
      "Epoch 12/300\n",
      "4500/4500 [==============================] - 416s 92ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 3.8089 - val_accuracy: 0.4753\n",
      "Epoch 13/300\n",
      "4500/4500 [==============================] - 471s 105ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 19.9216 - val_accuracy: 0.1480\n",
      "Epoch 14/300\n",
      "4500/4500 [==============================] - 529s 118ms/step - loss: 0.0157 - accuracy: 0.9958 - val_loss: 19.4113 - val_accuracy: 0.0722\n",
      "Epoch 15/300\n",
      "4500/4500 [==============================] - 465s 103ms/step - loss: 0.0145 - accuracy: 0.9964 - val_loss: 26.4151 - val_accuracy: 0.0327\n",
      "Epoch 16/300\n",
      "4500/4500 [==============================] - 443s 98ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 13.8921 - val_accuracy: 0.0834\n",
      "Epoch 17/300\n",
      "4500/4500 [==============================] - 436s 97ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 3.5263 - val_accuracy: 0.5432\n",
      "Epoch 18/300\n",
      "4500/4500 [==============================] - 432s 96ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 6.1756 - val_accuracy: 0.3346\n",
      "Epoch 19/300\n",
      "4500/4500 [==============================] - 428s 95ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 4.3361 - val_accuracy: 0.5111\n",
      "Epoch 20/300\n",
      "4500/4500 [==============================] - 424s 94ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 12.9390 - val_accuracy: 0.1357\n",
      "Epoch 21/300\n",
      "4500/4500 [==============================] - 421s 93ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 11.9952 - val_accuracy: 0.1737\n",
      "Epoch 22/300\n",
      "4500/4500 [==============================] - 428s 95ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 10.4716 - val_accuracy: 0.2509\n",
      "Epoch 23/300\n",
      "4500/4500 [==============================] - 432s 96ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 15.0208 - val_accuracy: 0.1437\n",
      "Epoch 24/300\n",
      "4500/4500 [==============================] - 432s 96ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 14.2895 - val_accuracy: 0.1905\n",
      "Epoch 25/300\n",
      "4500/4500 [==============================] - 439s 98ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 2.9341 - val_accuracy: 0.6649\n",
      "Epoch 26/300\n",
      "4500/4500 [==============================] - 436s 97ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 5.5320 - val_accuracy: 0.4454\n",
      "Epoch 27/300\n",
      "4500/4500 [==============================] - 450s 100ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 15.9229 - val_accuracy: 0.0946\n",
      "Epoch 28/300\n",
      "4500/4500 [==============================] - 429s 95ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 23.5021 - val_accuracy: 0.0532\n",
      "Epoch 29/300\n",
      "4500/4500 [==============================] - 478s 106ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 11.0957 - val_accuracy: 0.2219\n",
      "Epoch 30/300\n",
      "4500/4500 [==============================] - 498s 111ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 8.7913 - val_accuracy: 0.2244\n",
      "Epoch 31/300\n",
      "4500/4500 [==============================] - 467s 104ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 10.8672 - val_accuracy: 0.2136\n",
      "Epoch 32/300\n",
      "4500/4500 [==============================] - 438s 97ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 5.8867 - val_accuracy: 0.4054\n",
      "Epoch 32: early stopping\n",
      "\n",
      "Time taken for training:  03:53:28\n",
      "\n",
      "Train Accuracy: 41.79 %\n",
      "Test Accuracy: 40.70 %\n",
      "\n",
      "Evaluate other metrics:\n",
      "1250/1250 [==============================] - 47s 37ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.68      0.20      1250\n",
      "           1       0.87      0.88      0.87      1250\n",
      "           2       0.93      0.61      0.74      1250\n",
      "           3       0.98      0.42      0.59      1250\n",
      "           4       0.99      0.13      0.23      1250\n",
      "           5       1.00      0.34      0.51      1250\n",
      "           6       0.92      0.06      0.11      1250\n",
      "           7       1.00      0.38      0.55      1250\n",
      "           8       1.00      0.25      0.40      1250\n",
      "           9       0.53      0.70      0.60      1250\n",
      "          10       0.90      0.07      0.13      1250\n",
      "          11       1.00      0.47      0.64      1250\n",
      "          12       0.98      0.20      0.33      1250\n",
      "          13       1.00      0.10      0.19      1250\n",
      "          14       1.00      0.50      0.67      1250\n",
      "          15       0.51      0.99      0.67      1250\n",
      "          16       0.87      0.50      0.63      1250\n",
      "          17       0.08      1.00      0.14      1250\n",
      "          18       1.00      0.57      0.72      1250\n",
      "          19       0.99      0.52      0.68      1250\n",
      "          20       0.96      0.48      0.64      1250\n",
      "          21       0.91      0.60      0.72      1250\n",
      "          22       1.00      0.28      0.44      1250\n",
      "          23       1.00      0.35      0.51      1250\n",
      "          24       0.97      0.14      0.24      1250\n",
      "          25       1.00      0.00      0.01      1250\n",
      "          26       0.00      0.00      0.00      1250\n",
      "          27       1.00      0.73      0.84      1250\n",
      "          28       1.00      0.07      0.14      1250\n",
      "          29       1.00      0.44      0.61      1250\n",
      "          30       1.00      0.45      0.62      1250\n",
      "          31       1.00      0.10      0.19      1250\n",
      "\n",
      "    accuracy                           0.41     40000\n",
      "   macro avg       0.86      0.41      0.46     40000\n",
      "weighted avg       0.86      0.41      0.46     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"V6\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"V6\")\n",
    "\n",
    "# Try to release memory\n",
    "del new_df\n",
    "gc.collect()\n",
    "\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "X_array, y_array = apply_smote(X_array, y_array)\n",
    "X_train, X_test, y_train, y_test = split_dataset_for_training(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.1\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_train, y_train, X_test, y_test, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_V6.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eeacd4-381d-454c-bf54-0db942fb0e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
