{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47353fcc-74e3-426e-a724-6b1d1bf32b2f",
   "metadata": {},
   "source": [
    "#### Train a Convolutional Neural Network model for predicting cardiac arrhythmias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbe460f",
   "metadata": {},
   "source": [
    "#### Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077b6c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, Dense, Flatten, Input, Conv1D, MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42175028",
   "metadata": {},
   "source": [
    "#### Define a function to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b43ccbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(lead_name):\n",
    "    # Loads the dataset using only the chosen lead.\n",
    "    # Parameters:\n",
    "    #    lead_name: Lead to be used.\n",
    "    # Return:\n",
    "    #    Dataframe loaded (Pandas dataframe)\n",
    "    df = None\n",
    "    column_names = [\"idx\", \"ecg_id\", lead_name, \"arrhythmia_code\"]\n",
    "    dtypes = {\"ecg_id\": \"str\", lead_name : \"float16\", \"arrhythmia_code\" : \"int16\"}\n",
    "    try:\n",
    "        print(\"\\nStart loading CSV file...\")\n",
    "        df = pd.read_csv(\"../dataset/csv_files/ecg_sph_dataset.csv\", sep=\"|\", dtype = dtypes, usecols = column_names)\n",
    "        print(\"Finish loading CSV file.\")\n",
    "    except Exception as e:\n",
    "        print(\"\\nFail to load CSV file.\")\n",
    "        print(\"Error: {}\".format(e))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3579e10b",
   "metadata": {},
   "source": [
    "#### Build a helper function to convert the records to the required format to perform a time series processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "859f6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "number_of_steps = 1250\n",
    "number_of_features = 1\n",
    "number_of_classes = 32\n",
    "\n",
    "def get_new_columns_order(column_names_array):\n",
    "    column_idx_count = 0\n",
    "    new_array = np.zeros(len(column_names_array), dtype = int)\n",
    "    for column_idx in range(0, (number_of_steps * 4)):\n",
    "        for column_idx_2 in range(0, number_of_features):\n",
    "            new_array[column_idx + column_idx_2 * (number_of_steps * 4)] = column_idx_count\n",
    "            column_idx_count += 1\n",
    "    return new_array\n",
    "\n",
    "def build_time_window_structure(df, lead_name):\n",
    "    # Splits the dataset into \"time windows\" to be used as a time series.\n",
    "    # The function groups each 125 dataset records (CSV lines) into one record.\n",
    "    # Parameters:\n",
    "    #    df: Dataframe to be splitted.\n",
    "    #    lead_name: Lead to be used.\n",
    "    # Return:\n",
    "    #    All time windows (np.array)\n",
    "    #    All target values (np.array)\n",
    "    print(\"\\nStarting build_time_window_structure function...\")\n",
    "    df[\"idx\"] = df[\"idx\"] % (number_of_steps * 4)\n",
    "    df_aux = df.pivot_table(index = \"ecg_id\", columns = \"idx\", values = [lead_name], aggfunc = \"sum\")\n",
    "    new_columns = get_new_columns_order(df_aux.columns.values)\n",
    "    df_aux.columns = list(new_columns)\n",
    "    sorted_columns = sorted(df_aux.columns)\n",
    "    df_modified = df_aux[sorted_columns]\n",
    "    X_array = df_modified.values\n",
    "    y_array = df[\"arrhythmia_code\"].values\n",
    "    y_array = y_array[::(number_of_steps * 4)]\n",
    "    # Resample sample frequency to 125 hz.\n",
    "    fs_original = 500 # Original frequency (Hz)\n",
    "    fs_new = 125 # New frequency (Hz)\n",
    "    downsampling_factor = int(fs_original / fs_new)\n",
    "    nyquist_rate = fs_original / 2.0  # Nyquist rate\n",
    "    cutoff_freq = fs_new / 2.0  # Cut off rate\n",
    "    b, a = signal.butter(4, cutoff_freq / nyquist_rate, btype = \"low\")\n",
    "    X_array_filtered = signal.filtfilt(b, a, X_array, axis = 1)\n",
    "    X_array_125hz = X_array_filtered[:, ::downsampling_factor]\n",
    "    print(\"\\nShape of features: \", X_array_125hz.shape)\n",
    "    print(\"Quantity os samples (labels): \", len(y_array))\n",
    "    print(\"\\nFinishing build_time_window_structure function.\")\n",
    "    return X_array_125hz, y_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d50c0a6-624d-4e06-b5c3-438e3909aea8",
   "metadata": {},
   "source": [
    "#### Define a function to remove classes with less than 6 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b49334-6e2d-4a4e-899f-6ab4aceed629",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_classes_with_less_samples(X_array, y_array):\n",
    "    # Remove classes with less than 6 samples.\n",
    "    # Parameters:\n",
    "    #    X_array: array of features.\n",
    "    #    y_array: array of targets.\n",
    "    # Return:\n",
    "    #    Array of features (np.array)\n",
    "    #    Array of targets (np.array)\n",
    "\n",
    "    # Remove samples belonging to diagnostics 31, 37, 84, 87, 102, 143, 148, and 152 because these classes have less than 6 samples (SMOTE restriction).\n",
    "    print(\"\\nRemove classes with less than 6 samples.\")\n",
    "    removed_idx = np.where(np.isin(y_array, [31, 37, 84, 87, 102, 143, 148, 152]))[0]\n",
    "    X_array = np.delete(X_array, removed_idx, axis = 0)\n",
    "    y_array = np.delete(y_array, removed_idx, axis = 0)\n",
    "    number_of_classes = 32\n",
    "    # Generate a class number for each diagnostic code and replace y_array values.\n",
    "    sorted_codes = sorted(set(y_array))\n",
    "    dict_aux = {}\n",
    "    for classes_idx in range(0, number_of_classes):\n",
    "        dict_aux[classes_idx] = sorted_codes[classes_idx]\n",
    "        y_array = [classes_idx if elem == sorted_codes[classes_idx] else elem for elem in y_array]\n",
    "    y_array = np.array(y_array)\n",
    "    print(\"\\nShow classes identification:\")\n",
    "    for key, value in dict_aux.items():\n",
    "        print(f\"Class: {key} - Arrhythmia code: {value}\")\n",
    "    # Check for dataset balance.\n",
    "    diagnostic_classes, count = np.unique(y_array, return_counts = True)\n",
    "    percentage_by_class = [(i * 100 / np.sum(count)) for i in count]\n",
    "    category_count = list(zip(diagnostic_classes, count, percentage_by_class))\n",
    "    category_count.sort(key = lambda x: x[1], reverse = True)\n",
    "    print(\"\\nCheck for dataset balance:\")\n",
    "    for diagnostic_classes, count, percentage_by_class in category_count:\n",
    "        print(f\"Class = {diagnostic_classes:3.0f}   Qty = {count:8.0f}   Percentage = {percentage_by_class:2.2f} %\")\n",
    "    return X_array, y_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2c820a-3ac1-4da5-ae09-dd378637c4be",
   "metadata": {},
   "source": [
    "#### Define a function for training a CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19d8f38d-7cd0-4ddc-80d9-b11e94edb868",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_upsampling(X_array, y_array):\n",
    "    # Apply SMOTE to balance the dataset.\n",
    "    # Parameters:\n",
    "    #    X_array (np.array): array of features values.\n",
    "    #    y_array (np.array): array of target values.\n",
    "    # Return:\n",
    "    #    X_array (np.array): array of features values.\n",
    "    #    y_array (np.array): array of target values.\n",
    "    print(\"\\nGenerating upsampling using SMOTE...\")\n",
    "    min_samples = min([sum(y_array == c) for c in set(y_array)])\n",
    "    k_neighbors = min(5, min_samples - 1)\n",
    "    smote = SMOTE(sampling_strategy = \"auto\", k_neighbors = k_neighbors, random_state = 42)\n",
    "    X_array_res, y_array_res = smote.fit_resample(X_array, y_array)\n",
    "    # Check for balance.\n",
    "    diagnostic_codes, count = np.unique(y_array, return_counts = True)\n",
    "    percentage_by_codes = [(i * 100 / np.sum(count)) for i in count]\n",
    "    category_count = list(zip(diagnostic_codes, count, percentage_by_codes))\n",
    "    category_count.sort(key = lambda x: x[1], reverse = True)\n",
    "    # Use 6250 samples of each class for training.\n",
    "    dict_samples_per_class = {}\n",
    "    nr_samples_per_class = 6250\n",
    "    for category_ids, count, percentage_of_categories in category_count:\n",
    "        dict_samples_per_class[category_ids] = nr_samples_per_class\n",
    "    rus = RandomUnderSampler(sampling_strategy = dict_samples_per_class, random_state = 42)\n",
    "    X_train, y_train = rus.fit_resample(X_array_res, y_array_res)\n",
    "    print(\"{} samples after upsampling.\".format(len(y_train)))\n",
    "    print(f\"Class distribution for training after upsampling: {Counter(y_train)}\")\n",
    "    print(\"Finishing upsampling.\\n\")\n",
    "    return X_train, y_train\n",
    "\n",
    "def train_cnn_model(cnn_model, X, y, num_epochs, batch_size, validation_split, model_cfg_file):\n",
    "    # Train a CNN model.\n",
    "    # Parameters:\n",
    "    #    cnn_model (Sequential): model to be trained.\n",
    "    #    X (np.array): array of features values.\n",
    "    #    y (np.array): array of target values.\n",
    "    #    nun_folds (int): number of folds.\n",
    "    #    num_epochs (int): number of epochs of training.\n",
    "    #    batch_size (int): batch size.\n",
    "    #    validation_split (float): percentage of instances for validation set.\n",
    "    #    model_cfg_file (str): file to save the configuration model.\n",
    "    # Returns:\n",
    "    #    history (History object): history of training metrics.\n",
    "\n",
    "    # Defining the number of folds (k-Fold).\n",
    "    skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "    start_time = time.time()\n",
    "    print(\"\\nScaling data...\")\n",
    "    rb_scaler = RobustScaler()\n",
    "    rb_scaler.fit(X)\n",
    "    X_train = rb_scaler.transform(X)\n",
    "    y_train = y\n",
    "    es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 5, restore_best_weights = True)\n",
    "    train_accuracy_by_fold = []\n",
    "    test_accuracy_by_fold = []\n",
    "    fold_number = 1\n",
    "    history_by_fold = []\n",
    "    y_predclass_for_report = []\n",
    "    y_testclass_for_report = []\n",
    "    print(\"\\nStarting training...\")\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        print(\"\\nTraining fold {}\".format(fold_number))\n",
    "        with tf.device('/cpu:0'):\n",
    "            X_train_fold, y_train_fold = apply_upsampling(X_train[train_index], y_train[train_index])\n",
    "            X_train_fold = X_train_fold.reshape((X_train_fold.shape[0], number_of_steps, number_of_features))\n",
    "            history = cnn_model.fit(X_train_fold, y_train_fold, validation_split = validation_split,\n",
    "                                    epochs = num_epochs, batch_size = batch_size, \n",
    "                                    verbose = 1, callbacks = [es])\n",
    "            _, train_accuracy = cnn_model.evaluate(X_train_fold, y_train_fold, verbose = 0)\n",
    "            X_test_reshaped = X_train[test_index].reshape((X_train[test_index].shape[0], number_of_steps, number_of_features))\n",
    "            _, test_accuracy = cnn_model.evaluate(X_test_reshaped, y_train[test_index], verbose = 0)\n",
    "            train_accuracy_by_fold.append(train_accuracy)\n",
    "            test_accuracy_by_fold.append(test_accuracy)\n",
    "            y_predclass_for_report.extend(np.argmax(cnn_model.predict(X_test_reshaped), axis = 1))\n",
    "            y_testclass_for_report.extend(y_train[test_index])\n",
    "            history_by_fold.append(history)\n",
    "            fold_number += 1\n",
    "    cnn_model.save(\"../modelconfig/\" + model_cfg_file)\n",
    "    elapsed_seconds = time.time() - start_time\n",
    "    print(\"\\nTime taken for training: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_seconds)))\n",
    "    print(\"\\n\")\n",
    "    # Show metrics.\n",
    "    for i in range(len(train_accuracy_by_fold)):\n",
    "        print(\"Fold {} - Train Accuracy {:.4f} - Test Accuracy {:.4f}\".format((i + 1), train_accuracy_by_fold[i],\n",
    "                                                                              test_accuracy_by_fold[i]))\n",
    "    print(\"\\nMean Train Accuracy: {:.4f} - Std: {:.4f} \".format(np.mean(train_accuracy_by_fold),\n",
    "                                                                np.std(train_accuracy_by_fold)))\n",
    "    print(\"Mean Test Accuracy: {:.4f} - Std: {:.4f} \".format(np.mean(test_accuracy_by_fold),\n",
    "                                                             np.std(test_accuracy_by_fold)))\n",
    "    print(\"\\nEvaluate other metrics:\")\n",
    "    print(classification_report(y_testclass_for_report, y_predclass_for_report, zero_division = 0))\n",
    "    return history_by_fold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8dbf24-0ece-49d0-9644-a3a90865f0dd",
   "metadata": {},
   "source": [
    "#### Define a function to build a version 1 of CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acff693b-6d32-4b69-8133-0fca13f2b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_v1():\n",
    "    act_fuction = \"relu\"\n",
    "    k_init = \"he_uniform\"\n",
    "    model = Sequential()\n",
    "    model.add(Input((number_of_steps, number_of_features)))\n",
    "    model.add(Conv1D(filters = 8, kernel_size = 3, activation = act_fuction, kernel_initializer = k_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters = 8, kernel_size = 3, activation = act_fuction, kernel_initializer = k_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Conv1D(filters = 16, kernel_size = 5, activation = act_fuction, kernel_initializer = k_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters = 16, kernel_size = 5, activation = act_fuction, kernel_initializer = k_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation = act_fuction, kernel_initializer = k_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(number_of_classes, activation = 'softmax'))\n",
    "    opt = Adam(learning_rate = 0.001, clipnorm = 1.0)\n",
    "    model.summary()\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d861ca2b-79bb-4d8a-8216-3f1d80e985ba",
   "metadata": {},
   "source": [
    "#### Lead I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b3ad224-b9d5-4158-ba39-3f046d59ecdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">623</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">307</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4912</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">628,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │           \u001b[38;5;34m200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m623\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m1,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m307\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4912\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m628,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,880</span> (2.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m635,880\u001b[0m (2.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,528</span> (2.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m635,528\u001b[0m (2.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling data...\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Training fold 1\n",
      "\n",
      "Generating upsampling using SMOTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 18ms/step - accuracy: 0.8584 - loss: 0.5487 - val_accuracy: 1.0000 - val_loss: 1.3383e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 25ms/step - accuracy: 0.9782 - loss: 0.0727 - val_accuracy: 1.0000 - val_loss: 6.1228e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 28ms/step - accuracy: 0.9890 - loss: 0.0358 - val_accuracy: 0.1995 - val_loss: 3.8444\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 28ms/step - accuracy: 0.9920 - loss: 0.0263 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 30ms/step - accuracy: 0.9941 - loss: 0.0188 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 31ms/step - accuracy: 0.9949 - loss: 0.0165 - val_accuracy: 0.0000e+00 - val_loss: 6.9099\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 29ms/step - accuracy: 0.9962 - loss: 0.0147 - val_accuracy: 1.0000 - val_loss: 3.1745e-06\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 29ms/step - accuracy: 0.9965 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 2.9059e-06\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 30ms/step - accuracy: 0.9964 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 1.1402e-07\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 33ms/step - accuracy: 0.9970 - loss: 0.0102 - val_accuracy: 1.0000 - val_loss: 9.7899e-05\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 27ms/step - accuracy: 0.9971 - loss: 0.0112 - val_accuracy: 1.0000 - val_loss: 4.1172e-06\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 17ms/step - accuracy: 0.9974 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 6.6269e-06\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 18ms/step - accuracy: 0.9970 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 6.2823e-08\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 19ms/step - accuracy: 0.9975 - loss: 0.0084 - val_accuracy: 1.0000 - val_loss: 5.7832e-06\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 19ms/step - accuracy: 0.9977 - loss: 0.0084 - val_accuracy: 1.0000 - val_loss: 6.6698e-08\n",
      "Epoch 16/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 20ms/step - accuracy: 0.9979 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 5.7292e-07\n",
      "Epoch 17/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 21ms/step - accuracy: 0.9981 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 7.8099e-07\n",
      "Epoch 18/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 21ms/step - accuracy: 0.9981 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 3.3915e-07\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 2\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 26ms/step - accuracy: 0.9747 - loss: 0.1361 - val_accuracy: 1.0000 - val_loss: 4.5732e-06\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 28ms/step - accuracy: 0.9958 - loss: 0.0156 - val_accuracy: 1.0000 - val_loss: 7.3235e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 28ms/step - accuracy: 0.9972 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 8.2226e-06\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 27ms/step - accuracy: 0.9973 - loss: 0.0101 - val_accuracy: 1.0000 - val_loss: 1.3164e-05\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 30ms/step - accuracy: 0.9980 - loss: 0.0070 - val_accuracy: 0.6250 - val_loss: 1.6504\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 26ms/step - accuracy: 0.9978 - loss: 0.0093 - val_accuracy: 1.0000 - val_loss: 7.5936e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 28ms/step - accuracy: 0.9983 - loss: 0.0070 - val_accuracy: 0.9820 - val_loss: 0.0417\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 25ms/step - accuracy: 0.9984 - loss: 0.0069 - val_accuracy: 0.9460 - val_loss: 0.2024\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 29ms/step - accuracy: 0.9982 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 5.3644e-10\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 26ms/step - accuracy: 0.9982 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 1.7206e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 29ms/step - accuracy: 0.9984 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 1.6278e-07\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 26ms/step - accuracy: 0.9987 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 1.4305e-09\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 28ms/step - accuracy: 0.9984 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 5.8173e-07\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 26ms/step - accuracy: 0.9985 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 3.0380e-06\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\n",
      "Training fold 3\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 33ms/step - accuracy: 0.9889 - loss: 0.0471 - val_accuracy: 0.5155 - val_loss: 2.7081\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 27ms/step - accuracy: 0.9974 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 1.9610e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 29ms/step - accuracy: 0.9978 - loss: 0.0085 - val_accuracy: 0.9505 - val_loss: 0.1147\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 27ms/step - accuracy: 0.9978 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 9.7087e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 28ms/step - accuracy: 0.9984 - loss: 0.0066 - val_accuracy: 0.0000e+00 - val_loss: 13.5970\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 28ms/step - accuracy: 0.9986 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 4.7826e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 29ms/step - accuracy: 0.9986 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 1.7220e-07\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 4\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 31ms/step - accuracy: 0.9947 - loss: 0.0183 - val_accuracy: 1.0000 - val_loss: 4.5657e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 28ms/step - accuracy: 0.9980 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 6.0260e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 30ms/step - accuracy: 0.9981 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 9.8944e-09\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 29ms/step - accuracy: 0.9986 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 5.9830e-07\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 30ms/step - accuracy: 0.9984 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 1.1690e-05\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 28ms/step - accuracy: 0.9987 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 4.4703e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9983 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 6.9559e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 26ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 3.7956e-07\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 5\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 33ms/step - accuracy: 0.9954 - loss: 0.0162 - val_accuracy: 1.0000 - val_loss: 2.1159e-06\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 29ms/step - accuracy: 0.9981 - loss: 0.0081 - val_accuracy: 1.0000 - val_loss: 1.6868e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 30ms/step - accuracy: 0.9985 - loss: 0.0061 - val_accuracy: 0.3310 - val_loss: 4.5734\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 30ms/step - accuracy: 0.9988 - loss: 0.0055 - val_accuracy: 0.9475 - val_loss: 0.1573\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 29ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 5.2630e-07\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 30ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 9.3996e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 29ms/step - accuracy: 0.9986 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 1.0069e-05\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\n",
      "Training fold 6\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 31ms/step - accuracy: 0.9968 - loss: 0.0108 - val_accuracy: 1.0000 - val_loss: 1.4365e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 29ms/step - accuracy: 0.9986 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 4.5940e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 31ms/step - accuracy: 0.9988 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 5.9252e-07\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 29ms/step - accuracy: 0.9987 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 1.4102e-07\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9987 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 5.2219e-07\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 30ms/step - accuracy: 0.9988 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 3.8147e-09\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 31ms/step - accuracy: 0.9991 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 2.4259e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 32ms/step - accuracy: 0.9989 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 9.2428e-06\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 29ms/step - accuracy: 0.9987 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 1.0161e-05\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 29ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 1.3240e-05\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 30ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 1.2612e-07\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 7\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 32ms/step - accuracy: 0.9962 - loss: 0.0124 - val_accuracy: 0.7740 - val_loss: 0.9925\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 30ms/step - accuracy: 0.9984 - loss: 0.0054 - val_accuracy: 0.9115 - val_loss: 0.2643\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 29ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 1.8876e-06\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 28ms/step - accuracy: 0.9989 - loss: 0.0045 - val_accuracy: 0.8375 - val_loss: 0.4612\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 28ms/step - accuracy: 0.9987 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 8.0466e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 29ms/step - accuracy: 0.9989 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 1.8734e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 28ms/step - accuracy: 0.9990 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 4.7684e-10\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 28ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 1.1861e-08\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 28ms/step - accuracy: 0.9990 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 1.9163e-07\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 28ms/step - accuracy: 0.9990 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 6.6876e-08\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 29ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 4.6693e-07\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 28ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 6.9618e-08\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 8\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 30ms/step - accuracy: 0.9964 - loss: 0.0133 - val_accuracy: 1.0000 - val_loss: 2.5690e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 28ms/step - accuracy: 0.9988 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 3.1829e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 29ms/step - accuracy: 0.9987 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 7.8082e-09\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 32ms/step - accuracy: 0.9988 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 8.2254e-09\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 30ms/step - accuracy: 0.9990 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 3.2187e-09\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 31ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 1.5855e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 30ms/step - accuracy: 0.9989 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 5.7161e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 6.0797e-08\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9989 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 7.9453e-08\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 33ms/step - accuracy: 0.9989 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 1.5736e-08\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "Training fold 9\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 39ms/step - accuracy: 0.9972 - loss: 0.0096 - val_accuracy: 1.0000 - val_loss: 3.6359e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 39ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 38ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 3.6955e-09\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 36ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 8.8811e-09\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 37ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 3.5763e-09\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 36ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 2.4438e-09\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 37ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 1.7881e-09\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "Training fold 10\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 40ms/step - accuracy: 0.9972 - loss: 0.0114 - val_accuracy: 1.0000 - val_loss: 7.1883e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 40ms/step - accuracy: 0.9988 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 3.4939e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 41ms/step - accuracy: 0.9989 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 6.9797e-08\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 38ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 0.3195 - val_loss: 4.1258\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 38ms/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 2.8014e-09\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 39ms/step - accuracy: 0.9990 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 1.4544e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 40ms/step - accuracy: 0.9990 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 2.9921e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 41ms/step - accuracy: 0.9995 - loss: 0.0028 - val_accuracy: 0.9910 - val_loss: 0.0174\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 41ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.8430 - val_loss: 0.9590\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 43ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.6470 - val_loss: 2.4495\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\n",
      "Time taken for training:  05:31:56\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.9987 - Test Accuracy 0.5783\n",
      "Fold 2 - Train Accuracy 0.9992 - Test Accuracy 0.7876\n",
      "Fold 3 - Train Accuracy 0.9993 - Test Accuracy 0.9383\n",
      "Fold 4 - Train Accuracy 0.9996 - Test Accuracy 0.9507\n",
      "Fold 5 - Train Accuracy 0.9984 - Test Accuracy 0.9441\n",
      "Fold 6 - Train Accuracy 0.9997 - Test Accuracy 0.9588\n",
      "Fold 7 - Train Accuracy 0.9997 - Test Accuracy 0.9565\n",
      "Fold 8 - Train Accuracy 0.9993 - Test Accuracy 0.9689\n",
      "Fold 9 - Train Accuracy 0.9995 - Test Accuracy 0.9755\n",
      "Fold 10 - Train Accuracy 0.9997 - Test Accuracy 0.9845\n",
      "\n",
      "Mean Train Accuracy: 0.9993 - Std: 0.0004 \n",
      "Mean Test Accuracy: 0.9043 - Std: 0.1209 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93     13905\n",
      "           1       0.91      0.96      0.94       723\n",
      "           2       0.94      0.97      0.96      2659\n",
      "           3       0.79      0.84      0.81      1123\n",
      "           4       0.83      0.84      0.83       384\n",
      "           5       0.97      0.80      0.88        44\n",
      "           6       0.86      0.89      0.88       663\n",
      "           7       0.88      0.88      0.88        94\n",
      "           8       0.91      0.83      0.87        12\n",
      "           9       0.86      0.84      0.85       786\n",
      "          10       0.89      0.89      0.89         9\n",
      "          11       0.86      0.84      0.85        98\n",
      "          12       1.00      0.75      0.86         8\n",
      "          13       0.89      0.85      0.87        20\n",
      "          14       0.87      0.87      0.87        77\n",
      "          15       0.92      0.94      0.93        62\n",
      "          16       0.86      0.81      0.84       917\n",
      "          17       0.94      0.95      0.95       473\n",
      "          18       0.83      0.86      0.84        22\n",
      "          19       0.85      0.87      0.86       122\n",
      "          20       0.87      0.79      0.83       111\n",
      "          21       0.77      0.83      0.80       201\n",
      "          22       0.67      0.86      0.75         7\n",
      "          23       0.81      0.84      0.83        96\n",
      "          24       0.76      0.83      0.80      1045\n",
      "          25       0.80      0.85      0.82       540\n",
      "          26       0.80      0.84      0.82      1334\n",
      "          27       0.89      0.86      0.87        28\n",
      "          28       0.84      0.91      0.88        35\n",
      "          29       0.90      0.82      0.86        77\n",
      "          30       0.92      0.84      0.88        64\n",
      "          31       0.83      0.71      0.77         7\n",
      "\n",
      "    accuracy                           0.90     25746\n",
      "   macro avg       0.87      0.86      0.86     25746\n",
      "weighted avg       0.91      0.90      0.90     25746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"lead1\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"lead1\")\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.01\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_array, y_array, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_lead1.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a16aed-e2fe-44c0-a83d-30235fc2ec44",
   "metadata": {},
   "source": [
    "#### Lead II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b2c21c2-ca1c-4ec4-b7c7-42c4f374d4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">623</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">307</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4912</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">628,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │           \u001b[38;5;34m200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m623\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m1,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m307\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4912\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m628,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,880</span> (2.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m635,880\u001b[0m (2.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,528</span> (2.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m635,528\u001b[0m (2.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling data...\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Training fold 1\n",
      "\n",
      "Generating upsampling using SMOTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 21ms/step - accuracy: 0.8656 - loss: 0.5245 - val_accuracy: 1.0000 - val_loss: 4.8627e-05\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 21ms/step - accuracy: 0.9817 - loss: 0.0600 - val_accuracy: 1.0000 - val_loss: 1.6508e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 22ms/step - accuracy: 0.9905 - loss: 0.0297 - val_accuracy: 1.0000 - val_loss: 2.2304e-06\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 22ms/step - accuracy: 0.9938 - loss: 0.0201 - val_accuracy: 1.0000 - val_loss: 2.2755e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 24ms/step - accuracy: 0.9950 - loss: 0.0160 - val_accuracy: 1.0000 - val_loss: 1.3479e-05\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 23ms/step - accuracy: 0.9955 - loss: 0.0139 - val_accuracy: 1.0000 - val_loss: 7.8509e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 24ms/step - accuracy: 0.9967 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 1.5220e-06\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 24ms/step - accuracy: 0.9967 - loss: 0.0109 - val_accuracy: 1.0000 - val_loss: 7.2122e-09\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 25ms/step - accuracy: 0.9971 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 7.9870e-08\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 24ms/step - accuracy: 0.9976 - loss: 0.0075 - val_accuracy: 1.0000 - val_loss: 1.2100e-08\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 25ms/step - accuracy: 0.9974 - loss: 0.0084 - val_accuracy: 1.0000 - val_loss: 3.8803e-08\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0075 - val_accuracy: 1.0000 - val_loss: 1.7047e-08\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 24ms/step - accuracy: 0.9975 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 6.5565e-10\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 26ms/step - accuracy: 0.9978 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 1.4305e-09\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 24ms/step - accuracy: 0.9979 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 3.6359e-09\n",
      "Epoch 16/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 26ms/step - accuracy: 0.9981 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 25ms/step - accuracy: 0.9983 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 28ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 25ms/step - accuracy: 0.9983 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 27ms/step - accuracy: 0.9985 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 2\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 26ms/step - accuracy: 0.9743 - loss: 0.1415 - val_accuracy: 1.0000 - val_loss: 5.9605e-10\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 27ms/step - accuracy: 0.9955 - loss: 0.0135 - val_accuracy: 1.0000 - val_loss: 8.5334e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 28ms/step - accuracy: 0.9977 - loss: 0.0075 - val_accuracy: 1.0000 - val_loss: 8.9824e-08\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 4.5896e-09\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 26ms/step - accuracy: 0.9982 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 4.1723e-10\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 26ms/step - accuracy: 0.9985 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 8.9943e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 26ms/step - accuracy: 0.9986 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 5.9009e-09\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 27ms/step - accuracy: 0.9985 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 2.3842e-10\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 27ms/step - accuracy: 0.9986 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 2.3842e-09\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 27ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 2.1456e-06\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 27ms/step - accuracy: 0.9986 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 26ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 27ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 27ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 27ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 1.4305e-09\n",
      "Epoch 16/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 27ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\n",
      "Training fold 3\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 29ms/step - accuracy: 0.9905 - loss: 0.0416 - val_accuracy: 1.0000 - val_loss: 1.3649e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 28ms/step - accuracy: 0.9977 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 1.6809e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 28ms/step - accuracy: 0.9984 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 1.0493e-06\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 28ms/step - accuracy: 0.9985 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 1.2714e-07\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 27ms/step - accuracy: 0.9990 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 29ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 27ms/step - accuracy: 0.9990 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 7.7486e-10\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 30ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 27ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 29ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 1.6093e-09\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 4\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 29ms/step - accuracy: 0.9953 - loss: 0.0189 - val_accuracy: 1.0000 - val_loss: 1.1921e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 29ms/step - accuracy: 0.9986 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 29ms/step - accuracy: 0.9987 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 5.2631e-08\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 30ms/step - accuracy: 0.9984 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 1.4305e-09\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 28ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 9.5367e-09\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 30ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 3.5763e-10\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 29ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 5\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 30ms/step - accuracy: 0.9969 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 9.2983e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 29ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 2.0802e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 30ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 2.0509e-06\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 30ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 1.2517e-09\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 31ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 3.0907e-06\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 30ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 1.1921e-10\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 30ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 6.1427e-06\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 31ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 4.1723e-10\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 30ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 1.7881e-09\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 31ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 6\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 37ms/step - accuracy: 0.9967 - loss: 0.0138 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 31ms/step - accuracy: 0.9986 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 32ms/step - accuracy: 0.9988 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 32ms/step - accuracy: 0.9990 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 7.7486e-10\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 33ms/step - accuracy: 0.9989 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 33ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 7\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 36ms/step - accuracy: 0.9973 - loss: 0.0091 - val_accuracy: 1.0000 - val_loss: 8.1658e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 33ms/step - accuracy: 0.9988 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 2.6822e-09\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 34ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 34ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 35ms/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 33ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 3.3379e-09\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 34ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 5.9605e-10\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 35ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 8\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 37ms/step - accuracy: 0.9978 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 8.1062e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 36ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 1.0371e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 36ms/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 36ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 35ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 35ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 36ms/step - accuracy: 0.9993 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 37ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 9\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 39ms/step - accuracy: 0.9984 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 36ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 37ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 38ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 38ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 38ms/step - accuracy: 0.9992 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\n",
      "Training fold 10\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 42ms/step - accuracy: 0.9982 - loss: 0.0071 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 39ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 5.6624e-09\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 39ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 1.7285e-08\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 42ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 41ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 43ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 3.4571e-09\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\n",
      "Time taken for training:  05:25:29\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.9996 - Test Accuracy 0.5977\n",
      "Fold 2 - Train Accuracy 0.9996 - Test Accuracy 0.8167\n",
      "Fold 3 - Train Accuracy 0.9998 - Test Accuracy 0.9406\n",
      "Fold 4 - Train Accuracy 0.9997 - Test Accuracy 0.9713\n",
      "Fold 5 - Train Accuracy 0.9996 - Test Accuracy 0.9417\n",
      "Fold 6 - Train Accuracy 0.9992 - Test Accuracy 0.9783\n",
      "Fold 7 - Train Accuracy 0.9998 - Test Accuracy 0.9829\n",
      "Fold 8 - Train Accuracy 0.9991 - Test Accuracy 0.9810\n",
      "Fold 9 - Train Accuracy 0.9995 - Test Accuracy 0.9872\n",
      "Fold 10 - Train Accuracy 0.9998 - Test Accuracy 0.9934\n",
      "\n",
      "Mean Train Accuracy: 0.9996 - Std: 0.0002 \n",
      "Mean Test Accuracy: 0.9191 - Std: 0.1179 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     13905\n",
      "           1       0.94      0.96      0.95       723\n",
      "           2       0.95      0.98      0.96      2659\n",
      "           3       0.87      0.81      0.84      1123\n",
      "           4       0.91      0.80      0.85       384\n",
      "           5       0.95      0.80      0.86        44\n",
      "           6       0.90      0.92      0.91       663\n",
      "           7       0.88      0.96      0.92        94\n",
      "           8       0.91      0.83      0.87        12\n",
      "           9       0.87      0.90      0.88       786\n",
      "          10       0.86      0.67      0.75         9\n",
      "          11       0.92      0.85      0.88        98\n",
      "          12       0.86      0.75      0.80         8\n",
      "          13       1.00      0.85      0.92        20\n",
      "          14       0.94      0.87      0.91        77\n",
      "          15       0.92      0.90      0.91        62\n",
      "          16       0.81      0.82      0.82       917\n",
      "          17       0.88      0.86      0.87       473\n",
      "          18       0.95      0.86      0.90        22\n",
      "          19       0.91      0.82      0.86       122\n",
      "          20       0.88      0.88      0.88       111\n",
      "          21       0.88      0.82      0.85       201\n",
      "          22       1.00      1.00      1.00         7\n",
      "          23       0.89      0.85      0.87        96\n",
      "          24       0.85      0.82      0.83      1045\n",
      "          25       0.87      0.85      0.86       540\n",
      "          26       0.87      0.85      0.86      1334\n",
      "          27       1.00      0.89      0.94        28\n",
      "          28       0.91      0.83      0.87        35\n",
      "          29       0.93      0.84      0.88        77\n",
      "          30       0.96      0.83      0.89        64\n",
      "          31       0.86      0.86      0.86         7\n",
      "\n",
      "    accuracy                           0.92     25746\n",
      "   macro avg       0.91      0.86      0.88     25746\n",
      "weighted avg       0.92      0.92      0.92     25746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"lead2\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"lead2\")\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.01\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_array, y_array, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_lead2.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba6dabf-e8cc-4899-aa7a-db4ad6b0cd7a",
   "metadata": {},
   "source": [
    "#### Lead III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47199c32-f584-4be7-9a65-47b703645bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">623</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">307</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4912</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">628,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │           \u001b[38;5;34m200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m623\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m1,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m307\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4912\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m628,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,880</span> (2.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m635,880\u001b[0m (2.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,528</span> (2.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m635,528\u001b[0m (2.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling data...\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Training fold 1\n",
      "\n",
      "Generating upsampling using SMOTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 20ms/step - accuracy: 0.8446 - loss: 0.6009 - val_accuracy: 1.0000 - val_loss: 3.6119e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 19ms/step - accuracy: 0.9753 - loss: 0.0789 - val_accuracy: 1.0000 - val_loss: 7.2562e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 20ms/step - accuracy: 0.9872 - loss: 0.0419 - val_accuracy: 1.0000 - val_loss: 3.0998e-06\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 21ms/step - accuracy: 0.9918 - loss: 0.0270 - val_accuracy: 1.0000 - val_loss: 1.1138e-05\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 22ms/step - accuracy: 0.9933 - loss: 0.0224 - val_accuracy: 1.0000 - val_loss: 1.0979e-07\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 23ms/step - accuracy: 0.9941 - loss: 0.0192 - val_accuracy: 1.0000 - val_loss: 6.2075e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 23ms/step - accuracy: 0.9955 - loss: 0.0150 - val_accuracy: 1.0000 - val_loss: 2.6127e-06\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 23ms/step - accuracy: 0.9955 - loss: 0.0149 - val_accuracy: 0.0000e+00 - val_loss: 10.8861\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 25ms/step - accuracy: 0.9955 - loss: 0.0165 - val_accuracy: 1.0000 - val_loss: 4.1144e-07\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 24ms/step - accuracy: 0.9964 - loss: 0.0124 - val_accuracy: 1.0000 - val_loss: 7.9901e-06\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 2\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 26ms/step - accuracy: 0.9676 - loss: 0.1410 - val_accuracy: 1.0000 - val_loss: 7.6248e-06\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 24ms/step - accuracy: 0.9935 - loss: 0.0228 - val_accuracy: 1.0000 - val_loss: 1.4531e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 25ms/step - accuracy: 0.9948 - loss: 0.0179 - val_accuracy: 1.0000 - val_loss: 1.8357e-05\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 25ms/step - accuracy: 0.9952 - loss: 0.0156 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 25ms/step - accuracy: 0.9961 - loss: 0.0135 - val_accuracy: 1.0000 - val_loss: 1.7569e-06\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 25ms/step - accuracy: 0.9968 - loss: 0.0108 - val_accuracy: 0.0000e+00 - val_loss: 13.3681\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 25ms/step - accuracy: 0.9969 - loss: 0.0109 - val_accuracy: 0.5840 - val_loss: 2.0593\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 25ms/step - accuracy: 0.9970 - loss: 0.0100 - val_accuracy: 1.0000 - val_loss: 8.5235e-08\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 25ms/step - accuracy: 0.9975 - loss: 0.0089 - val_accuracy: 0.8245 - val_loss: 0.6579\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 25ms/step - accuracy: 0.9972 - loss: 0.0099 - val_accuracy: 1.0000 - val_loss: 1.4524e-06\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 26ms/step - accuracy: 0.9978 - loss: 0.0084 - val_accuracy: 1.0000 - val_loss: 1.8131e-06\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 19ms/step - accuracy: 0.9973 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 7.2956e-08\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 21ms/step - accuracy: 0.9977 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 1.1235e-07\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 22ms/step - accuracy: 0.9979 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 8.6605e-08\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 24ms/step - accuracy: 0.9975 - loss: 0.0096 - val_accuracy: 1.0000 - val_loss: 4.7266e-08\n",
      "Epoch 16/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0088 - val_accuracy: 0.5140 - val_loss: 2.6442\n",
      "Epoch 17/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 28ms/step - accuracy: 0.9981 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 1.3202e-07\n",
      "Epoch 18/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 26ms/step - accuracy: 0.9982 - loss: 0.0068 - val_accuracy: 0.9865 - val_loss: 0.0423\n",
      "Epoch 19/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 27ms/step - accuracy: 0.9984 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 5.4836e-09\n",
      "Epoch 20/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0071 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 21/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 26ms/step - accuracy: 0.9984 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 1.2898e-07\n",
      "Epoch 22/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 29ms/step - accuracy: 0.9985 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 1.7345e-08\n",
      "Epoch 23/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 27ms/step - accuracy: 0.9984 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 5.1260e-09\n",
      "Epoch 24/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 28ms/step - accuracy: 0.9983 - loss: 0.0065 - val_accuracy: 0.0000e+00 - val_loss: 30.9464\n",
      "Epoch 25/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 27ms/step - accuracy: 0.9988 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 1.2875e-08\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 3\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 29ms/step - accuracy: 0.9800 - loss: 0.1058 - val_accuracy: 1.0000 - val_loss: 7.8850e-05\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 27ms/step - accuracy: 0.9960 - loss: 0.0141 - val_accuracy: 1.0000 - val_loss: 3.5942e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 29ms/step - accuracy: 0.9975 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 2.6196e-05\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 27ms/step - accuracy: 0.9981 - loss: 0.0075 - val_accuracy: 1.0000 - val_loss: 1.1725e-05\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 29ms/step - accuracy: 0.9982 - loss: 0.0066 - val_accuracy: 0.0000e+00 - val_loss: 11.6067\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 27ms/step - accuracy: 0.9985 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 4.7365e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 28ms/step - accuracy: 0.9984 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 6.8931e-07\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\n",
      "Training fold 4\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 30ms/step - accuracy: 0.9924 - loss: 0.0276 - val_accuracy: 1.0000 - val_loss: 1.2016e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 27ms/step - accuracy: 0.9976 - loss: 0.0093 - val_accuracy: 0.9615 - val_loss: 0.0940\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 29ms/step - accuracy: 0.9982 - loss: 0.0070 - val_accuracy: 0.0000e+00 - val_loss: 26.7473\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 28ms/step - accuracy: 0.9985 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 5.5432e-08\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 30ms/step - accuracy: 0.9985 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 6.8486e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 28ms/step - accuracy: 0.9984 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 1.8537e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 30ms/step - accuracy: 0.9987 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 2.6226e-09\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 27ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 7.7486e-09\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 30ms/step - accuracy: 0.9988 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 9.7632e-08\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 29ms/step - accuracy: 0.9987 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 3.8147e-09\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 30ms/step - accuracy: 0.9987 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 5.4131e-07\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 28ms/step - accuracy: 0.9987 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 33ms/step - accuracy: 0.9988 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 4.4703e-09\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 28ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 5.4038e-06\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9988 - loss: 0.0046 - val_accuracy: 0.0120 - val_loss: 11.8822\n",
      "Epoch 16/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 28ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 1.1921e-10\n",
      "Epoch 17/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 2.8149e-05\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 5\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 29ms/step - accuracy: 0.9920 - loss: 0.0318 - val_accuracy: 1.0000 - val_loss: 4.5586e-06\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 30ms/step - accuracy: 0.9980 - loss: 0.0071 - val_accuracy: 0.0000e+00 - val_loss: 22.8800\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 30ms/step - accuracy: 0.9980 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 1.9073e-09\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 30ms/step - accuracy: 0.9985 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 1.7058e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 31ms/step - accuracy: 0.9986 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 4.5657e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 31ms/step - accuracy: 0.9990 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 4.6492e-09\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 31ms/step - accuracy: 0.9989 - loss: 0.0051 - val_accuracy: 0.9510 - val_loss: 0.1094\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9989 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 1.2222e-06\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 6\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 33ms/step - accuracy: 0.9963 - loss: 0.0151 - val_accuracy: 1.0000 - val_loss: 1.1921e-10\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 31ms/step - accuracy: 0.9982 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 6.5081e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 33ms/step - accuracy: 0.9987 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 6.4976e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 32ms/step - accuracy: 0.9986 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 2.3160e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9988 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 32ms/step - accuracy: 0.9989 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 1.2279e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 1.7083e-07\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 32ms/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 0.0000e+00 - val_loss: 25.3948\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9990 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 7\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 35ms/step - accuracy: 0.9962 - loss: 0.0144 - val_accuracy: 1.0000 - val_loss: 5.7578e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 35ms/step - accuracy: 0.9985 - loss: 0.0059 - val_accuracy: 0.7905 - val_loss: 0.8303\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 33ms/step - accuracy: 0.9987 - loss: 0.0048 - val_accuracy: 0.9170 - val_loss: 0.2591\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9986 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 1.0092e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 33ms/step - accuracy: 0.9991 - loss: 0.0044 - val_accuracy: 0.9505 - val_loss: 0.2784\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 31ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 7.1526e-10\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 35ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.9775 - val_loss: 0.0657\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 3.9695e-05\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 33ms/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 2.1458e-09\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 31ms/step - accuracy: 0.9992 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 2.6878e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 36ms/step - accuracy: 0.9992 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 1.2577e-08\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\n",
      "Training fold 8\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 31ms/step - accuracy: 0.9965 - loss: 0.0137 - val_accuracy: 1.0000 - val_loss: 7.8678e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 35ms/step - accuracy: 0.9984 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 3.6345e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 31ms/step - accuracy: 0.9986 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 6.5565e-10\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 36ms/step - accuracy: 0.9989 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 32ms/step - accuracy: 0.9989 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 35ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 1.1463e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.1515 - val_loss: 7.8109\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 35ms/step - accuracy: 0.9988 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 9.3579e-09\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 34ms/step - accuracy: 0.9990 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "Training fold 9\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 42ms/step - accuracy: 0.9972 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 2.6286e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 37ms/step - accuracy: 0.9989 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 8.0168e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 44ms/step - accuracy: 0.9990 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 5.9605e-10\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 40ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 9.5367e-10\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 42ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 9.4473e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 43ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 1.4722e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 44ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 1.1623e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 46ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 5.7816e-09\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "Training fold 10\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 44ms/step - accuracy: 0.9974 - loss: 0.0098 - val_accuracy: 1.0000 - val_loss: 2.1458e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 42ms/step - accuracy: 0.9984 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 5.7816e-09\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 43ms/step - accuracy: 0.9987 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 48ms/step - accuracy: 0.9988 - loss: 0.0054 - val_accuracy: 0.9975 - val_loss: 0.0198\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 45ms/step - accuracy: 0.9988 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 7.7486e-10\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 47ms/step - accuracy: 0.9989 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 8.0281e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 50ms/step - accuracy: 0.9989 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 4.2801e-07\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 45ms/step - accuracy: 0.9989 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 1.0327e-05\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\n",
      "Time taken for training:  06:09:12\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.9980 - Test Accuracy 0.5033\n",
      "Fold 2 - Train Accuracy 0.9996 - Test Accuracy 0.6136\n",
      "Fold 3 - Train Accuracy 0.9990 - Test Accuracy 0.9111\n",
      "Fold 4 - Train Accuracy 0.9997 - Test Accuracy 0.8680\n",
      "Fold 5 - Train Accuracy 0.9992 - Test Accuracy 0.9487\n",
      "Fold 6 - Train Accuracy 0.9998 - Test Accuracy 0.9701\n",
      "Fold 7 - Train Accuracy 0.9998 - Test Accuracy 0.9685\n",
      "Fold 8 - Train Accuracy 0.9997 - Test Accuracy 0.9837\n",
      "Fold 9 - Train Accuracy 0.9997 - Test Accuracy 0.9848\n",
      "Fold 10 - Train Accuracy 0.9997 - Test Accuracy 0.9880\n",
      "\n",
      "Mean Train Accuracy: 0.9994 - Std: 0.0005 \n",
      "Mean Test Accuracy: 0.8740 - Std: 0.1636 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91     13905\n",
      "           1       0.89      0.94      0.92       723\n",
      "           2       0.93      0.94      0.94      2659\n",
      "           3       0.79      0.77      0.78      1123\n",
      "           4       0.84      0.78      0.81       384\n",
      "           5       0.87      0.77      0.82        44\n",
      "           6       0.85      0.84      0.85       663\n",
      "           7       0.89      0.82      0.85        94\n",
      "           8       1.00      0.75      0.86        12\n",
      "           9       0.89      0.85      0.87       786\n",
      "          10       0.78      0.78      0.78         9\n",
      "          11       0.94      0.77      0.84        98\n",
      "          12       0.86      0.75      0.80         8\n",
      "          13       0.89      0.80      0.84        20\n",
      "          14       0.92      0.87      0.89        77\n",
      "          15       0.83      0.81      0.82        62\n",
      "          16       0.76      0.75      0.76       917\n",
      "          17       0.84      0.84      0.84       473\n",
      "          18       0.95      0.82      0.88        22\n",
      "          19       0.87      0.75      0.81       122\n",
      "          20       0.86      0.81      0.83       111\n",
      "          21       0.81      0.77      0.79       201\n",
      "          22       0.86      0.86      0.86         7\n",
      "          23       0.88      0.74      0.80        96\n",
      "          24       0.70      0.78      0.74      1045\n",
      "          25       0.73      0.79      0.76       540\n",
      "          26       0.76      0.78      0.77      1334\n",
      "          27       0.95      0.68      0.79        28\n",
      "          28       0.83      0.83      0.83        35\n",
      "          29       0.94      0.75      0.83        77\n",
      "          30       0.96      0.78      0.86        64\n",
      "          31       0.80      0.57      0.67         7\n",
      "\n",
      "    accuracy                           0.87     25746\n",
      "   macro avg       0.86      0.80      0.82     25746\n",
      "weighted avg       0.88      0.87      0.87     25746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"lead3\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"lead3\")\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.01\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_array, y_array, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_lead3.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54846ed-31bc-430c-85e0-6d212656e48b",
   "metadata": {},
   "source": [
    "#### aVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e435817e-25fc-4477-a72c-f5c760204725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">623</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">307</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4912</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">628,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │           \u001b[38;5;34m200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m623\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m1,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m307\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4912\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m628,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,880</span> (2.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m635,880\u001b[0m (2.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,528</span> (2.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m635,528\u001b[0m (2.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling data...\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Training fold 1\n",
      "\n",
      "Generating upsampling using SMOTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 20ms/step - accuracy: 0.8799 - loss: 0.4645 - val_accuracy: 1.0000 - val_loss: 0.0049\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 21ms/step - accuracy: 0.9826 - loss: 0.0571 - val_accuracy: 1.0000 - val_loss: 1.1106e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 22ms/step - accuracy: 0.9913 - loss: 0.0280 - val_accuracy: 1.0000 - val_loss: 3.2487e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 23ms/step - accuracy: 0.9939 - loss: 0.0191 - val_accuracy: 1.0000 - val_loss: 8.0107e-05\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 26ms/step - accuracy: 0.9948 - loss: 0.0175 - val_accuracy: 1.0000 - val_loss: 2.2919e-06\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 30ms/step - accuracy: 0.9957 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 7.2388e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 25ms/step - accuracy: 0.9965 - loss: 0.0114 - val_accuracy: 1.0000 - val_loss: 7.7426e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 28ms/step - accuracy: 0.9970 - loss: 0.0105 - val_accuracy: 0.9690 - val_loss: 0.0607\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 29ms/step - accuracy: 0.9972 - loss: 0.0100 - val_accuracy: 1.0000 - val_loss: 1.3506e-07\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 25ms/step - accuracy: 0.9974 - loss: 0.0084 - val_accuracy: 1.0000 - val_loss: 7.4029e-08\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 29ms/step - accuracy: 0.9974 - loss: 0.0086 - val_accuracy: 1.0000 - val_loss: 1.9619e-06\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 27ms/step - accuracy: 0.9980 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 1.7074e-06\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 27ms/step - accuracy: 0.9980 - loss: 0.0072 - val_accuracy: 0.9280 - val_loss: 0.1910\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 31ms/step - accuracy: 0.9979 - loss: 0.0084 - val_accuracy: 1.0000 - val_loss: 5.0068e-09\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 28ms/step - accuracy: 0.9982 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 1.6957e-07\n",
      "Epoch 16/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 29ms/step - accuracy: 0.9983 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 3.6032e-05\n",
      "Epoch 17/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 29ms/step - accuracy: 0.9983 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 3.8743e-09\n",
      "Epoch 18/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 28ms/step - accuracy: 0.9986 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 1.8299e-08\n",
      "Epoch 19/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 20ms/step - accuracy: 0.9984 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 5.2452e-09\n",
      "Epoch 20/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 20ms/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 1.0533e-06\n",
      "Epoch 21/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 20ms/step - accuracy: 0.9985 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 6.7412e-07\n",
      "Epoch 22/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 21ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.9985 - val_loss: 0.0071\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\n",
      "Training fold 2\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 23ms/step - accuracy: 0.9776 - loss: 0.1224 - val_accuracy: 1.0000 - val_loss: 8.6188e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 23ms/step - accuracy: 0.9959 - loss: 0.0141 - val_accuracy: 1.0000 - val_loss: 7.7724e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 26ms/step - accuracy: 0.9978 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 1.5527e-07\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 30ms/step - accuracy: 0.9981 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 7.4665e-07\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 35ms/step - accuracy: 0.9982 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 2.1368e-07\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 32ms/step - accuracy: 0.9984 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 4.4346e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 33ms/step - accuracy: 0.9981 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 9.8883e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 34ms/step - accuracy: 0.9987 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 2.0665e-07\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9986 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 2.2525e-07\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 27ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 5.3644e-10\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 30ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 4.1406e-07\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 35ms/step - accuracy: 0.9985 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 1.9371e-08\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 29ms/step - accuracy: 0.9988 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 3.1286e-06\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 34ms/step - accuracy: 0.9987 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 3.5763e-10\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 31ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 2.5630e-09\n",
      "Epoch 16/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 33ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 30ms/step - accuracy: 0.9990 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 7.8499e-08\n",
      "Epoch 18/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 31ms/step - accuracy: 0.9989 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 35ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 1.0133e-08\n",
      "Epoch 20/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 30ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 4.9834e-07\n",
      "Epoch 21/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 31ms/step - accuracy: 0.9988 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 8.3446e-09\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\n",
      "Training fold 3\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 32ms/step - accuracy: 0.9903 - loss: 0.0456 - val_accuracy: 1.0000 - val_loss: 6.9960e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 37ms/step - accuracy: 0.9977 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 2.8240e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 30ms/step - accuracy: 0.9985 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 2.5630e-09\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 35ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 5.5432e-09\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 32ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 1.4234e-07\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 33ms/step - accuracy: 0.9990 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 5.1556e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 37ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 4.1962e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 33ms/step - accuracy: 0.9990 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 1.2755e-08\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 4\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 31ms/step - accuracy: 0.9955 - loss: 0.0167 - val_accuracy: 1.0000 - val_loss: 2.5153e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 34ms/step - accuracy: 0.9982 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 4.6194e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 34ms/step - accuracy: 0.9987 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 1.1510e-07\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 34ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 3.9099e-07\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 34ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 33ms/step - accuracy: 0.9990 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 8.9526e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 40ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 0.0084\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 33ms/step - accuracy: 0.9990 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 1.7881e-10\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 33ms/step - accuracy: 0.9990 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9993 - loss: 0.0031 - val_accuracy: 0.3365 - val_loss: 4.9017\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 5\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 40ms/step - accuracy: 0.9964 - loss: 0.0144 - val_accuracy: 1.0000 - val_loss: 4.2361e-06\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 34ms/step - accuracy: 0.9984 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 2.5272e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 33ms/step - accuracy: 0.9989 - loss: 0.0042 - val_accuracy: 0.6170 - val_loss: 1.5629\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 33ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 8.1658e-09\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 40ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 1.0133e-09\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 33ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 3.5763e-10\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 35ms/step - accuracy: 0.9991 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 8.9288e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 5.8472e-08\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 38ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 5.9843e-08\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 5.0270e-07\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 34ms/step - accuracy: 0.9992 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 2.9802e-09\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 6\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 33ms/step - accuracy: 0.9973 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 35ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 4.7684e-10\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 1.7405e-08\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 34ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 1.7285e-09\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 31ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 4.5657e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 36ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 4.7684e-10\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "Training fold 7\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 34ms/step - accuracy: 0.9981 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 4.1586e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 35ms/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 3.6776e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 31ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 2.0862e-09\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 28ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 5.0664e-09\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 33ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 7.1103e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 35ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 8.0891e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 34ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 4.8101e-08\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 31ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 1.6093e-09\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 36ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 1.1182e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 32ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 5.5521e-05\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 35ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 3.8147e-09\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "Training fold 8\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 34ms/step - accuracy: 0.9977 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 2.4527e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 36ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 32ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 5.9605e-11\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 36ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 7.2718e-09\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 33ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 33ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 4.7684e-10\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 47ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 5.0664e-09\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\n",
      "Training fold 9\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 40ms/step - accuracy: 0.9982 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 6.9141e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 41ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 1.1921e-10\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 39ms/step - accuracy: 0.9994 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 4.8418e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 40ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 1.1444e-08\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 45ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 1.4663e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 46ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 2.2054e-09\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 43ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 1.6045e-07\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\n",
      "Training fold 10\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 48ms/step - accuracy: 0.9981 - loss: 0.0071 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 48ms/step - accuracy: 0.9990 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 48ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 50ms/step - accuracy: 0.9992 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 50ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 1.2100e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 52ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 1.2517e-09\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\n",
      "Time taken for training:  06:26:05\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.9995 - Test Accuracy 0.5856\n",
      "Fold 2 - Train Accuracy 0.9998 - Test Accuracy 0.7953\n",
      "Fold 3 - Train Accuracy 0.9997 - Test Accuracy 0.9553\n",
      "Fold 4 - Train Accuracy 0.9999 - Test Accuracy 0.9639\n",
      "Fold 5 - Train Accuracy 0.9997 - Test Accuracy 0.9623\n",
      "Fold 6 - Train Accuracy 0.9997 - Test Accuracy 0.9876\n",
      "Fold 7 - Train Accuracy 0.9998 - Test Accuracy 0.9810\n",
      "Fold 8 - Train Accuracy 0.9997 - Test Accuracy 0.9949\n",
      "Fold 9 - Train Accuracy 0.9999 - Test Accuracy 0.9899\n",
      "Fold 10 - Train Accuracy 0.9998 - Test Accuracy 0.9926\n",
      "\n",
      "Mean Train Accuracy: 0.9997 - Std: 0.0001 \n",
      "Mean Test Accuracy: 0.9209 - Std: 0.1250 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     13905\n",
      "           1       0.95      0.96      0.96       723\n",
      "           2       0.95      0.98      0.96      2659\n",
      "           3       0.83      0.81      0.82      1123\n",
      "           4       0.85      0.84      0.84       384\n",
      "           5       0.88      0.84      0.86        44\n",
      "           6       0.91      0.88      0.89       663\n",
      "           7       0.87      0.85      0.86        94\n",
      "           8       0.83      0.83      0.83        12\n",
      "           9       0.90      0.88      0.89       786\n",
      "          10       0.88      0.78      0.82         9\n",
      "          11       0.92      0.85      0.88        98\n",
      "          12       1.00      0.75      0.86         8\n",
      "          13       0.94      0.85      0.89        20\n",
      "          14       0.88      0.87      0.88        77\n",
      "          15       0.90      0.92      0.91        62\n",
      "          16       0.85      0.84      0.84       917\n",
      "          17       0.93      0.93      0.93       473\n",
      "          18       0.90      0.86      0.88        22\n",
      "          19       0.88      0.87      0.87       122\n",
      "          20       0.86      0.85      0.85       111\n",
      "          21       0.85      0.87      0.86       201\n",
      "          22       0.78      1.00      0.88         7\n",
      "          23       0.89      0.85      0.87        96\n",
      "          24       0.85      0.84      0.85      1045\n",
      "          25       0.85      0.86      0.85       540\n",
      "          26       0.83      0.87      0.85      1334\n",
      "          27       0.85      0.82      0.84        28\n",
      "          28       0.91      0.89      0.90        35\n",
      "          29       0.88      0.87      0.88        77\n",
      "          30       0.92      0.84      0.88        64\n",
      "          31       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.92     25746\n",
      "   macro avg       0.89      0.87      0.88     25746\n",
      "weighted avg       0.92      0.92      0.92     25746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"aVR\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"aVR\")\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.01\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_array, y_array, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_aVR.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d176951-e933-4b9c-99a2-0b8feb53f203",
   "metadata": {},
   "source": [
    "#### aVL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf2df936-284f-40ba-bc77-fac990e58f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">623</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">307</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4912</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">628,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │           \u001b[38;5;34m200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m623\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m1,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m307\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4912\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m628,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,880</span> (2.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m635,880\u001b[0m (2.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,528</span> (2.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m635,528\u001b[0m (2.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling data...\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Training fold 1\n",
      "\n",
      "Generating upsampling using SMOTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 19ms/step - accuracy: 0.8462 - loss: 0.5996 - val_accuracy: 1.0000 - val_loss: 2.1340e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 19ms/step - accuracy: 0.9768 - loss: 0.0752 - val_accuracy: 0.0000e+00 - val_loss: 10.0016\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 19ms/step - accuracy: 0.9885 - loss: 0.0379 - val_accuracy: 0.6910 - val_loss: 1.0483\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 20ms/step - accuracy: 0.9919 - loss: 0.0275 - val_accuracy: 1.0000 - val_loss: 1.3312e-05\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 22ms/step - accuracy: 0.9931 - loss: 0.0234 - val_accuracy: 0.0000e+00 - val_loss: 16.4766\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 23ms/step - accuracy: 0.9946 - loss: 0.0206 - val_accuracy: 1.0000 - val_loss: 4.2368e-05\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 26ms/step - accuracy: 0.9952 - loss: 0.0162 - val_accuracy: 1.0000 - val_loss: 4.0293e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 29ms/step - accuracy: 0.9958 - loss: 0.0143 - val_accuracy: 1.0000 - val_loss: 1.2718e-06\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 24ms/step - accuracy: 0.9963 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 4.4636e-06\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 31ms/step - accuracy: 0.9964 - loss: 0.0156 - val_accuracy: 1.0000 - val_loss: 1.5661e-06\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 28ms/step - accuracy: 0.9966 - loss: 0.0123 - val_accuracy: 0.8485 - val_loss: 0.5078\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 25ms/step - accuracy: 0.9975 - loss: 0.0084 - val_accuracy: 0.5250 - val_loss: 1.9690\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 2\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 27ms/step - accuracy: 0.9693 - loss: 0.1526 - val_accuracy: 1.0000 - val_loss: 3.0051e-06\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 25ms/step - accuracy: 0.9941 - loss: 0.0210 - val_accuracy: 1.0000 - val_loss: 6.9212e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 26ms/step - accuracy: 0.9955 - loss: 0.0171 - val_accuracy: 0.0000e+00 - val_loss: 14.1853\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 25ms/step - accuracy: 0.9964 - loss: 0.0133 - val_accuracy: 1.0000 - val_loss: 1.4851e-05\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 27ms/step - accuracy: 0.9967 - loss: 0.0118 - val_accuracy: 0.9140 - val_loss: 0.1547\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 24ms/step - accuracy: 0.9972 - loss: 0.0112 - val_accuracy: 0.0445 - val_loss: 6.7964\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 3\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 27ms/step - accuracy: 0.9877 - loss: 0.0412 - val_accuracy: 1.0000 - val_loss: 1.0245e-06\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 25ms/step - accuracy: 0.9954 - loss: 0.0177 - val_accuracy: 1.0000 - val_loss: 7.4347e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 26ms/step - accuracy: 0.9967 - loss: 0.0138 - val_accuracy: 0.9705 - val_loss: 0.0600\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 25ms/step - accuracy: 0.9969 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 4.6030e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 26ms/step - accuracy: 0.9971 - loss: 0.0103 - val_accuracy: 1.0000 - val_loss: 2.7594e-06\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 28ms/step - accuracy: 0.9977 - loss: 0.0085 - val_accuracy: 0.1360 - val_loss: 8.7255\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 4\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 27ms/step - accuracy: 0.9909 - loss: 0.0315 - val_accuracy: 1.0000 - val_loss: 3.1549e-06\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 29ms/step - accuracy: 0.9963 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 6.8896e-06\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 25ms/step - accuracy: 0.9970 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 1.3352e-06\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 29ms/step - accuracy: 0.9971 - loss: 0.0106 - val_accuracy: 0.0000e+00 - val_loss: 15.7782\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 26ms/step - accuracy: 0.9974 - loss: 0.0097 - val_accuracy: 1.0000 - val_loss: 2.8719e-05\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 28ms/step - accuracy: 0.9967 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 26ms/step - accuracy: 0.9976 - loss: 0.0086 - val_accuracy: 0.0125 - val_loss: 8.7662\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 28ms/step - accuracy: 0.9973 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 4.3404e-07\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 27ms/step - accuracy: 0.9980 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 1.0133e-09\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 29ms/step - accuracy: 0.9976 - loss: 0.0093 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 32ms/step - accuracy: 0.9979 - loss: 0.0077 - val_accuracy: 0.0000e+00 - val_loss: 12.0947\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 27ms/step - accuracy: 0.9980 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 1.1384e-08\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 31ms/step - accuracy: 0.9983 - loss: 0.0067 - val_accuracy: 0.9540 - val_loss: 0.1244\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 26ms/step - accuracy: 0.9984 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 3.5861e-06\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\n",
      "Training fold 5\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 33ms/step - accuracy: 0.9867 - loss: 0.0546 - val_accuracy: 1.0000 - val_loss: 2.4533e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 22ms/step - accuracy: 0.9970 - loss: 0.0102 - val_accuracy: 0.0170 - val_loss: 7.1454\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 20ms/step - accuracy: 0.9973 - loss: 0.0103 - val_accuracy: 1.0000 - val_loss: 1.8060e-08\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 20ms/step - accuracy: 0.9978 - loss: 0.0093 - val_accuracy: 1.0000 - val_loss: 3.6683e-05\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 21ms/step - accuracy: 0.9979 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 1.4866e-06\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 22ms/step - accuracy: 0.9980 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 2.3246e-09\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 23ms/step - accuracy: 0.9979 - loss: 0.0084 - val_accuracy: 0.2555 - val_loss: 4.2951\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 25ms/step - accuracy: 0.9983 - loss: 0.0079 - val_accuracy: 0.0000e+00 - val_loss: 23.0596\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 26ms/step - accuracy: 0.9982 - loss: 0.0074 - val_accuracy: 0.0370 - val_loss: 13.0268\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 40ms/step - accuracy: 0.9984 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 4.2471e-06\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9982 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 5.0490e-07\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\n",
      "Training fold 6\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 20ms/step - accuracy: 0.9930 - loss: 0.0257 - val_accuracy: 1.0000 - val_loss: 5.0151e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 21ms/step - accuracy: 0.9982 - loss: 0.0073 - val_accuracy: 0.9100 - val_loss: 0.4139\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 21ms/step - accuracy: 0.9984 - loss: 0.0065 - val_accuracy: 0.2130 - val_loss: 3.6631\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 22ms/step - accuracy: 0.9983 - loss: 0.0063 - val_accuracy: 0.8410 - val_loss: 0.3743\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 23ms/step - accuracy: 0.9985 - loss: 0.0060 - val_accuracy: 0.0000e+00 - val_loss: 16.3010\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 26ms/step - accuracy: 0.9986 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 3.7163e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 30ms/step - accuracy: 0.9988 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 3.7372e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 32ms/step - accuracy: 0.9984 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 7.9870e-08\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 27ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 2.1398e-08\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9987 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 1.6445e-07\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 33ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 2.6822e-09\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 31ms/step - accuracy: 0.9989 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 2.9802e-10\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 33ms/step - accuracy: 0.9989 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 1.4901e-09\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 35ms/step - accuracy: 0.9987 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 2.8253e-08\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 29ms/step - accuracy: 0.9989 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 1.7267e-07\n",
      "Epoch 16/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 32ms/step - accuracy: 0.9989 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 2.5269e-06\n",
      "Epoch 17/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 28ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 0.0000e+00 - val_loss: 23.2392\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 7\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 37ms/step - accuracy: 0.9927 - loss: 0.0285 - val_accuracy: 1.0000 - val_loss: 2.4652e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 29ms/step - accuracy: 0.9981 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 4.8485e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 32ms/step - accuracy: 0.9987 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 34ms/step - accuracy: 0.9986 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 2.7776e-08\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9987 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 2.3192e-07\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 30ms/step - accuracy: 0.9990 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 3.7193e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 31ms/step - accuracy: 0.9988 - loss: 0.0049 - val_accuracy: 0.0000e+00 - val_loss: 22.8460\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 34ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 8.9049e-07\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 8\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 34ms/step - accuracy: 0.9963 - loss: 0.0140 - val_accuracy: 1.0000 - val_loss: 2.1914e-05\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 31ms/step - accuracy: 0.9983 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 2.0087e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 32ms/step - accuracy: 0.9985 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 3.0204e-06\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 32ms/step - accuracy: 0.9986 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 2.0450e-07\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 7.1361e-06\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 34ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 4.2319e-09\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 31ms/step - accuracy: 0.9990 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 1.1921e-10\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 35ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 3.3379e-08\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 30ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 1.6394e-06\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 33ms/step - accuracy: 0.9989 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 6.5565e-10\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 0.0000e+00 - val_loss: 17.4768\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 33ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 1.3029e-07\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "Training fold 9\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9964 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 1.1128e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 35ms/step - accuracy: 0.9987 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 2.5034e-09\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 31ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 1.8090e-07\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 34ms/step - accuracy: 0.9990 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 9.5963e-09\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 6.3181e-09\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 33ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 4.9852e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 33ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 6.1393e-09\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "Training fold 10\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 38ms/step - accuracy: 0.9967 - loss: 0.0138 - val_accuracy: 1.0000 - val_loss: 3.4094e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 37ms/step - accuracy: 0.9983 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 6.8366e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 36ms/step - accuracy: 0.9989 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 1.4663e-08\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 34ms/step - accuracy: 0.9989 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 9.9698e-05\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 37ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 1.1325e-07\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 34ms/step - accuracy: 0.9989 - loss: 0.0054 - val_accuracy: 0.0205 - val_loss: 14.9208\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 40ms/step - accuracy: 0.9989 - loss: 0.0047 - val_accuracy: 0.0000e+00 - val_loss: 21.7879\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 36ms/step - accuracy: 0.9990 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 1.3173e-08\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 39ms/step - accuracy: 0.9993 - loss: 0.0035 - val_accuracy: 0.2725 - val_loss: 6.3935\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 39ms/step - accuracy: 0.9990 - loss: 0.0054 - val_accuracy: 0.2520 - val_loss: 7.6733\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 40ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 6.5565e-10\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 40ms/step - accuracy: 0.9993 - loss: 0.0032 - val_accuracy: 0.7035 - val_loss: 1.0841\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 39ms/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 4.0233e-08\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 42ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.0630 - val_loss: 7.6006\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 40ms/step - accuracy: 0.9990 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 2.8860e-07\n",
      "Epoch 16/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 40ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 1.7345e-08\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\n",
      "Time taken for training:  05:43:05\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.9972 - Test Accuracy 0.4649\n",
      "Fold 2 - Train Accuracy 0.9968 - Test Accuracy 0.8823\n",
      "Fold 3 - Train Accuracy 0.9974 - Test Accuracy 0.8936\n",
      "Fold 4 - Train Accuracy 0.9994 - Test Accuracy 0.7546\n",
      "Fold 5 - Train Accuracy 0.9990 - Test Accuracy 0.8610\n",
      "Fold 6 - Train Accuracy 0.9998 - Test Accuracy 0.8742\n",
      "Fold 7 - Train Accuracy 0.9995 - Test Accuracy 0.9569\n",
      "Fold 8 - Train Accuracy 0.9996 - Test Accuracy 0.9611\n",
      "Fold 9 - Train Accuracy 0.9997 - Test Accuracy 0.9790\n",
      "Fold 10 - Train Accuracy 0.9997 - Test Accuracy 0.9526\n",
      "\n",
      "Mean Train Accuracy: 0.9988 - Std: 0.0011 \n",
      "Mean Test Accuracy: 0.8580 - Std: 0.1454 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90     13905\n",
      "           1       0.88      0.95      0.91       723\n",
      "           2       0.92      0.95      0.93      2659\n",
      "           3       0.77      0.76      0.76      1123\n",
      "           4       0.74      0.75      0.75       384\n",
      "           5       0.80      0.82      0.81        44\n",
      "           6       0.80      0.84      0.82       663\n",
      "           7       0.80      0.83      0.81        94\n",
      "           8       0.83      0.83      0.83        12\n",
      "           9       0.79      0.87      0.83       786\n",
      "          10       0.78      0.78      0.78         9\n",
      "          11       0.88      0.71      0.79        98\n",
      "          12       0.70      0.88      0.78         8\n",
      "          13       0.94      0.80      0.86        20\n",
      "          14       0.85      0.79      0.82        77\n",
      "          15       0.85      0.90      0.88        62\n",
      "          16       0.73      0.76      0.74       917\n",
      "          17       0.79      0.90      0.84       473\n",
      "          18       0.82      0.82      0.82        22\n",
      "          19       0.80      0.77      0.79       122\n",
      "          20       0.83      0.77      0.80       111\n",
      "          21       0.79      0.75      0.77       201\n",
      "          22       0.83      0.71      0.77         7\n",
      "          23       0.88      0.79      0.84        96\n",
      "          24       0.70      0.74      0.72      1045\n",
      "          25       0.72      0.77      0.75       540\n",
      "          26       0.72      0.73      0.73      1334\n",
      "          27       0.92      0.82      0.87        28\n",
      "          28       0.88      0.83      0.85        35\n",
      "          29       0.80      0.78      0.79        77\n",
      "          30       0.94      0.78      0.85        64\n",
      "          31       0.80      0.57      0.67         7\n",
      "\n",
      "    accuracy                           0.86     25746\n",
      "   macro avg       0.82      0.80      0.81     25746\n",
      "weighted avg       0.86      0.86      0.86     25746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"aVL\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"aVL\")\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.01\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_array, y_array, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_aVL.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2208e2-0e65-456a-b89e-12edae1f335e",
   "metadata": {},
   "source": [
    "#### aVF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edc52dc0-fd6e-4fbb-8e35-49f257922c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">623</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">307</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4912</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">628,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │           \u001b[38;5;34m200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m623\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m1,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m307\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4912\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m628,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,880</span> (2.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m635,880\u001b[0m (2.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,528</span> (2.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m635,528\u001b[0m (2.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling data...\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Training fold 1\n",
      "\n",
      "Generating upsampling using SMOTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 19ms/step - accuracy: 0.8543 - loss: 0.5572 - val_accuracy: 1.0000 - val_loss: 3.7936e-05\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 20ms/step - accuracy: 0.9788 - loss: 0.0680 - val_accuracy: 1.0000 - val_loss: 1.4143e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 21ms/step - accuracy: 0.9902 - loss: 0.0323 - val_accuracy: 1.0000 - val_loss: 1.9111e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 22ms/step - accuracy: 0.9926 - loss: 0.0239 - val_accuracy: 1.0000 - val_loss: 2.9228e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 24ms/step - accuracy: 0.9938 - loss: 0.0204 - val_accuracy: 1.0000 - val_loss: 6.0293e-06\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 27ms/step - accuracy: 0.9949 - loss: 0.0161 - val_accuracy: 1.0000 - val_loss: 9.9981e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 22ms/step - accuracy: 0.9959 - loss: 0.0138 - val_accuracy: 1.0000 - val_loss: 2.0707e-06\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 27ms/step - accuracy: 0.9961 - loss: 0.0133 - val_accuracy: 1.0000 - val_loss: 1.6109e-06\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 25ms/step - accuracy: 0.9966 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 5.9664e-08\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 25ms/step - accuracy: 0.9968 - loss: 0.0109 - val_accuracy: 1.0000 - val_loss: 1.7649e-07\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 29ms/step - accuracy: 0.9969 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 5.4204e-07\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 24ms/step - accuracy: 0.9970 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 1.4763e-05\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 27ms/step - accuracy: 0.9973 - loss: 0.0096 - val_accuracy: 1.0000 - val_loss: 3.1737e-06\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 27ms/step - accuracy: 0.9979 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 2.5305e-05\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 2\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 27ms/step - accuracy: 0.9719 - loss: 0.1443 - val_accuracy: 1.0000 - val_loss: 8.4149e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 28ms/step - accuracy: 0.9955 - loss: 0.0161 - val_accuracy: 1.0000 - val_loss: 9.0943e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 25ms/step - accuracy: 0.9965 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 6.7740e-07\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 29ms/step - accuracy: 0.9977 - loss: 0.0084 - val_accuracy: 1.0000 - val_loss: 7.4106e-07\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 25ms/step - accuracy: 0.9976 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 3.5899e-05\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 27ms/step - accuracy: 0.9972 - loss: 0.0099 - val_accuracy: 1.0000 - val_loss: 5.8234e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 29ms/step - accuracy: 0.9976 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 1.8310e-07\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 25ms/step - accuracy: 0.9980 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 2.8378e-07\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 28ms/step - accuracy: 0.9980 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 1.0788e-08\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 2.7367e-05\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 28ms/step - accuracy: 0.9983 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 8.3089e-08\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 25ms/step - accuracy: 0.9984 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 3.4575e-06\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 29ms/step - accuracy: 0.9983 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 8.6325e-07\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 3\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 26ms/step - accuracy: 0.9867 - loss: 0.0564 - val_accuracy: 1.0000 - val_loss: 2.7049e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 28ms/step - accuracy: 0.9967 - loss: 0.0117 - val_accuracy: 1.0000 - val_loss: 7.8676e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 29ms/step - accuracy: 0.9979 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 2.0743e-06\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 28ms/step - accuracy: 0.9979 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 1.5144e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 30ms/step - accuracy: 0.9981 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 2.9534e-06\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 25ms/step - accuracy: 0.9985 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 9.7870e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 28ms/step - accuracy: 0.9985 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 4.9293e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 27ms/step - accuracy: 0.9985 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 4.2474e-07\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 28ms/step - accuracy: 0.9985 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 1.8060e-08\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 32ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 1.8477e-09\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 25ms/step - accuracy: 0.9985 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 1.8001e-05\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 30ms/step - accuracy: 0.9986 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 2.0802e-08\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 28ms/step - accuracy: 0.9989 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 1.5246e-05\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 27ms/step - accuracy: 0.9988 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 32ms/step - accuracy: 0.9989 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 1.5688e-07\n",
      "Epoch 16/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 6.2466e-08\n",
      "Epoch 17/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 29ms/step - accuracy: 0.9988 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 4.6968e-08\n",
      "Epoch 18/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 29ms/step - accuracy: 0.9991 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 7.8678e-09\n",
      "Epoch 19/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 27ms/step - accuracy: 0.9988 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 1.6272e-08\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 4\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 30ms/step - accuracy: 0.9905 - loss: 0.0401 - val_accuracy: 1.0000 - val_loss: 6.9737e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 28ms/step - accuracy: 0.9976 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 4.7684e-09\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 32ms/step - accuracy: 0.9981 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 1.8883e-07\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 26ms/step - accuracy: 0.9987 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 2.6333e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 31ms/step - accuracy: 0.9987 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 1.2875e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 30ms/step - accuracy: 0.9988 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 1.4245e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 28ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 5.7995e-08\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 5\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 28ms/step - accuracy: 0.9952 - loss: 0.0172 - val_accuracy: 1.0000 - val_loss: 4.5896e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 30ms/step - accuracy: 0.9982 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 2.3842e-10\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 30ms/step - accuracy: 0.9984 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 4.4942e-08\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 30ms/step - accuracy: 0.9988 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 4.5299e-08\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 30ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 4.7684e-10\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 29ms/step - accuracy: 0.9989 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 1.2517e-09\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 33ms/step - accuracy: 0.9990 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 28ms/step - accuracy: 0.9988 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 31ms/step - accuracy: 0.9989 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 7.1526e-10\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 29ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 4.4703e-09\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 30ms/step - accuracy: 0.9991 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 1.0729e-09\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\n",
      "Training fold 6\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 30ms/step - accuracy: 0.9957 - loss: 0.0152 - val_accuracy: 1.0000 - val_loss: 1.1921e-10\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 29ms/step - accuracy: 0.9984 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 5.6028e-09\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 31ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 7.6711e-08\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 33ms/step - accuracy: 0.9990 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 2.8491e-08\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 31ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 6.2682e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 33ms/step - accuracy: 0.9992 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 2.3961e-08\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 7\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 33ms/step - accuracy: 0.9972 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 3.8326e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 33ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 4.1723e-10\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 34ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 1.9646e-07\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 36ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 1.1921e-09\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 37ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 1.9371e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 37ms/step - accuracy: 0.9990 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 9.6107e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 40ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 2.9802e-10\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 38ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 1.7881e-10\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 41ms/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 1.3113e-08\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 39ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 40ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 1.0729e-09\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 43ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 39ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 41ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 44ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 7.2122e-09\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\n",
      "Training fold 8\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 44ms/step - accuracy: 0.9963 - loss: 0.0140 - val_accuracy: 1.0000 - val_loss: 7.3750e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 42ms/step - accuracy: 0.9987 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 46ms/step - accuracy: 0.9989 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 43ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 44ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 6.8545e-09\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 43ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 4.7862e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 45ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\n",
      "Training fold 9\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 45ms/step - accuracy: 0.9976 - loss: 0.0086 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 48ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 46ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 45ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 47ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 2.6703e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 47ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\n",
      "Training fold 10\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 49ms/step - accuracy: 0.9978 - loss: 0.0096 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 52ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 51ms/step - accuracy: 0.9990 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 52ms/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 53ms/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 52ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 6.8413e-06\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "\n",
      "Time taken for training:  06:08:34\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.9987 - Test Accuracy 0.5468\n",
      "Fold 2 - Train Accuracy 0.9987 - Test Accuracy 0.7410\n",
      "Fold 3 - Train Accuracy 0.9995 - Test Accuracy 0.8093\n",
      "Fold 4 - Train Accuracy 0.9995 - Test Accuracy 0.9604\n",
      "Fold 5 - Train Accuracy 0.9995 - Test Accuracy 0.9518\n",
      "Fold 6 - Train Accuracy 0.9993 - Test Accuracy 0.9849\n",
      "Fold 7 - Train Accuracy 0.9998 - Test Accuracy 0.9522\n",
      "Fold 8 - Train Accuracy 0.9998 - Test Accuracy 0.9887\n",
      "Fold 9 - Train Accuracy 0.9998 - Test Accuracy 0.9926\n",
      "Fold 10 - Train Accuracy 0.9995 - Test Accuracy 0.9915\n",
      "\n",
      "Mean Train Accuracy: 0.9994 - Std: 0.0004 \n",
      "Mean Test Accuracy: 0.8919 - Std: 0.1410 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     13905\n",
      "           1       0.89      0.94      0.92       723\n",
      "           2       0.93      0.96      0.95      2659\n",
      "           3       0.85      0.77      0.81      1123\n",
      "           4       0.83      0.79      0.81       384\n",
      "           5       0.81      0.77      0.79        44\n",
      "           6       0.94      0.83      0.88       663\n",
      "           7       0.86      0.88      0.87        94\n",
      "           8       0.67      0.83      0.74        12\n",
      "           9       0.91      0.85      0.88       786\n",
      "          10       0.78      0.78      0.78         9\n",
      "          11       0.89      0.73      0.80        98\n",
      "          12       1.00      0.75      0.86         8\n",
      "          13       0.80      0.80      0.80        20\n",
      "          14       0.90      0.82      0.86        77\n",
      "          15       0.93      0.87      0.90        62\n",
      "          16       0.76      0.77      0.77       917\n",
      "          17       0.78      0.82      0.80       473\n",
      "          18       0.95      0.82      0.88        22\n",
      "          19       0.80      0.79      0.79       122\n",
      "          20       0.89      0.86      0.88       111\n",
      "          21       0.76      0.79      0.78       201\n",
      "          22       0.88      1.00      0.93         7\n",
      "          23       0.85      0.81      0.83        96\n",
      "          24       0.79      0.79      0.79      1045\n",
      "          25       0.84      0.76      0.80       540\n",
      "          26       0.81      0.80      0.80      1334\n",
      "          27       0.89      0.86      0.87        28\n",
      "          28       0.94      0.83      0.88        35\n",
      "          29       0.83      0.87      0.85        77\n",
      "          30       0.89      0.75      0.81        64\n",
      "          31       0.71      0.71      0.71         7\n",
      "\n",
      "    accuracy                           0.89     25746\n",
      "   macro avg       0.85      0.82      0.84     25746\n",
      "weighted avg       0.89      0.89      0.89     25746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"aVF\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"aVF\")\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.01\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_array, y_array, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_aVF.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb71dcc-692a-42df-a689-fb840b30eb16",
   "metadata": {},
   "source": [
    "#### V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b835848-0532-4dc4-a4bf-f8512aceeea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">623</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">307</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4912</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">628,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │           \u001b[38;5;34m200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m623\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m1,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m307\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4912\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m628,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,880</span> (2.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m635,880\u001b[0m (2.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,528</span> (2.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m635,528\u001b[0m (2.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling data...\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Training fold 1\n",
      "\n",
      "Generating upsampling using SMOTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 22ms/step - accuracy: 0.8589 - loss: 0.5432 - val_accuracy: 1.0000 - val_loss: 3.6460e-05\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 22ms/step - accuracy: 0.9773 - loss: 0.0737 - val_accuracy: 1.0000 - val_loss: 1.0792e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 24ms/step - accuracy: 0.9888 - loss: 0.0371 - val_accuracy: 1.0000 - val_loss: 1.0710e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 27ms/step - accuracy: 0.9928 - loss: 0.0236 - val_accuracy: 1.0000 - val_loss: 1.0638e-05\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 24ms/step - accuracy: 0.9935 - loss: 0.0204 - val_accuracy: 0.9595 - val_loss: 0.0696\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 25ms/step - accuracy: 0.9948 - loss: 0.0177 - val_accuracy: 1.0000 - val_loss: 3.5447e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 26ms/step - accuracy: 0.9961 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 1.0103e-06\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 23ms/step - accuracy: 0.9962 - loss: 0.0122 - val_accuracy: 1.0000 - val_loss: 2.4119e-06\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 26ms/step - accuracy: 0.9967 - loss: 0.0113 - val_accuracy: 1.0000 - val_loss: 3.0696e-07\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 25ms/step - accuracy: 0.9965 - loss: 0.0134 - val_accuracy: 1.0000 - val_loss: 2.7844e-06\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 25ms/step - accuracy: 0.9972 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 7.7419e-07\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 27ms/step - accuracy: 0.9971 - loss: 0.0089 - val_accuracy: 0.7250 - val_loss: 0.8595\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 24ms/step - accuracy: 0.9977 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 2.3186e-07\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 26ms/step - accuracy: 0.9974 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 2.8837e-07\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 27ms/step - accuracy: 0.9978 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 2.8139e-06\n",
      "Epoch 16/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0071 - val_accuracy: 1.0000 - val_loss: 3.3632e-05\n",
      "Epoch 17/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 28ms/step - accuracy: 0.9981 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 2.3555e-07\n",
      "Epoch 18/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 26ms/step - accuracy: 0.9981 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 9.1521e-07\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 2\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 30ms/step - accuracy: 0.9729 - loss: 0.1449 - val_accuracy: 1.0000 - val_loss: 7.0106e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 27ms/step - accuracy: 0.9954 - loss: 0.0159 - val_accuracy: 1.0000 - val_loss: 2.0080e-06\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 27ms/step - accuracy: 0.9968 - loss: 0.0118 - val_accuracy: 1.0000 - val_loss: 2.0039e-07\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 30ms/step - accuracy: 0.9971 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 1.5551e-07\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 25ms/step - accuracy: 0.9976 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 3.1287e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 28ms/step - accuracy: 0.9980 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 1.1295e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 31ms/step - accuracy: 0.9980 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 9.0645e-07\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 27ms/step - accuracy: 0.9982 - loss: 0.0063 - val_accuracy: 0.7580 - val_loss: 0.8221\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 31ms/step - accuracy: 0.9982 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 1.2994e-08\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 25ms/step - accuracy: 0.9984 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 3.3736e-08\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 28ms/step - accuracy: 0.9984 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 1.9736e-06\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 29ms/step - accuracy: 0.9984 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 1.6689e-09\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 26ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 5.3644e-10\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 30ms/step - accuracy: 0.9987 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 2.4819e-07\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 28ms/step - accuracy: 0.9984 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 1.4925e-07\n",
      "Epoch 16/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 27ms/step - accuracy: 0.9986 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 6.9975e-08\n",
      "Epoch 17/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9985 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 5.1138e-07\n",
      "Epoch 18/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 27ms/step - accuracy: 0.9989 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 4.1394e-07\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\n",
      "Training fold 3\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 33ms/step - accuracy: 0.9877 - loss: 0.0554 - val_accuracy: 1.0000 - val_loss: 2.1458e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 29ms/step - accuracy: 0.9973 - loss: 0.0094 - val_accuracy: 1.0000 - val_loss: 3.9900e-06\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 29ms/step - accuracy: 0.9980 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 4.6569e-07\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 31ms/step - accuracy: 0.9982 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 28ms/step - accuracy: 0.9985 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 5.1441e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 31ms/step - accuracy: 0.9985 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 6.1393e-09\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 27ms/step - accuracy: 0.9988 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 1.1325e-09\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 30ms/step - accuracy: 0.9987 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 1.5497e-09\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 31ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 1.6749e-08\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\n",
      "Training fold 4\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 32ms/step - accuracy: 0.9943 - loss: 0.0201 - val_accuracy: 0.9995 - val_loss: 0.0061\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 31ms/step - accuracy: 0.9982 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 3.8564e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 28ms/step - accuracy: 0.9985 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 5.7817e-09\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 33ms/step - accuracy: 0.9982 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 7.7724e-08\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 31ms/step - accuracy: 0.9986 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 3.6061e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9986 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 1.0884e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 31ms/step - accuracy: 0.9986 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 1.7881e-10\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 31ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 1.8477e-09\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 37ms/step - accuracy: 0.9990 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 1.7166e-08\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 32ms/step - accuracy: 0.9990 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 1.7881e-10\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 35ms/step - accuracy: 0.9989 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 30ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 34ms/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 1.3266e-06\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 31ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 0.9800 - val_loss: 0.0773\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 33ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 1.7341e-06\n",
      "Epoch 16/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 34ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 3.8924e-06\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 5\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 36ms/step - accuracy: 0.9939 - loss: 0.0232 - val_accuracy: 1.0000 - val_loss: 4.2498e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 36ms/step - accuracy: 0.9980 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 4.6194e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 36ms/step - accuracy: 0.9987 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 3.9518e-08\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 36ms/step - accuracy: 0.9987 - loss: 0.0039 - val_accuracy: 0.3375 - val_loss: 4.2229\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 34ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 38ms/step - accuracy: 0.9989 - loss: 0.0046 - val_accuracy: 0.9430 - val_loss: 0.3099\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 34ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 2.5272e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 38ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 34ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 1.4901e-09\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 39ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "Training fold 6\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 38ms/step - accuracy: 0.9968 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 4.7684e-10\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 35ms/step - accuracy: 0.9986 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 36ms/step - accuracy: 0.9988 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 33ms/step - accuracy: 0.9991 - loss: 0.0037 - val_accuracy: 0.1625 - val_loss: 8.1164\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 36ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 37ms/step - accuracy: 0.9990 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 35ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 0.2430 - val_loss: 5.9351\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "\n",
      "Training fold 7\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 35ms/step - accuracy: 0.9977 - loss: 0.0097 - val_accuracy: 1.0000 - val_loss: 9.3519e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 38ms/step - accuracy: 0.9985 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 35ms/step - accuracy: 0.9989 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 2.7120e-08\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 37ms/step - accuracy: 0.9991 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 5.1141e-08\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 36ms/step - accuracy: 0.9990 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 5.9605e-11\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 38ms/step - accuracy: 0.9986 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 1.5585e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 36ms/step - accuracy: 0.9990 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 2.6941e-08\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 8\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 41ms/step - accuracy: 0.9979 - loss: 0.0086 - val_accuracy: 1.0000 - val_loss: 2.6226e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 34ms/step - accuracy: 0.9990 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 1.1325e-09\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 39ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 2.9110e-07\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 34ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 8.4410e-07\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 40ms/step - accuracy: 0.9991 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 1.2726e-07\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 35ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 9.8944e-09\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 42ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 0.5465 - val_loss: 1.8449\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "Training fold 9\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 44ms/step - accuracy: 0.9982 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 41ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 1.4305e-09\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 46ms/step - accuracy: 0.9992 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 42ms/step - accuracy: 0.9991 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 4.1356e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 45ms/step - accuracy: 0.9992 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 8.1837e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 49ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 1.5616e-08\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\n",
      "Training fold 10\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 51ms/step - accuracy: 0.9982 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 3.1947e-06\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 48ms/step - accuracy: 0.9989 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 3.9399e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 55ms/step - accuracy: 0.9991 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 5.3644e-10\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 56ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 1.4227e-07\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 54ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 1.3053e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 59ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 4.3213e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 59ms/step - accuracy: 0.9991 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 61ms/step - accuracy: 0.9992 - loss: 0.0036 - val_accuracy: 0.9920 - val_loss: 0.0225\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 63ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 2.5896e-06\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 65ms/step - accuracy: 0.9994 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 9.2935e-06\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 63ms/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 4.3511e-09\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 64ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 2.8610e-09\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step\n",
      "\n",
      "Time taken for training:  06:46:32\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.9986 - Test Accuracy 0.5433\n",
      "Fold 2 - Train Accuracy 0.9993 - Test Accuracy 0.7468\n",
      "Fold 3 - Train Accuracy 0.9996 - Test Accuracy 0.9200\n",
      "Fold 4 - Train Accuracy 0.9998 - Test Accuracy 0.9126\n",
      "Fold 5 - Train Accuracy 0.9997 - Test Accuracy 0.9701\n",
      "Fold 6 - Train Accuracy 0.9996 - Test Accuracy 0.9794\n",
      "Fold 7 - Train Accuracy 0.9995 - Test Accuracy 0.9872\n",
      "Fold 8 - Train Accuracy 0.9997 - Test Accuracy 0.9895\n",
      "Fold 9 - Train Accuracy 0.9997 - Test Accuracy 0.9934\n",
      "Fold 10 - Train Accuracy 0.9999 - Test Accuracy 0.9806\n",
      "\n",
      "Mean Train Accuracy: 0.9995 - Std: 0.0003 \n",
      "Mean Test Accuracy: 0.9023 - Std: 0.1390 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     13905\n",
      "           1       0.93      0.96      0.95       723\n",
      "           2       0.94      0.97      0.96      2659\n",
      "           3       0.82      0.81      0.81      1123\n",
      "           4       0.92      0.79      0.85       384\n",
      "           5       0.84      0.86      0.85        44\n",
      "           6       0.95      0.87      0.91       663\n",
      "           7       0.90      0.88      0.89        94\n",
      "           8       0.91      0.83      0.87        12\n",
      "           9       0.86      0.81      0.83       786\n",
      "          10       0.64      0.78      0.70         9\n",
      "          11       0.93      0.79      0.85        98\n",
      "          12       0.86      0.75      0.80         8\n",
      "          13       0.94      0.85      0.89        20\n",
      "          14       0.93      0.84      0.88        77\n",
      "          15       0.88      0.95      0.91        62\n",
      "          16       0.85      0.83      0.84       917\n",
      "          17       0.94      0.97      0.96       473\n",
      "          18       0.95      0.82      0.88        22\n",
      "          19       0.91      0.82      0.86       122\n",
      "          20       0.87      0.80      0.84       111\n",
      "          21       0.85      0.79      0.82       201\n",
      "          22       0.88      1.00      0.93         7\n",
      "          23       0.90      0.81      0.85        96\n",
      "          24       0.79      0.80      0.80      1045\n",
      "          25       0.84      0.80      0.82       540\n",
      "          26       0.77      0.81      0.79      1334\n",
      "          27       0.91      0.75      0.82        28\n",
      "          28       0.97      0.83      0.89        35\n",
      "          29       0.94      0.83      0.88        77\n",
      "          30       0.96      0.78      0.86        64\n",
      "          31       0.75      0.86      0.80         7\n",
      "\n",
      "    accuracy                           0.90     25746\n",
      "   macro avg       0.88      0.84      0.86     25746\n",
      "weighted avg       0.90      0.90      0.90     25746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"V1\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"V1\")\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.01\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_array, y_array, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_V1.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb5ce9b-c8da-4148-9c31-b214e86f06c9",
   "metadata": {},
   "source": [
    "#### V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02823a7a-2fe6-46ff-a389-9cda41b46cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">623</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">307</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4912</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">628,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │           \u001b[38;5;34m200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m623\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m1,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m307\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4912\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m628,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,880</span> (2.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m635,880\u001b[0m (2.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,528</span> (2.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m635,528\u001b[0m (2.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling data...\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Training fold 1\n",
      "\n",
      "Generating upsampling using SMOTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 19ms/step - accuracy: 0.8609 - loss: 0.5357 - val_accuracy: 1.0000 - val_loss: 1.2567e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 18ms/step - accuracy: 0.9775 - loss: 0.0734 - val_accuracy: 1.0000 - val_loss: 5.6552e-06\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 19ms/step - accuracy: 0.9881 - loss: 0.0388 - val_accuracy: 1.0000 - val_loss: 5.4466e-06\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 20ms/step - accuracy: 0.9923 - loss: 0.0255 - val_accuracy: 1.0000 - val_loss: 2.6996e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 21ms/step - accuracy: 0.9926 - loss: 0.0259 - val_accuracy: 1.0000 - val_loss: 1.3534e-06\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 22ms/step - accuracy: 0.9948 - loss: 0.0173 - val_accuracy: 1.0000 - val_loss: 4.0168e-05\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 23ms/step - accuracy: 0.9958 - loss: 0.0146 - val_accuracy: 1.0000 - val_loss: 2.4529e-05\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 26ms/step - accuracy: 0.9962 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 2.9429e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 30ms/step - accuracy: 0.9965 - loss: 0.0117 - val_accuracy: 1.0000 - val_loss: 6.5566e-05\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 25ms/step - accuracy: 0.9968 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 3.4975e-05\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 2\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9691 - loss: 0.1316 - val_accuracy: 1.0000 - val_loss: 1.9355e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 26ms/step - accuracy: 0.9931 - loss: 0.0227 - val_accuracy: 1.0000 - val_loss: 1.0548e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 29ms/step - accuracy: 0.9955 - loss: 0.0161 - val_accuracy: 1.0000 - val_loss: 1.1975e-07\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 32ms/step - accuracy: 0.9959 - loss: 0.0148 - val_accuracy: 1.0000 - val_loss: 2.3285e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 29ms/step - accuracy: 0.9967 - loss: 0.0108 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 30ms/step - accuracy: 0.9968 - loss: 0.0117 - val_accuracy: 1.0000 - val_loss: 1.2791e-05\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 29ms/step - accuracy: 0.9969 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 1.6421e-07\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 28ms/step - accuracy: 0.9971 - loss: 0.0101 - val_accuracy: 0.0300 - val_loss: 6.5016\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 3\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 28ms/step - accuracy: 0.9856 - loss: 0.0512 - val_accuracy: 0.9070 - val_loss: 0.3579\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 27ms/step - accuracy: 0.9956 - loss: 0.0156 - val_accuracy: 1.0000 - val_loss: 2.3181e-06\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9961 - loss: 0.0142 - val_accuracy: 0.9545 - val_loss: 0.2312\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 26ms/step - accuracy: 0.9970 - loss: 0.0113 - val_accuracy: 0.4560 - val_loss: 2.9582\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 30ms/step - accuracy: 0.9972 - loss: 0.0104 - val_accuracy: 0.5120 - val_loss: 2.4629\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 29ms/step - accuracy: 0.9972 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 28ms/step - accuracy: 0.9973 - loss: 0.0096 - val_accuracy: 0.9060 - val_loss: 0.3685\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\n",
      "Training fold 4\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 29ms/step - accuracy: 0.9901 - loss: 0.0329 - val_accuracy: 1.0000 - val_loss: 3.1365e-05\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 27ms/step - accuracy: 0.9959 - loss: 0.0154 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 31ms/step - accuracy: 0.9967 - loss: 0.0117 - val_accuracy: 1.0000 - val_loss: 1.0407e-07\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 25ms/step - accuracy: 0.9970 - loss: 0.0107 - val_accuracy: 1.0000 - val_loss: 2.5049e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 30ms/step - accuracy: 0.9972 - loss: 0.0098 - val_accuracy: 0.9905 - val_loss: 0.0214\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 30ms/step - accuracy: 0.9976 - loss: 0.0103 - val_accuracy: 1.0000 - val_loss: 4.7117e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 28ms/step - accuracy: 0.9975 - loss: 0.0103 - val_accuracy: 1.0000 - val_loss: 5.7910e-07\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9977 - loss: 0.0102 - val_accuracy: 1.0000 - val_loss: 8.3446e-10\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 33ms/step - accuracy: 0.9978 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 2.8949e-07\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 31ms/step - accuracy: 0.9979 - loss: 0.0085 - val_accuracy: 1.0000 - val_loss: 1.8626e-07\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 32ms/step - accuracy: 0.9983 - loss: 0.0071 - val_accuracy: 1.0000 - val_loss: 2.1317e-06\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 29ms/step - accuracy: 0.9982 - loss: 0.0068 - val_accuracy: 0.1320 - val_loss: 6.4215\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 34ms/step - accuracy: 0.9983 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 4.6492e-08\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "Training fold 5\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9888 - loss: 0.0431 - val_accuracy: 1.0000 - val_loss: 1.2977e-05\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 32ms/step - accuracy: 0.9967 - loss: 0.0120 - val_accuracy: 1.0000 - val_loss: 1.2565e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 29ms/step - accuracy: 0.9972 - loss: 0.0126 - val_accuracy: 1.0000 - val_loss: 6.7001e-07\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 34ms/step - accuracy: 0.9975 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 0.0178\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 31ms/step - accuracy: 0.9980 - loss: 0.0081 - val_accuracy: 0.4580 - val_loss: 2.3453\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 33ms/step - accuracy: 0.9980 - loss: 0.0108 - val_accuracy: 1.0000 - val_loss: 3.2490e-05\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 36ms/step - accuracy: 0.9983 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 3.0696e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 32ms/step - accuracy: 0.9982 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 6.8683e-06\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 35ms/step - accuracy: 0.9983 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 3.8827e-06\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 31ms/step - accuracy: 0.9987 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 2.8501e-06\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 33ms/step - accuracy: 0.9985 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 1.3256e-07\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9986 - loss: 0.0055 - val_accuracy: 0.9820 - val_loss: 0.0532\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 6\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 37ms/step - accuracy: 0.9932 - loss: 0.0236 - val_accuracy: 0.8875 - val_loss: 0.2748\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 34ms/step - accuracy: 0.9978 - loss: 0.0075 - val_accuracy: 1.0000 - val_loss: 7.9297e-06\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 33ms/step - accuracy: 0.9974 - loss: 0.0097 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9982 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 6.3008e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 35ms/step - accuracy: 0.9986 - loss: 0.0054 - val_accuracy: 0.4620 - val_loss: 2.5801\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 31ms/step - accuracy: 0.9984 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 6.6399e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 36ms/step - accuracy: 0.9986 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 6.2466e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 33ms/step - accuracy: 0.9988 - loss: 0.0042 - val_accuracy: 0.9260 - val_loss: 0.1869\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 36ms/step - accuracy: 0.9987 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 6.7714e-06\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 31ms/step - accuracy: 0.9987 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 35ms/step - accuracy: 0.9987 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 3.5703e-08\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 35ms/step - accuracy: 0.9989 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 6.0557e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 35ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 7.2641e-07\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 37ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.9075 - val_loss: 0.3349\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 36ms/step - accuracy: 0.9989 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 8.1722e-06\n",
      "Epoch 16/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 34ms/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 0.6835 - val_loss: 1.4336\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "Training fold 7\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 41ms/step - accuracy: 0.9933 - loss: 0.0272 - val_accuracy: 1.0000 - val_loss: 2.9802e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 34ms/step - accuracy: 0.9980 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 2.8074e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 39ms/step - accuracy: 0.9982 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 37ms/step - accuracy: 0.9985 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 2.4722e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 40ms/step - accuracy: 0.9986 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 1.1683e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 40ms/step - accuracy: 0.9987 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 8.2850e-09\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "\n",
      "Training fold 8\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 48ms/step - accuracy: 0.9967 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 1.3179e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 47ms/step - accuracy: 0.9984 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 5.1140e-06\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 45ms/step - accuracy: 0.9987 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 2.2769e-08\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 46ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 4.9472e-09\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 49ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 5.9605e-10\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 44ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 8.5235e-09\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 51ms/step - accuracy: 0.9990 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 7.9274e-09\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 54ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 1.8597e-08\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 46ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 59ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 6.5565e-10\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 52ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 7.8082e-09\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 51ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 4.5896e-09\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 47ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 8.9407e-10\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 53ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 1.1206e-08\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\n",
      "Training fold 9\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 58ms/step - accuracy: 0.9959 - loss: 0.0160 - val_accuracy: 1.0000 - val_loss: 1.6272e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 56ms/step - accuracy: 0.9981 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 3.5882e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 55ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.3965 - val_loss: 2.6784\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 50ms/step - accuracy: 0.9987 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 1.7719e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 60ms/step - accuracy: 0.9988 - loss: 0.0046 - val_accuracy: 0.9250 - val_loss: 0.2298\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 59ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 7.9274e-09\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 58ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 2.9974e-07\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 56ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 2.7880e-06\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 56ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 58ms/step - accuracy: 0.9991 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 2.9623e-08\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 60ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.9825 - val_loss: 0.0722\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 62ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 62ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 3.7608e-05\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 61ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 3.0654e-07\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "\n",
      "Training fold 10\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 68ms/step - accuracy: 0.9971 - loss: 0.0112 - val_accuracy: 1.0000 - val_loss: 5.9009e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 67ms/step - accuracy: 0.9985 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 7.0809e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 65ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 6.3777e-09\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 67ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 3.5763e-10\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 70ms/step - accuracy: 0.9988 - loss: 0.0052 - val_accuracy: 0.9990 - val_loss: 0.0039\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 67ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 1.0014e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 68ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 3.7307e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 69ms/step - accuracy: 0.9990 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 5.2821e-07\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 73ms/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 4.7684e-10\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step\n",
      "\n",
      "Time taken for training:  07:40:13\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.9973 - Test Accuracy 0.5227\n",
      "Fold 2 - Train Accuracy 0.9986 - Test Accuracy 0.7763\n",
      "Fold 3 - Train Accuracy 0.9986 - Test Accuracy 0.8804\n",
      "Fold 4 - Train Accuracy 0.9989 - Test Accuracy 0.7817\n",
      "Fold 5 - Train Accuracy 0.9994 - Test Accuracy 0.8835\n",
      "Fold 6 - Train Accuracy 0.9996 - Test Accuracy 0.8753\n",
      "Fold 7 - Train Accuracy 0.9992 - Test Accuracy 0.9747\n",
      "Fold 8 - Train Accuracy 0.9998 - Test Accuracy 0.9479\n",
      "Fold 9 - Train Accuracy 0.9998 - Test Accuracy 0.9510\n",
      "Fold 10 - Train Accuracy 0.9998 - Test Accuracy 0.9759\n",
      "\n",
      "Mean Train Accuracy: 0.9991 - Std: 0.0007 \n",
      "Mean Test Accuracy: 0.8570 - Std: 0.1306 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90     13905\n",
      "           1       0.90      0.95      0.93       723\n",
      "           2       0.92      0.97      0.94      2659\n",
      "           3       0.78      0.69      0.73      1123\n",
      "           4       0.82      0.73      0.77       384\n",
      "           5       0.85      0.75      0.80        44\n",
      "           6       0.78      0.79      0.79       663\n",
      "           7       0.87      0.81      0.84        94\n",
      "           8       0.90      0.75      0.82        12\n",
      "           9       0.83      0.75      0.79       786\n",
      "          10       1.00      0.56      0.71         9\n",
      "          11       0.86      0.71      0.78        98\n",
      "          12       0.86      0.75      0.80         8\n",
      "          13       0.94      0.80      0.86        20\n",
      "          14       0.79      0.77      0.78        77\n",
      "          15       0.88      0.90      0.89        62\n",
      "          16       0.72      0.74      0.73       917\n",
      "          17       0.87      0.88      0.87       473\n",
      "          18       0.79      0.86      0.83        22\n",
      "          19       0.85      0.66      0.75       122\n",
      "          20       0.88      0.68      0.77       111\n",
      "          21       0.81      0.73      0.77       201\n",
      "          22       0.64      1.00      0.78         7\n",
      "          23       0.87      0.64      0.73        96\n",
      "          24       0.75      0.73      0.74      1045\n",
      "          25       0.72      0.74      0.73       540\n",
      "          26       0.67      0.74      0.70      1334\n",
      "          27       0.77      0.61      0.68        28\n",
      "          28       0.86      0.91      0.89        35\n",
      "          29       0.78      0.74      0.76        77\n",
      "          30       0.80      0.81      0.81        64\n",
      "          31       0.71      0.71      0.71         7\n",
      "\n",
      "    accuracy                           0.86     25746\n",
      "   macro avg       0.82      0.77      0.79     25746\n",
      "weighted avg       0.86      0.86      0.86     25746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"V2\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"V2\")\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.01\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_array, y_array, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_V2.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94d85e3-d80b-4382-a810-5f7459e324e3",
   "metadata": {},
   "source": [
    "#### V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acf30b68-13b9-4d3e-bb39-b83a0f5c003f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">623</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">307</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4912</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">628,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │           \u001b[38;5;34m200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m623\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m1,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m307\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4912\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m628,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,880</span> (2.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m635,880\u001b[0m (2.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,528</span> (2.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m635,528\u001b[0m (2.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling data...\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Training fold 1\n",
      "\n",
      "Generating upsampling using SMOTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 22ms/step - accuracy: 0.8753 - loss: 0.4836 - val_accuracy: 1.0000 - val_loss: 7.0468e-05\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 23ms/step - accuracy: 0.9801 - loss: 0.0640 - val_accuracy: 1.0000 - val_loss: 5.4050e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 25ms/step - accuracy: 0.9903 - loss: 0.0310 - val_accuracy: 1.0000 - val_loss: 9.6077e-06\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 29ms/step - accuracy: 0.9932 - loss: 0.0216 - val_accuracy: 1.0000 - val_loss: 1.3462e-05\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 27ms/step - accuracy: 0.9952 - loss: 0.0152 - val_accuracy: 1.0000 - val_loss: 1.7558e-05\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 25ms/step - accuracy: 0.9957 - loss: 0.0137 - val_accuracy: 1.0000 - val_loss: 4.3060e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 29ms/step - accuracy: 0.9963 - loss: 0.0121 - val_accuracy: 1.0000 - val_loss: 7.9951e-07\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 27ms/step - accuracy: 0.9969 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 3.4368e-07\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 27ms/step - accuracy: 0.9968 - loss: 0.0098 - val_accuracy: 1.0000 - val_loss: 1.3135e-05\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 29ms/step - accuracy: 0.9974 - loss: 0.0081 - val_accuracy: 1.0000 - val_loss: 4.5849e-05\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 25ms/step - accuracy: 0.9975 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 8.7738e-08\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 28ms/step - accuracy: 0.9974 - loss: 0.0086 - val_accuracy: 1.0000 - val_loss: 1.3161e-07\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 30ms/step - accuracy: 0.9981 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 4.7618e-07\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 27ms/step - accuracy: 0.9976 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 9.4338e-06\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 30ms/step - accuracy: 0.9979 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 1.2511e-07\n",
      "Epoch 16/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 25ms/step - accuracy: 0.9980 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 5.3883e-08\n",
      "Epoch 17/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 29ms/step - accuracy: 0.9985 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 2.1219e-08\n",
      "Epoch 18/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 31ms/step - accuracy: 0.9982 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 2.3723e-08\n",
      "Epoch 19/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 27ms/step - accuracy: 0.9984 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 2.5743e-07\n",
      "Epoch 20/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 29ms/step - accuracy: 0.9981 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 3.1108e-07\n",
      "Epoch 21/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 25ms/step - accuracy: 0.9985 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 4.5896e-09\n",
      "Epoch 22/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 28ms/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 23/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 30ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 4.1723e-10\n",
      "Epoch 24/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 27ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 1.1861e-08\n",
      "Epoch 25/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 31ms/step - accuracy: 0.9986 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 3.0398e-09\n",
      "Epoch 26/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 28ms/step - accuracy: 0.9988 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 2.8014e-09\n",
      "Epoch 27/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 28ms/step - accuracy: 0.9987 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 9.7752e-09\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 2\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 29ms/step - accuracy: 0.9743 - loss: 0.1556 - val_accuracy: 1.0000 - val_loss: 2.3925e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 30ms/step - accuracy: 0.9942 - loss: 0.0234 - val_accuracy: 1.0000 - val_loss: 2.9206e-09\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9975 - loss: 0.0097 - val_accuracy: 1.0000 - val_loss: 4.9472e-09\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 28ms/step - accuracy: 0.9981 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 4.1902e-08\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 31ms/step - accuracy: 0.9986 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 3.8624e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 29ms/step - accuracy: 0.9987 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 3.7932e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 30ms/step - accuracy: 0.9984 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 4.0119e-07\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 3\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 30ms/step - accuracy: 0.9917 - loss: 0.0314 - val_accuracy: 1.0000 - val_loss: 4.3970e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 30ms/step - accuracy: 0.9974 - loss: 0.0097 - val_accuracy: 1.0000 - val_loss: 2.1279e-06\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9980 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 4.6849e-08\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 28ms/step - accuracy: 0.9984 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 3.5504e-05\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 33ms/step - accuracy: 0.9984 - loss: 0.0094 - val_accuracy: 1.0000 - val_loss: 1.1027e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 29ms/step - accuracy: 0.9985 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 2.7001e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 32ms/step - accuracy: 0.9989 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 31ms/step - accuracy: 0.9988 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 2.4862e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 31ms/step - accuracy: 0.9986 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 1.2517e-09\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 33ms/step - accuracy: 0.9986 - loss: 0.0081 - val_accuracy: 1.0000 - val_loss: 2.9802e-10\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 29ms/step - accuracy: 0.9987 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 1.0133e-09\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 33ms/step - accuracy: 0.9987 - loss: 0.0071 - val_accuracy: 1.0000 - val_loss: 2.0981e-08\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 4\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 30ms/step - accuracy: 0.9933 - loss: 0.0250 - val_accuracy: 1.0000 - val_loss: 7.0930e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 34ms/step - accuracy: 0.9974 - loss: 0.0139 - val_accuracy: 1.0000 - val_loss: 4.9292e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 27ms/step - accuracy: 0.9987 - loss: 0.0067 - val_accuracy: 0.0000e+00 - val_loss: 13.1193\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9987 - loss: 0.0055 - val_accuracy: 0.5635 - val_loss: 1.9065\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 35ms/step - accuracy: 0.9986 - loss: 0.0071 - val_accuracy: 1.0000 - val_loss: 4.5488e-07\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 31ms/step - accuracy: 0.9986 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 1.1414e-06\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "Training fold 5\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 31ms/step - accuracy: 0.9954 - loss: 0.0178 - val_accuracy: 1.0000 - val_loss: 4.8058e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 31ms/step - accuracy: 0.9984 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 2.6094e-06\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 31ms/step - accuracy: 0.9988 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 1.1861e-07\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 29ms/step - accuracy: 0.9987 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 2.9802e-10\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 34ms/step - accuracy: 0.9990 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 2.3355e-06\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 28ms/step - accuracy: 0.9988 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 1.7226e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 32ms/step - accuracy: 0.9988 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 1.9431e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 28ms/step - accuracy: 0.9987 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 2.3246e-09\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 32ms/step - accuracy: 0.9988 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 4.5240e-08\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 6\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 30ms/step - accuracy: 0.9963 - loss: 0.0138 - val_accuracy: 1.0000 - val_loss: 1.4901e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 31ms/step - accuracy: 0.9984 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 1.0069e-06\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 29ms/step - accuracy: 0.9990 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 4.1723e-09\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 31ms/step - accuracy: 0.9991 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 31ms/step - accuracy: 0.9990 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 9.8348e-09\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 31ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 0.0000e+00 - val_loss: 14.8257\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 31ms/step - accuracy: 0.9992 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 2.0802e-07\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 30ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 7.7486e-09\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 8.3446e-10\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 7\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 31ms/step - accuracy: 0.9968 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 1.5497e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 31ms/step - accuracy: 0.9987 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 31ms/step - accuracy: 0.9985 - loss: 0.0070 - val_accuracy: 0.0000e+00 - val_loss: 13.4492\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 31ms/step - accuracy: 0.9988 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 2.5451e-08\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 31ms/step - accuracy: 0.9990 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 7.8261e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 29ms/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 2.3425e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 31ms/step - accuracy: 0.9990 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 4.3511e-09\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 8\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 32ms/step - accuracy: 0.9972 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 6.6757e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 32ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9990 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 1.2070e-07\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 31ms/step - accuracy: 0.9990 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 9.5069e-08\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 3.8624e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 31ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 33ms/step - accuracy: 0.9992 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 1.4004e-06\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 30ms/step - accuracy: 0.9991 - loss: 0.0045 - val_accuracy: 0.9950 - val_loss: 0.0232\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 8.9407e-10\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 31ms/step - accuracy: 0.9993 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 1.7047e-08\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 9\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 34ms/step - accuracy: 0.9971 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 7.1526e-10\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 29ms/step - accuracy: 0.9989 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 8.0466e-09\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 30ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 2.4617e-08\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 33ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 1.0729e-09\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 32ms/step - accuracy: 0.9990 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 2.3007e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 33ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 2.4736e-08\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 10\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 37ms/step - accuracy: 0.9978 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 1.2415e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 39ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 1.9073e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 36ms/step - accuracy: 0.9991 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 4.1723e-10\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 37ms/step - accuracy: 0.9989 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 3.7968e-08\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 39ms/step - accuracy: 0.9989 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 5.9605e-11\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 39ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.8885 - val_loss: 0.4616\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 41ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 1.6850e-06\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 38ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 9.7156e-09\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 42ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 5.3644e-09\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 41ms/step - accuracy: 0.9993 - loss: 0.0035 - val_accuracy: 0.9975 - val_loss: 0.0060\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "\n",
      "Time taken for training:  05:44:09\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.9996 - Test Accuracy 0.5592\n",
      "Fold 2 - Train Accuracy 0.9985 - Test Accuracy 0.9021\n",
      "Fold 3 - Train Accuracy 0.9983 - Test Accuracy 0.8509\n",
      "Fold 4 - Train Accuracy 0.9923 - Test Accuracy 0.8835\n",
      "Fold 5 - Train Accuracy 0.9995 - Test Accuracy 0.9460\n",
      "Fold 6 - Train Accuracy 0.9996 - Test Accuracy 0.9608\n",
      "Fold 7 - Train Accuracy 0.9996 - Test Accuracy 0.9767\n",
      "Fold 8 - Train Accuracy 0.9998 - Test Accuracy 0.9685\n",
      "Fold 9 - Train Accuracy 0.9998 - Test Accuracy 0.9821\n",
      "Fold 10 - Train Accuracy 0.9997 - Test Accuracy 0.9736\n",
      "\n",
      "Mean Train Accuracy: 0.9987 - Std: 0.0022 \n",
      "Mean Test Accuracy: 0.9003 - Std: 0.1214 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     13905\n",
      "           1       0.90      0.97      0.93       723\n",
      "           2       0.96      0.97      0.96      2659\n",
      "           3       0.81      0.85      0.83      1123\n",
      "           4       0.88      0.82      0.85       384\n",
      "           5       0.95      0.86      0.90        44\n",
      "           6       0.87      0.87      0.87       663\n",
      "           7       0.95      0.89      0.92        94\n",
      "           8       0.79      0.92      0.85        12\n",
      "           9       0.78      0.86      0.82       786\n",
      "          10       1.00      0.89      0.94         9\n",
      "          11       0.92      0.81      0.86        98\n",
      "          12       0.75      0.75      0.75         8\n",
      "          13       1.00      0.90      0.95        20\n",
      "          14       0.88      0.86      0.87        77\n",
      "          15       0.86      0.89      0.87        62\n",
      "          16       0.74      0.86      0.80       917\n",
      "          17       0.86      0.89      0.88       473\n",
      "          18       0.90      0.86      0.88        22\n",
      "          19       0.91      0.89      0.90       122\n",
      "          20       0.87      0.85      0.86       111\n",
      "          21       0.88      0.86      0.87       201\n",
      "          22       0.70      1.00      0.82         7\n",
      "          23       0.83      0.83      0.83        96\n",
      "          24       0.78      0.83      0.81      1045\n",
      "          25       0.83      0.81      0.82       540\n",
      "          26       0.83      0.79      0.81      1334\n",
      "          27       0.86      0.89      0.88        28\n",
      "          28       1.00      0.94      0.97        35\n",
      "          29       0.93      0.86      0.89        77\n",
      "          30       0.98      0.88      0.93        64\n",
      "          31       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.90     25746\n",
      "   macro avg       0.88      0.87      0.87     25746\n",
      "weighted avg       0.90      0.90      0.90     25746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"V3\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"V3\")\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.01\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_array, y_array, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_V3.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5c04d8-ecce-4f37-a589-6241f436d375",
   "metadata": {},
   "source": [
    "#### V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46d5bb04-8192-4d41-a718-524175becc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">623</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">307</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4912</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">628,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │           \u001b[38;5;34m200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m623\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m1,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m307\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4912\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m628,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,880</span> (2.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m635,880\u001b[0m (2.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,528</span> (2.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m635,528\u001b[0m (2.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling data...\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Training fold 1\n",
      "\n",
      "Generating upsampling using SMOTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 21ms/step - accuracy: 0.8822 - loss: 0.4603 - val_accuracy: 1.0000 - val_loss: 1.7318e-05\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 21ms/step - accuracy: 0.9812 - loss: 0.0616 - val_accuracy: 1.0000 - val_loss: 3.9636e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 24ms/step - accuracy: 0.9899 - loss: 0.0333 - val_accuracy: 1.0000 - val_loss: 7.5164e-06\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 25ms/step - accuracy: 0.9935 - loss: 0.0211 - val_accuracy: 1.0000 - val_loss: 2.7410e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 24ms/step - accuracy: 0.9952 - loss: 0.0161 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 24ms/step - accuracy: 0.9962 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 4.6711e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 26ms/step - accuracy: 0.9963 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 1.5150e-06\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 23ms/step - accuracy: 0.9966 - loss: 0.0113 - val_accuracy: 1.0000 - val_loss: 5.7476e-06\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 26ms/step - accuracy: 0.9972 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 3.1411e-07\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 25ms/step - accuracy: 0.9974 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 3.9995e-08\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 24ms/step - accuracy: 0.9977 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 2.3246e-09\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 28ms/step - accuracy: 0.9976 - loss: 0.0085 - val_accuracy: 1.0000 - val_loss: 1.7868e-06\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 25ms/step - accuracy: 0.9979 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 8.2970e-08\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 25ms/step - accuracy: 0.9981 - loss: 0.0058 - val_accuracy: 0.6665 - val_loss: 1.2254\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 28ms/step - accuracy: 0.9982 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 9.9687e-07\n",
      "Epoch 16/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 24ms/step - accuracy: 0.9980 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 3.9380e-07\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 2\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 29ms/step - accuracy: 0.9763 - loss: 0.1166 - val_accuracy: 1.0000 - val_loss: 7.9334e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 27ms/step - accuracy: 0.9955 - loss: 0.0158 - val_accuracy: 1.0000 - val_loss: 1.1719e-06\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 25ms/step - accuracy: 0.9974 - loss: 0.0096 - val_accuracy: 1.0000 - val_loss: 4.5004e-05\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 29ms/step - accuracy: 0.9976 - loss: 0.0083 - val_accuracy: 1.0000 - val_loss: 1.6809e-08\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 25ms/step - accuracy: 0.9981 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 2.5427e-07\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 27ms/step - accuracy: 0.9980 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 9.0954e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 29ms/step - accuracy: 0.9980 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 2.8729e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 24ms/step - accuracy: 0.9984 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 6.9856e-08\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 28ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 6.2524e-07\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\n",
      "Training fold 3\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 27ms/step - accuracy: 0.9907 - loss: 0.0361 - val_accuracy: 1.0000 - val_loss: 4.0652e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 28ms/step - accuracy: 0.9972 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 8.9425e-06\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 28ms/step - accuracy: 0.9980 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 5.7344e-05\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 25ms/step - accuracy: 0.9982 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 1.1572e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 30ms/step - accuracy: 0.9986 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 4.2975e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 29ms/step - accuracy: 0.9985 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 2.3552e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 28ms/step - accuracy: 0.9983 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 4.9638e-07\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 30ms/step - accuracy: 0.9987 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 3.0529e-07\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 26ms/step - accuracy: 0.9984 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 1.4955e-05\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 30ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 1.5074e-07\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 4\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 29ms/step - accuracy: 0.9932 - loss: 0.0240 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 29ms/step - accuracy: 0.9979 - loss: 0.0066 - val_accuracy: 0.8915 - val_loss: 0.2867\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 31ms/step - accuracy: 0.9980 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 1.9452e-05\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 28ms/step - accuracy: 0.9984 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 8.7798e-08\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9986 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 3.0601e-07\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 33ms/step - accuracy: 0.9990 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 3.4547e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 31ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 1.9324e-07\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 32ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 2.1935e-08\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 30ms/step - accuracy: 0.9987 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 1.7488e-07\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 35ms/step - accuracy: 0.9989 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 1.1325e-09\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 31ms/step - accuracy: 0.9988 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 1.7138e-06\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 33ms/step - accuracy: 0.9990 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 2.2054e-06\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 33ms/step - accuracy: 0.9990 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 3.8795e-06\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 33ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 7.9870e-09\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 31ms/step - accuracy: 0.9991 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9989 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 1.7583e-08\n",
      "Epoch 17/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 40ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 6.7353e-08\n",
      "Epoch 18/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 36ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 7.3850e-08\n",
      "Epoch 19/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 37ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 1.2681e-06\n",
      "Epoch 20/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 33ms/step - accuracy: 0.9989 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 1.5497e-09\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "Training fold 5\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 37ms/step - accuracy: 0.9924 - loss: 0.0294 - val_accuracy: 1.0000 - val_loss: 8.9565e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 39ms/step - accuracy: 0.9982 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 1.2642e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 39ms/step - accuracy: 0.9990 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 40ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 1.9610e-08\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 36ms/step - accuracy: 0.9989 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 3.5167e-09\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 42ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 9.9540e-09\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 38ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 9.2327e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 41ms/step - accuracy: 0.9989 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 1.9252e-08\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "Training fold 6\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 45ms/step - accuracy: 0.9964 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 5.0068e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 42ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 0.8965 - val_loss: 0.1819\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 45ms/step - accuracy: 0.9989 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 44ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 1.2040e-08\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 45ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 1.5134e-06\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 42ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 1.5116e-06\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\n",
      "Training fold 7\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 43ms/step - accuracy: 0.9975 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 1.1610e-06\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 47ms/step - accuracy: 0.9991 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 1.7357e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 46ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 9.5367e-10\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 47ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 1.6034e-08\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 51ms/step - accuracy: 0.9987 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 1.7881e-09\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 47ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 3.2902e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 53ms/step - accuracy: 0.9993 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 1.2821e-07\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 55ms/step - accuracy: 0.9991 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 2.1070e-05\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "\n",
      "Training fold 8\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 57ms/step - accuracy: 0.9978 - loss: 0.0081 - val_accuracy: 1.0000 - val_loss: 1.2457e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 57ms/step - accuracy: 0.9989 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 9.8418e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 53ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 1.2552e-06\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 52ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 5.6228e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 57ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 5.4479e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 59ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 3.0398e-08\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n",
      "\n",
      "Training fold 9\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 66ms/step - accuracy: 0.9980 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 2.5034e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 59ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 1.6260e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 61ms/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 59ms/step - accuracy: 0.9993 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 4.3035e-08\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 65ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 2.0862e-09\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 69ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 5.9605e-11\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 67ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 65ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "\n",
      "Training fold 10\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 69ms/step - accuracy: 0.9982 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 4.5300e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 71ms/step - accuracy: 0.9993 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 1.2279e-08\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 68ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 73ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 1.5974e-08\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 75ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.8225 - val_loss: 0.5092\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 74ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 2.0316e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 74ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 1.6630e-08\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 75ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 1.0509e-05\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "\n",
      "Time taken for training:  07:00:02\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.9971 - Test Accuracy 0.5806\n",
      "Fold 2 - Train Accuracy 0.9993 - Test Accuracy 0.8427\n",
      "Fold 3 - Train Accuracy 0.9997 - Test Accuracy 0.8808\n",
      "Fold 4 - Train Accuracy 0.9995 - Test Accuracy 0.8299\n",
      "Fold 5 - Train Accuracy 0.9996 - Test Accuracy 0.9561\n",
      "Fold 6 - Train Accuracy 0.9995 - Test Accuracy 0.9771\n",
      "Fold 7 - Train Accuracy 0.9997 - Test Accuracy 0.9829\n",
      "Fold 8 - Train Accuracy 0.9996 - Test Accuracy 0.9907\n",
      "Fold 9 - Train Accuracy 0.9998 - Test Accuracy 0.9810\n",
      "Fold 10 - Train Accuracy 0.9995 - Test Accuracy 0.9767\n",
      "\n",
      "Mean Train Accuracy: 0.9993 - Std: 0.0008 \n",
      "Mean Test Accuracy: 0.8998 - Std: 0.1213 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     13905\n",
      "           1       0.92      0.95      0.93       723\n",
      "           2       0.93      0.97      0.95      2659\n",
      "           3       0.87      0.75      0.80      1123\n",
      "           4       0.87      0.75      0.81       384\n",
      "           5       0.92      0.75      0.82        44\n",
      "           6       0.90      0.80      0.85       663\n",
      "           7       0.87      0.85      0.86        94\n",
      "           8       0.80      0.67      0.73        12\n",
      "           9       0.84      0.82      0.83       786\n",
      "          10       1.00      0.78      0.88         9\n",
      "          11       0.87      0.84      0.85        98\n",
      "          12       0.86      0.75      0.80         8\n",
      "          13       1.00      0.85      0.92        20\n",
      "          14       0.81      0.82      0.81        77\n",
      "          15       0.82      0.90      0.86        62\n",
      "          16       0.84      0.79      0.82       917\n",
      "          17       0.83      0.90      0.86       473\n",
      "          18       0.91      0.91      0.91        22\n",
      "          19       0.86      0.84      0.85       122\n",
      "          20       0.82      0.80      0.81       111\n",
      "          21       0.80      0.77      0.78       201\n",
      "          22       0.88      1.00      0.93         7\n",
      "          23       0.81      0.85      0.83        96\n",
      "          24       0.77      0.79      0.78      1045\n",
      "          25       0.80      0.83      0.82       540\n",
      "          26       0.86      0.80      0.82      1334\n",
      "          27       0.86      0.86      0.86        28\n",
      "          28       0.70      0.94      0.80        35\n",
      "          29       0.96      0.84      0.90        77\n",
      "          30       0.84      0.80      0.82        64\n",
      "          31       0.80      0.57      0.67         7\n",
      "\n",
      "    accuracy                           0.90     25746\n",
      "   macro avg       0.86      0.83      0.84     25746\n",
      "weighted avg       0.90      0.90      0.90     25746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"V4\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"V4\")\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.01\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_array, y_array, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_V4.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4393b94-adff-4999-bc4a-f800ed79665e",
   "metadata": {},
   "source": [
    "#### V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53694cdc-fc20-4759-9fc5-94ed8992946f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">623</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">307</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4912</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">628,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │           \u001b[38;5;34m200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m623\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m1,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m307\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4912\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m628,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,880</span> (2.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m635,880\u001b[0m (2.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,528</span> (2.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m635,528\u001b[0m (2.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling data...\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Training fold 1\n",
      "\n",
      "Generating upsampling using SMOTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 19ms/step - accuracy: 0.8817 - loss: 0.4577 - val_accuracy: 0.9545 - val_loss: 0.1106\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 19ms/step - accuracy: 0.9800 - loss: 0.0679 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 20ms/step - accuracy: 0.9896 - loss: 0.0345 - val_accuracy: 1.0000 - val_loss: 1.5738e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 20ms/step - accuracy: 0.9927 - loss: 0.0255 - val_accuracy: 1.0000 - val_loss: 0.0053\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 21ms/step - accuracy: 0.9937 - loss: 0.0210 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 23ms/step - accuracy: 0.9956 - loss: 0.0144 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 24ms/step - accuracy: 0.9962 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 1.3492e-05\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 28ms/step - accuracy: 0.9969 - loss: 0.0101 - val_accuracy: 1.0000 - val_loss: 9.4831e-08\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 27ms/step - accuracy: 0.9969 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 3.2350e-05\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 27ms/step - accuracy: 0.9972 - loss: 0.0093 - val_accuracy: 1.0000 - val_loss: 2.2272e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 32ms/step - accuracy: 0.9973 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 4.0073e-06\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 28ms/step - accuracy: 0.9974 - loss: 0.0081 - val_accuracy: 1.0000 - val_loss: 1.4386e-05\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 29ms/step - accuracy: 0.9979 - loss: 0.0072 - val_accuracy: 0.9790 - val_loss: 0.0349\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "Training fold 2\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 30ms/step - accuracy: 0.9776 - loss: 0.0982 - val_accuracy: 0.9365 - val_loss: 0.1543\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 31ms/step - accuracy: 0.9955 - loss: 0.0160 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 31ms/step - accuracy: 0.9970 - loss: 0.0108 - val_accuracy: 0.9580 - val_loss: 0.1334\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 28ms/step - accuracy: 0.9977 - loss: 0.0081 - val_accuracy: 0.9600 - val_loss: 0.1503\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 33ms/step - accuracy: 0.9977 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 1.0557e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 28ms/step - accuracy: 0.9978 - loss: 0.0081 - val_accuracy: 1.0000 - val_loss: 1.4993e-05\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9981 - loss: 0.0063 - val_accuracy: 0.9660 - val_loss: 0.0846\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 33ms/step - accuracy: 0.9982 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 7.9855e-06\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 30ms/step - accuracy: 0.9980 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 5.4617e-05\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 35ms/step - accuracy: 0.9984 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 1.2888e-06\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 29ms/step - accuracy: 0.9982 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 2.6275e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 30ms/step - accuracy: 0.9983 - loss: 0.0063 - val_accuracy: 0.0000e+00 - val_loss: 14.7826\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 19ms/step - accuracy: 0.9985 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 20ms/step - accuracy: 0.9986 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 9.1725e-05\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 21ms/step - accuracy: 0.9987 - loss: 0.0048 - val_accuracy: 0.8350 - val_loss: 0.5975\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\n",
      "Training fold 3\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 27ms/step - accuracy: 0.9884 - loss: 0.0481 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 27ms/step - accuracy: 0.9974 - loss: 0.0085 - val_accuracy: 0.1650 - val_loss: 3.9827\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 31ms/step - accuracy: 0.9976 - loss: 0.0078 - val_accuracy: 0.9875 - val_loss: 0.0304\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 35ms/step - accuracy: 0.9981 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 34ms/step - accuracy: 0.9984 - loss: 0.0055 - val_accuracy: 0.8775 - val_loss: 0.5220\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 35ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.0000e+00 - val_loss: 13.6999\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\n",
      "Training fold 4\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 36ms/step - accuracy: 0.9938 - loss: 0.0214 - val_accuracy: 1.0000 - val_loss: 7.0058e-05\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 36ms/step - accuracy: 0.9976 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 31ms/step - accuracy: 0.9981 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 5.7101e-08\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 38ms/step - accuracy: 0.9982 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 7.7863e-06\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 34ms/step - accuracy: 0.9984 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 2.1329e-06\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 43ms/step - accuracy: 0.9985 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 1.3274e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 36ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 0.8610 - val_loss: 0.5660\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 51ms/step - accuracy: 0.9986 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 2.9962e-05\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "Training fold 5\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 42ms/step - accuracy: 0.9950 - loss: 0.0169 - val_accuracy: 1.0000 - val_loss: 3.0267e-07\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 32ms/step - accuracy: 0.9983 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 1.2093e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 39ms/step - accuracy: 0.9985 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 2.7557e-06\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 38ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 1.6868e-07\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 39ms/step - accuracy: 0.9986 - loss: 0.0055 - val_accuracy: 0.1440 - val_loss: 4.4645\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 34ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 3.0420e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 42ms/step - accuracy: 0.9987 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 2.5630e-09\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 33ms/step - accuracy: 0.9987 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 2.4801e-07\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 40ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.7380 - val_loss: 0.8512\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 33ms/step - accuracy: 0.9990 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 32ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.7835 - val_loss: 0.9787\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 21ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 2.7359e-08\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 22ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 2.0908e-05\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 23ms/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 1.6451e-08\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 23ms/step - accuracy: 0.9990 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 2.1458e-09\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\n",
      "Training fold 6\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 32ms/step - accuracy: 0.9944 - loss: 0.0204 - val_accuracy: 1.0000 - val_loss: 3.8743e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 33ms/step - accuracy: 0.9982 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 1.0723e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 40ms/step - accuracy: 0.9985 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 37ms/step - accuracy: 0.9987 - loss: 0.0052 - val_accuracy: 0.9715 - val_loss: 0.0660\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 39ms/step - accuracy: 0.9990 - loss: 0.0033 - val_accuracy: 0.8955 - val_loss: 0.3873\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 39ms/step - accuracy: 0.9990 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 2.8849e-05\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 39ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 0.9815 - val_loss: 0.0354\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 34ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.0000e+00 - val_loss: 13.1884\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\n",
      "Training fold 7\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 36ms/step - accuracy: 0.9968 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 6.7891e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 36ms/step - accuracy: 0.9987 - loss: 0.0049 - val_accuracy: 0.3475 - val_loss: 3.4103\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 37ms/step - accuracy: 0.9988 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 1.0133e-08\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 36ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.9140 - val_loss: 0.1870\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 38ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 0.5775 - val_loss: 2.3819\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 38ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 1.5825e-07\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 38ms/step - accuracy: 0.9990 - loss: 0.0042 - val_accuracy: 0.9985 - val_loss: 0.0050\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 39ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.0000e+00 - val_loss: 12.9681\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "\n",
      "Training fold 8\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 45ms/step - accuracy: 0.9974 - loss: 0.0096 - val_accuracy: 1.0000 - val_loss: 4.5300e-09\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 40ms/step - accuracy: 0.9985 - loss: 0.0051 - val_accuracy: 0.0810 - val_loss: 6.9271\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 43ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 0.4885 - val_loss: 2.3387\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 43ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 0.1050 - val_loss: 5.2587\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 47ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 9.9003e-08\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 45ms/step - accuracy: 0.9987 - loss: 0.0046 - val_accuracy: 0.5295 - val_loss: 2.2858\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "\n",
      "Training fold 9\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 49ms/step - accuracy: 0.9977 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 1.0377e-06\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 50ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 1.0108e-06\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 50ms/step - accuracy: 0.9990 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 49ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 1.6093e-09\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 50ms/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 0.9980 - val_loss: 0.0115\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 54ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.7900 - val_loss: 0.8146\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 52ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 50ms/step - accuracy: 0.9991 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 2.7180e-08\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step\n",
      "\n",
      "Training fold 10\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 56ms/step - accuracy: 0.9977 - loss: 0.0081 - val_accuracy: 0.9670 - val_loss: 0.1117\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 58ms/step - accuracy: 0.9987 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 1.0609e-06\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 62ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 3.6359e-09\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 60ms/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 2.5630e-09\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 63ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 67ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.9640 - val_loss: 0.1630\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 63ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 0.0000e+00 - val_loss: 24.0443\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 59ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 3.8147e-09\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 65ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 0.9185 - val_loss: 0.1654\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 62ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.9230 - val_loss: 0.1657\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "\n",
      "Time taken for training:  06:26:52\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.9980 - Test Accuracy 0.6229\n",
      "Fold 2 - Train Accuracy 0.9969 - Test Accuracy 0.7130\n",
      "Fold 3 - Train Accuracy 0.9741 - Test Accuracy 0.8353\n",
      "Fold 4 - Train Accuracy 0.9993 - Test Accuracy 0.9344\n",
      "Fold 5 - Train Accuracy 0.9998 - Test Accuracy 0.8917\n",
      "Fold 6 - Train Accuracy 0.9988 - Test Accuracy 0.9542\n",
      "Fold 7 - Train Accuracy 0.9996 - Test Accuracy 0.9767\n",
      "Fold 8 - Train Accuracy 0.9982 - Test Accuracy 0.9635\n",
      "Fold 9 - Train Accuracy 0.9996 - Test Accuracy 0.9740\n",
      "Fold 10 - Train Accuracy 0.9997 - Test Accuracy 0.9720\n",
      "\n",
      "Mean Train Accuracy: 0.9964 - Std: 0.0075 \n",
      "Mean Test Accuracy: 0.8838 - Std: 0.1175 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92     13905\n",
      "           1       0.91      0.95      0.93       723\n",
      "           2       0.91      0.96      0.93      2659\n",
      "           3       0.78      0.74      0.76      1123\n",
      "           4       0.81      0.72      0.76       384\n",
      "           5       0.86      0.73      0.79        44\n",
      "           6       0.89      0.74      0.81       663\n",
      "           7       0.91      0.82      0.86        94\n",
      "           8       0.91      0.83      0.87        12\n",
      "           9       0.89      0.76      0.82       786\n",
      "          10       1.00      0.78      0.88         9\n",
      "          11       0.92      0.78      0.84        98\n",
      "          12       0.88      0.88      0.88         8\n",
      "          13       0.81      0.85      0.83        20\n",
      "          14       0.91      0.79      0.85        77\n",
      "          15       0.86      0.90      0.88        62\n",
      "          16       0.87      0.72      0.79       917\n",
      "          17       0.83      0.88      0.85       473\n",
      "          18       0.72      0.82      0.77        22\n",
      "          19       0.92      0.73      0.81       122\n",
      "          20       0.93      0.74      0.82       111\n",
      "          21       0.89      0.71      0.79       201\n",
      "          22       0.78      1.00      0.88         7\n",
      "          23       0.82      0.79      0.80        96\n",
      "          24       0.70      0.76      0.73      1045\n",
      "          25       0.77      0.84      0.80       540\n",
      "          26       0.81      0.81      0.81      1334\n",
      "          27       0.79      0.82      0.81        28\n",
      "          28       0.89      0.89      0.89        35\n",
      "          29       0.91      0.79      0.85        77\n",
      "          30       0.98      0.72      0.83        64\n",
      "          31       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.88     25746\n",
      "   macro avg       0.87      0.81      0.83     25746\n",
      "weighted avg       0.88      0.88      0.88     25746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"V5\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"V5\")\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.01\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_array, y_array, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_V5.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f5e894-ae42-4873-98a3-1fea5d538033",
   "metadata": {},
   "source": [
    "#### V6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "604f6dc2-b2e7-4688-9aff-c4a8874d5f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start loading CSV file...\n",
      "Finish loading CSV file.\n",
      "\n",
      "Starting build_time_window_structure function...\n",
      "\n",
      "Shape of features:  (25770, 1250)\n",
      "Quantity os samples (labels):  25770\n",
      "\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Remove classes with less than 6 samples.\n",
      "\n",
      "Show classes identification:\n",
      "Class: 0 - Arrhythmia code: 1\n",
      "Class: 1 - Arrhythmia code: 21\n",
      "Class: 2 - Arrhythmia code: 22\n",
      "Class: 3 - Arrhythmia code: 23\n",
      "Class: 4 - Arrhythmia code: 30\n",
      "Class: 5 - Arrhythmia code: 36\n",
      "Class: 6 - Arrhythmia code: 50\n",
      "Class: 7 - Arrhythmia code: 51\n",
      "Class: 8 - Arrhythmia code: 54\n",
      "Class: 9 - Arrhythmia code: 60\n",
      "Class: 10 - Arrhythmia code: 80\n",
      "Class: 11 - Arrhythmia code: 82\n",
      "Class: 12 - Arrhythmia code: 83\n",
      "Class: 13 - Arrhythmia code: 88\n",
      "Class: 14 - Arrhythmia code: 101\n",
      "Class: 15 - Arrhythmia code: 104\n",
      "Class: 16 - Arrhythmia code: 105\n",
      "Class: 17 - Arrhythmia code: 106\n",
      "Class: 18 - Arrhythmia code: 108\n",
      "Class: 19 - Arrhythmia code: 120\n",
      "Class: 20 - Arrhythmia code: 121\n",
      "Class: 21 - Arrhythmia code: 125\n",
      "Class: 22 - Arrhythmia code: 140\n",
      "Class: 23 - Arrhythmia code: 142\n",
      "Class: 24 - Arrhythmia code: 145\n",
      "Class: 25 - Arrhythmia code: 146\n",
      "Class: 26 - Arrhythmia code: 147\n",
      "Class: 27 - Arrhythmia code: 155\n",
      "Class: 28 - Arrhythmia code: 160\n",
      "Class: 29 - Arrhythmia code: 161\n",
      "Class: 30 - Arrhythmia code: 165\n",
      "Class: 31 - Arrhythmia code: 166\n",
      "\n",
      "Check for dataset balance:\n",
      "Class =   0   Qty =    13905   Percentage = 54.01 %\n",
      "Class =   2   Qty =     2659   Percentage = 10.33 %\n",
      "Class =  26   Qty =     1334   Percentage = 5.18 %\n",
      "Class =   3   Qty =     1123   Percentage = 4.36 %\n",
      "Class =  24   Qty =     1045   Percentage = 4.06 %\n",
      "Class =  16   Qty =      917   Percentage = 3.56 %\n",
      "Class =   9   Qty =      786   Percentage = 3.05 %\n",
      "Class =   1   Qty =      723   Percentage = 2.81 %\n",
      "Class =   6   Qty =      663   Percentage = 2.58 %\n",
      "Class =  25   Qty =      540   Percentage = 2.10 %\n",
      "Class =  17   Qty =      473   Percentage = 1.84 %\n",
      "Class =   4   Qty =      384   Percentage = 1.49 %\n",
      "Class =  21   Qty =      201   Percentage = 0.78 %\n",
      "Class =  19   Qty =      122   Percentage = 0.47 %\n",
      "Class =  20   Qty =      111   Percentage = 0.43 %\n",
      "Class =  11   Qty =       98   Percentage = 0.38 %\n",
      "Class =  23   Qty =       96   Percentage = 0.37 %\n",
      "Class =   7   Qty =       94   Percentage = 0.37 %\n",
      "Class =  14   Qty =       77   Percentage = 0.30 %\n",
      "Class =  29   Qty =       77   Percentage = 0.30 %\n",
      "Class =  30   Qty =       64   Percentage = 0.25 %\n",
      "Class =  15   Qty =       62   Percentage = 0.24 %\n",
      "Class =   5   Qty =       44   Percentage = 0.17 %\n",
      "Class =  28   Qty =       35   Percentage = 0.14 %\n",
      "Class =  27   Qty =       28   Percentage = 0.11 %\n",
      "Class =  18   Qty =       22   Percentage = 0.09 %\n",
      "Class =  13   Qty =       20   Percentage = 0.08 %\n",
      "Class =   8   Qty =       12   Percentage = 0.05 %\n",
      "Class =  10   Qty =        9   Percentage = 0.03 %\n",
      "Class =  12   Qty =        8   Percentage = 0.03 %\n",
      "Class =  22   Qty =        7   Percentage = 0.03 %\n",
      "Class =  31   Qty =        7   Percentage = 0.03 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">623</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">619</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">615</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">307</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4912</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">628,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │           \u001b[38;5;34m200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1246\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m623\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m619\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m1,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m615\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m307\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4912\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m628,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,880</span> (2.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m635,880\u001b[0m (2.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,528</span> (2.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m635,528\u001b[0m (2.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling data...\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Training fold 1\n",
      "\n",
      "Generating upsampling using SMOTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 20ms/step - accuracy: 0.8711 - loss: 0.5065 - val_accuracy: 0.8395 - val_loss: 0.4961\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 19ms/step - accuracy: 0.9801 - loss: 0.0659 - val_accuracy: 0.4675 - val_loss: 1.4778\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 20ms/step - accuracy: 0.9898 - loss: 0.0342 - val_accuracy: 0.9845 - val_loss: 0.0363\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 20ms/step - accuracy: 0.9929 - loss: 0.0246 - val_accuracy: 1.0000 - val_loss: 6.4230e-05\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 22ms/step - accuracy: 0.9940 - loss: 0.0198 - val_accuracy: 0.5405 - val_loss: 1.3696\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 24ms/step - accuracy: 0.9949 - loss: 0.0175 - val_accuracy: 1.0000 - val_loss: 0.0733\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 27ms/step - accuracy: 0.9956 - loss: 0.0154 - val_accuracy: 1.0000 - val_loss: 1.8239e-05\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 30ms/step - accuracy: 0.9960 - loss: 0.0142 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 25ms/step - accuracy: 0.9965 - loss: 0.0129 - val_accuracy: 0.5960 - val_loss: 0.9071\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 28ms/step - accuracy: 0.9970 - loss: 0.0103 - val_accuracy: 0.9375 - val_loss: 0.1519\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 25ms/step - accuracy: 0.9968 - loss: 0.0116 - val_accuracy: 0.6455 - val_loss: 1.1800\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 27ms/step - accuracy: 0.9973 - loss: 0.0098 - val_accuracy: 0.0000e+00 - val_loss: 18.8044\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 2\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 30ms/step - accuracy: 0.9761 - loss: 0.1047 - val_accuracy: 1.0000 - val_loss: 4.1186e-06\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 32ms/step - accuracy: 0.9945 - loss: 0.0187 - val_accuracy: 1.0000 - val_loss: 4.4430e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 29ms/step - accuracy: 0.9963 - loss: 0.0135 - val_accuracy: 1.0000 - val_loss: 2.0826e-07\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 28ms/step - accuracy: 0.9969 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 1.2706e-05\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 30ms/step - accuracy: 0.9970 - loss: 0.0100 - val_accuracy: 1.0000 - val_loss: 1.0977e-06\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 27ms/step - accuracy: 0.9974 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 9.6381e-08\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 32ms/step - accuracy: 0.9979 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 4.3362e-07\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 33ms/step - accuracy: 0.9978 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 4.9462e-06\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 33ms/step - accuracy: 0.9982 - loss: 0.0070 - val_accuracy: 0.8435 - val_loss: 0.6153\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 31ms/step - accuracy: 0.9980 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 1.1742e-06\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 31ms/step - accuracy: 0.9981 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 1.3621e-05\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "Training fold 3\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 34ms/step - accuracy: 0.9875 - loss: 0.0472 - val_accuracy: 0.9690 - val_loss: 0.0576\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 33ms/step - accuracy: 0.9966 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 6.1154e-07\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 32ms/step - accuracy: 0.9977 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 7.0882e-05\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 32ms/step - accuracy: 0.9976 - loss: 0.0096 - val_accuracy: 0.0000e+00 - val_loss: 13.7346\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 37ms/step - accuracy: 0.9979 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 5.5257e-06\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 30ms/step - accuracy: 0.9981 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 2.9767e-06\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 34ms/step - accuracy: 0.9982 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 4.6851e-06\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\n",
      "Training fold 4\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 34ms/step - accuracy: 0.9934 - loss: 0.0229 - val_accuracy: 0.0000e+00 - val_loss: 16.1035\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 37ms/step - accuracy: 0.9966 - loss: 0.0132 - val_accuracy: 0.0000e+00 - val_loss: 9.0359\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 31ms/step - accuracy: 0.9977 - loss: 0.0081 - val_accuracy: 0.5680 - val_loss: 1.8199\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 35ms/step - accuracy: 0.9981 - loss: 0.0071 - val_accuracy: 0.0000e+00 - val_loss: 16.5807\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 30ms/step - accuracy: 0.9977 - loss: 0.0078 - val_accuracy: 0.7455 - val_loss: 1.5742\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 35ms/step - accuracy: 0.9976 - loss: 0.0093 - val_accuracy: 0.0720 - val_loss: 6.4564\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 33ms/step - accuracy: 0.9984 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 6.7614e-07\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 34ms/step - accuracy: 0.9982 - loss: 0.0064 - val_accuracy: 0.5950 - val_loss: 2.2712\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 36ms/step - accuracy: 0.9984 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 5.8923e-05\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 34ms/step - accuracy: 0.9984 - loss: 0.0060 - val_accuracy: 0.9380 - val_loss: 0.0955\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 32ms/step - accuracy: 0.9985 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 9.5045\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 34ms/step - accuracy: 0.9983 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 1.1271e-07\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 36ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 1.4591e-07\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 33ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 37ms/step - accuracy: 0.9988 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 1.4901e-09\n",
      "Epoch 16/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 32ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 0.6970 - val_loss: 1.2294\n",
      "Epoch 17/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 35ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 2.0367e-07\n",
      "Epoch 18/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 32ms/step - accuracy: 0.9990 - loss: 0.0038 - val_accuracy: 0.0000e+00 - val_loss: 18.1569\n",
      "Epoch 19/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 36ms/step - accuracy: 0.9988 - loss: 0.0046 - val_accuracy: 0.0000e+00 - val_loss: 12.9910\n",
      "Epoch 20/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 31ms/step - accuracy: 0.9989 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 9.8798e-07\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "Training fold 5\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 37ms/step - accuracy: 0.9903 - loss: 0.0389 - val_accuracy: 0.2360 - val_loss: 4.7026\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 35ms/step - accuracy: 0.9974 - loss: 0.0097 - val_accuracy: 0.7880 - val_loss: 0.8222\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 38ms/step - accuracy: 0.9981 - loss: 0.0077 - val_accuracy: 0.6960 - val_loss: 1.6305\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 33ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 0.3385 - val_loss: 4.8865\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 34ms/step - accuracy: 0.9985 - loss: 0.0054 - val_accuracy: 0.0000e+00 - val_loss: 17.1275\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 38ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 0.8730 - val_loss: 0.5559\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 34ms/step - accuracy: 0.9988 - loss: 0.0047 - val_accuracy: 0.9980 - val_loss: 0.0060\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 38ms/step - accuracy: 0.9987 - loss: 0.0049 - val_accuracy: 0.0000e+00 - val_loss: 18.4021\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 34ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.9725 - val_loss: 0.0412\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 38ms/step - accuracy: 0.9989 - loss: 0.0045 - val_accuracy: 0.3125 - val_loss: 3.5529\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 34ms/step - accuracy: 0.9989 - loss: 0.0042 - val_accuracy: 0.8875 - val_loss: 0.3085\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 37ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 5.9605e-09\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 36ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 1.8176e-06\n",
      "Epoch 14/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 38ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 1.8499e-06\n",
      "Epoch 15/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 35ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.9120 - val_loss: 0.2061\n",
      "Epoch 16/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 38ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 0.0000e+00 - val_loss: 28.0083\n",
      "Epoch 17/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 35ms/step - accuracy: 0.9991 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 1.3560e-04\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\n",
      "Training fold 6\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 38ms/step - accuracy: 0.9945 - loss: 0.0210 - val_accuracy: 0.9980 - val_loss: 0.0114\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 38ms/step - accuracy: 0.9984 - loss: 0.0059 - val_accuracy: 0.0000e+00 - val_loss: 21.5013\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 36ms/step - accuracy: 0.9986 - loss: 0.0058 - val_accuracy: 0.6960 - val_loss: 1.1039\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 41ms/step - accuracy: 0.9986 - loss: 0.0059 - val_accuracy: 0.0000e+00 - val_loss: 20.8633\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 41ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 1.7788e-06\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 38ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 0.0000e+00 - val_loss: 16.6992\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 34ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 0.3040 - val_loss: 4.9692\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 40ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 1.9427e-06\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 34ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.1060 - val_loss: 6.2711\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 41ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 2.0504e-04\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Training fold 7\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 42ms/step - accuracy: 0.9969 - loss: 0.0113 - val_accuracy: 0.9945 - val_loss: 0.0215\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 38ms/step - accuracy: 0.9988 - loss: 0.0046 - val_accuracy: 0.0000e+00 - val_loss: 11.8699\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 38ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 0.0000e+00 - val_loss: 20.3498\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 36ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 5.4240e-09\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 38ms/step - accuracy: 0.9989 - loss: 0.0042 - val_accuracy: 0.3155 - val_loss: 4.3648\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 42ms/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 39ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 1.8726e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 34ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 1.1921e-09\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 42ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 0.0000e+00 - val_loss: 22.3427\n",
      "Epoch 10/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 40ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.0000e+00 - val_loss: 21.2605\n",
      "Epoch 11/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 43ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 1.9974e-06\n",
      "Epoch 12/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 36ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 0.1685 - val_loss: 5.2421\n",
      "Epoch 13/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 44ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 5.3644e-09\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\n",
      "Training fold 8\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 48ms/step - accuracy: 0.9973 - loss: 0.0102 - val_accuracy: 0.6255 - val_loss: 1.5776\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 41ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 52ms/step - accuracy: 0.9990 - loss: 0.0035 - val_accuracy: 0.2025 - val_loss: 4.6145\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 49ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 0.1920 - val_loss: 5.2760\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 45ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.0000e+00 - val_loss: 21.6807\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 55ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.1440 - val_loss: 5.8396\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 56ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 0.0000e+00 - val_loss: 18.6853\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "\n",
      "Training fold 9\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 69ms/step - accuracy: 0.9983 - loss: 0.0068 - val_accuracy: 0.0000e+00 - val_loss: 20.1053\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 59ms/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 0.9950 - val_loss: 0.0098\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 57ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.0000e+00 - val_loss: 14.3394\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 63ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 1.9389e-07\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 61ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.0000e+00 - val_loss: 15.5743\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 67ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.0000e+00 - val_loss: 19.4203\n",
      "Epoch 7/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 68ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9000 - val_loss: 0.4876\n",
      "Epoch 8/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 75ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.0000e+00 - val_loss: 23.4622\n",
      "Epoch 9/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 73ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 4.5715e-07\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "\n",
      "Training fold 10\n",
      "\n",
      "Generating upsampling using SMOTE...\n",
      "200000 samples after upsampling.\n",
      "Class distribution for training after upsampling: Counter({0: 6250, 1: 6250, 2: 6250, 3: 6250, 4: 6250, 5: 6250, 6: 6250, 7: 6250, 8: 6250, 9: 6250, 10: 6250, 11: 6250, 12: 6250, 13: 6250, 14: 6250, 15: 6250, 16: 6250, 17: 6250, 18: 6250, 19: 6250, 20: 6250, 21: 6250, 22: 6250, 23: 6250, 24: 6250, 25: 6250, 26: 6250, 27: 6250, 28: 6250, 29: 6250, 30: 6250, 31: 6250})\n",
      "Finishing upsampling.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m519s\u001b[0m 84ms/step - accuracy: 0.9976 - loss: 0.0104 - val_accuracy: 1.0000 - val_loss: 1.6868e-08\n",
      "Epoch 2/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m480s\u001b[0m 78ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 1.0732e-05\n",
      "Epoch 3/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 81ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.0000e+00 - val_loss: 22.2626\n",
      "Epoch 4/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 80ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 5/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 81ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.2055 - val_loss: 5.2683\n",
      "Epoch 6/300\n",
      "\u001b[1m6188/6188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 85ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 3.6299e-08\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "\n",
      "Time taken for training:  07:55:12\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.9871 - Test Accuracy 0.5915\n",
      "Fold 2 - Train Accuracy 0.9983 - Test Accuracy 0.7755\n",
      "Fold 3 - Train Accuracy 0.9974 - Test Accuracy 0.8936\n",
      "Fold 4 - Train Accuracy 0.9958 - Test Accuracy 0.7631\n",
      "Fold 5 - Train Accuracy 0.9992 - Test Accuracy 0.8882\n",
      "Fold 6 - Train Accuracy 0.9900 - Test Accuracy 0.8862\n",
      "Fold 7 - Train Accuracy 0.9995 - Test Accuracy 0.9681\n",
      "Fold 8 - Train Accuracy 0.8076 - Test Accuracy 0.7253\n",
      "Fold 9 - Train Accuracy 0.9987 - Test Accuracy 0.9705\n",
      "Fold 10 - Train Accuracy 0.9995 - Test Accuracy 0.9872\n",
      "\n",
      "Mean Train Accuracy: 0.9773 - Std: 0.0567 \n",
      "Mean Test Accuracy: 0.8449 - Std: 0.1213 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     13905\n",
      "           1       0.96      0.79      0.86       723\n",
      "           2       0.82      0.97      0.89      2659\n",
      "           3       0.85      0.55      0.67      1123\n",
      "           4       0.84      0.60      0.70       384\n",
      "           5       0.92      0.52      0.67        44\n",
      "           6       0.87      0.65      0.74       663\n",
      "           7       0.94      0.64      0.76        94\n",
      "           8       0.89      0.67      0.76        12\n",
      "           9       0.83      0.70      0.76       786\n",
      "          10       0.50      0.44      0.47         9\n",
      "          11       0.83      0.63      0.72        98\n",
      "          12       0.56      0.62      0.59         8\n",
      "          13       1.00      0.75      0.86        20\n",
      "          14       0.91      0.62      0.74        77\n",
      "          15       0.30      0.97      0.46        62\n",
      "          16       0.82      0.61      0.70       917\n",
      "          17       0.91      0.79      0.85       473\n",
      "          18       0.88      0.68      0.77        22\n",
      "          19       0.92      0.64      0.75       122\n",
      "          20       0.92      0.50      0.65       111\n",
      "          21       0.61      0.72      0.66       201\n",
      "          22       0.71      0.71      0.71         7\n",
      "          23       0.91      0.66      0.76        96\n",
      "          24       0.92      0.51      0.66      1045\n",
      "          25       0.77      0.72      0.74       540\n",
      "          26       0.79      0.71      0.75      1334\n",
      "          27       0.78      0.75      0.76        28\n",
      "          28       0.92      0.69      0.79        35\n",
      "          29       0.85      0.66      0.74        77\n",
      "          30       0.97      0.55      0.70        64\n",
      "          31       0.83      0.71      0.77         7\n",
      "\n",
      "    accuracy                           0.84     25746\n",
      "   macro avg       0.82      0.68      0.73     25746\n",
      "weighted avg       0.85      0.84      0.84     25746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a \"time window\" structure to handle the dataset as a time series.\n",
    "new_df = load_dataset(\"V6\")\n",
    "X_array, y_array = build_time_window_structure(new_df, \"V6\")\n",
    "X_array, y_array = remove_classes_with_less_samples(X_array, y_array)\n",
    "\n",
    "# Train the CNN model.\n",
    "v1_model = create_v1()\n",
    "v1_num_epochs = 300\n",
    "v1_batch_size = 32\n",
    "v1_validation_split = 0.01\n",
    "\n",
    "training_history_v1 = train_cnn_model(v1_model, X_array, y_array, v1_num_epochs, v1_batch_size, v1_validation_split, \"v1_model_V6.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eeacd4-381d-454c-bf54-0db942fb0e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
